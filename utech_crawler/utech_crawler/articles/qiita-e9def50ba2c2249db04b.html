<!DOCTYPE html><html xmlns:og="http://ogp.me/ns#"><head><meta charset="UTF-8" /><title>ディープラーニングにおける様々な物体領域検出のアプローチ方法(R-CNN) - Qiita</title><meta content="width=device-width,initial-scale=1" name="viewport" /><meta content="

ディープラーニングにおける物体領域認識の必要性

最近ディープラーニングについて勉強していまして、あらかじめ人間によってトリミングや処理された認識しやすい下記のような画像の認識は90%以上の高確率で出来るようになりました。



しかしこの前処理を人間がやっていたのではディープラーニングを使う利点が大きく削がれてしまいます。そこで複数の物体を含む画像からそれぞれの物体領域を認識し、その領域ごとにニューラルネットワークによる認識を行うプロセスいわゆるR-CNN(Reg..." name="description" /><meta content="summary" name="twitter:card" /><meta content="@Qiita" name="twitter:site" /><meta content="t_hiroyoshi" name="twitter:creator" /><meta content="ディープラーニングにおける様々な物体領域検出のアプローチ方法(R-CNN) - Qiita" property="og:title" /><meta content="article" property="og:type" /><meta content="http://qiita.com/t-hiroyoshi/items/e9def50ba2c2249db04b" property="og:url" /><meta content="http://cdn.qiita.com/assets/qiita-fb-2887e7b4aad86fd8c25cea84846f2236.png" property="og:image" /><meta content="## ディープラーニングにおける物体領域認識の必要性

最近ディープラーニングについて勉強していまして、あらかじめ人間によってトリミングや処理された認識しやすい下記のような画像の認識は90%以上の高確率で出来るようになりました。

!..." property="og:description" /><meta content="Qiita" property="og:site_name" /><meta content="564524038" property="fb:admins" /><link rel="shortcut icon" type="image/x-icon" href="http://cdn.qiita.com/assets/favicons/public/production-4ff10c1e1e2b5fcb353ff9cafdd56c70.ico" /><link rel="apple-touch-icon" type="image/png" href="http://cdn.qiita.com/assets/favicons/public/apple-touch-icon-f9a6afad761ec2306e10db2736187c8b.png" /><link href="/opensearch.xml" rel="search" title="Qiita" type="application/opensearchdescription+xml" /><link rel="stylesheet" media="all" href="http://cdn.qiita.com/assets/public-81dd63f4385f99b52aeab91266068ebd.min.css" /><meta name="csrf-param" content="authenticity_token" />
<meta name="csrf-token" content="6jIbrAvyylATLaS3tWezv/xnrdZrk35qyzSmBdEXBfSetb0IN/RP5XEmS4+7taOOMhpyvIgnclOppxYPSMLIYA==" /></head><body class="without-js" id=""><noscript><iframe height="0" src="//www.googletagmanager.com/ns.html?id=GTM-TBQWPN" style="display:none;visibility:hidden" width="0"></iframe></noscript><script>
  document.body.className = document.body.className.replace('without-js', '') + ' with-js';
  window.Qiita = {"asset_host":"cdn.qiita.com","TLD":"com","controller_path":"public/items","controller_action":"public/items#show","controller":"items","action":"show","action_path":"public/items#show","env":"production","flash":{},"is_landing_page":false,"is_team_page":false,"request_parameters":{"controller":"public/items","action":"show","user_id":"t-hiroyoshi","type":"items","id":"e9def50ba2c2249db04b"},"root_domain":"qiita.com","variant":null,"config":{"mixpanel":{"career":"dd35af27e959781713d63fd7ca898a8d","per_team":"c0a2116368b33b44b5029ebd2cc9b094","public":"be87616606b0e26a87689099aab2c4e5","team":"b7c0342acba2dbc8742484d98788efb3"},"default_locale":"ja","locale":"en"},"team":null,"user":null,"GIT_BRANCH":null,"DEBUG":false};

</script>
<div class="headerContainer headerContainer-public" role="navigation"><div class="js-react-on-rails-component" data-component-name="HeaderContainer" data-props="{&quot;user&quot;:null,&quot;team&quot;:null,&quot;news&quot;:{&quot;type&quot;:&quot;Hot&quot;,&quot;content&quot;:&quot;Markdownによる情報共有サービス、Qiita:Team&quot;,&quot;url&quot;:&quot;https://teams.qiita.com?utm_source=qiita\u0026utm_medium=header_news&quot;},&quot;initial_unread_count&quot;:null,&quot;siteid_image&quot;:&quot;http://cdn.qiita.com/siteid-reverse.png&quot;,&quot;is_team_page&quot;:false,&quot;on_team_setting&quot;:false,&quot;show_post_menu&quot;:true,&quot;show_search_menu&quot;:true,&quot;is_fluid&quot;:false,&quot;locale&quot;:&quot;en&quot;}" data-trace="false" data-dom-id="HeaderContainer-react-component-8bfb5680-3f1a-4411-a1e6-3f0807f37fbd"></div>
    <div id="HeaderContainer-react-component-8bfb5680-3f1a-4411-a1e6-3f0807f37fbd"></div>
    
</div><div id="main"><script type="application/ld+json">{  "@context": "http://schema.org",  "@type": "BreadcrumbList",  "itemListElement": [    {      "@type": "ListItem",      "position": 1,      "item": {        "@id": "/",        "name": "Qiita"      }    },    {      "@type": "ListItem",      "position": 2,      "item": {        "@id": "/items",        "name": "Items"      }    },    {      "@type": "ListItem",      "position": 3,      "item": {        "@id": "/tags/DeepLearning",        "name": "DeepLearning"      }    }  ]}</script><article itemscope="" itemtype="http://schema.org/Article"><div class="ArticleMainHeader "><div class="container"></div><div class="container"><div class="row s-flex-align-center"><div class="col-sm-9"><h1 class="ArticleMainHeader__title" itemprop="headline">ディープラーニングにおける様々な物体領域検出のアプローチ方法(R-CNN)</h1><ul class="TagList"><li class="TagList__item" data-count="1075"><a class="u-link-unstyled TagList__label" href="/tags/DeepLearning"><img alt="DeepLearning" class="TagList__icon" src="https://s3-ap-northeast-1.amazonaws.com/qiita-tag-image/eac844d1d880a38fc3be5ebf534cad5182b64ebf/medium.jpg?1453002020" /><span>DeepLearning</span></a></li><li class="TagList__item" data-count="1835"><a class="u-link-unstyled TagList__label" href="/tags/%E6%A9%9F%E6%A2%B0%E5%AD%A6%E7%BF%92"><img alt="機械学習" class="TagList__icon" src="https://s3-ap-northeast-1.amazonaws.com/qiita-tag-image/a94d4d239b3b0b83723d5b56c050ffc54b8593e7/medium.jpg?1394635775" /><span>機械学習</span></a></li></ul></div><div class="col-sm-3"><div class="itemsShowHeaderStock"><ul class="list-unstyled itemsShowHeaderStock_statusList"><li><div class="itemsShowHeaderStock_count stock"><span class="fa fa-thumbs-up"></span><span class="js-likecount">156</span></div><div class="itemsShowHeaderStock_countText">Like</div></li><li><div class="itemsShowHeaderStock_count" content="1 UserComments" itemprop="commentCount"><span class="fa fa-comment"></span>1</div><div class="itemsShowHeaderStock_countText">Comment</div></li></ul></div><div class="js-likebutton" data-props="{&quot;like_status&quot;:false,&quot;like_count&quot;:156,&quot;uuid&quot;:&quot;e9def50ba2c2249db04b&quot;,&quot;likable_type&quot;:&quot;Article&quot;,&quot;position&quot;:&quot;article-header&quot;}"></div><ul class="list-inline ArticleMainHeader__users"><li class="js-hovercard" data-hovercard-target-name="suin"><a itemprop="url" href="/suin"><img alt="suin" class="thumb thumb--xs" src="https://qiita-image-store.s3.amazonaws.com/0/889/profile-images/1473682133" /></a></li><li class="js-hovercard" data-hovercard-target-name="miseyu"><a itemprop="url" href="/miseyu"><img alt="miseyu" class="thumb thumb--xs" src="https://qiita-image-store.s3.amazonaws.com/0/5921/profile-images/1473682386" /></a></li><li class="js-hovercard" data-hovercard-target-name="mono0926"><a itemprop="url" href="/mono0926"><img alt="mono0926" class="thumb thumb--xs" src="https://qiita-image-store.s3.amazonaws.com/0/19398/profile-images/1473682701" /></a></li><li class="js-hovercard" data-hovercard-target-name="cheshire"><a itemprop="url" href="/cheshire"><img alt="cheshire" class="thumb thumb--xs" src="https://qiita-image-store.s3.amazonaws.com/0/53149/profile-images/1473692970" /></a></li><li class="js-hovercard" data-hovercard-target-name="mpyw"><a itemprop="url" href="/mpyw"><img alt="mpyw" class="thumb thumb--xs" src="https://qiita-image-store.s3.amazonaws.com/0/25060/profile-images/1473684251" /></a></li><li class="js-hovercard" data-hovercard-target-name="st450"><a itemprop="url" href="/st450"><img alt="st450" class="thumb thumb--xs" src="https://qiita-image-store.s3.amazonaws.com/0/63970/profile-images/1473696432" /></a></li><li class="js-hovercard" data-hovercard-target-name="UedaTakeyuki"><a itemprop="url" href="/UedaTakeyuki"><img alt="UedaTakeyuki" class="thumb thumb--xs" src="https://qiita-image-store.s3.amazonaws.com/0/46544/profile-images/1489714841" /></a></li><li class="js-hovercard" data-hovercard-target-name="yorksyo"><a itemprop="url" href="/yorksyo"><img alt="yorksyo" class="thumb thumb--xs" src="https://qiita-image-store.s3.amazonaws.com/0/44317/profile-images/1473689856" /></a></li><li class="js-hovercard" data-hovercard-target-name="mero"><a itemprop="url" href="/mero"><img alt="mero" class="thumb thumb--xs" src="https://qiita-image-store.s3.amazonaws.com/0/63104/profile-images/1473696161" /></a></li><li class="js-hovercard" data-hovercard-target-name="trkbt10"><a itemprop="url" href="/trkbt10"><img alt="trkbt10" class="thumb thumb--xs" src="https://qiita-image-store.s3.amazonaws.com/0/74461/profile-images/1473699844" /></a></li><li><a href="/t-hiroyoshi/items/e9def50ba2c2249db04b/likers"><span class="fa fa-ellipsis-h"></span></a></li></ul></div></div></div></div><div class="ArticleAsideHeader"><div class="container"><div class="u-flex u-space-between"><div class="u-flex u-flex-wrap"><div class="u-flex u-align-center s-pdv-5 u-flex-wrap"><div class="ArticleAsideHeader__author"><a href="/t-hiroyoshi"><img class="thumb thumb--xs" src="https://qiita-image-store.s3.amazonaws.com/0/72314/profile-images/1473699117" alt="1473699117" /></a> <a class="u-link-unstyled" href="/t-hiroyoshi">t-hiroyoshi</a> </div><div class="ArticleAsideHeader__date"><span>posted at <time datetime="2015-07-09T18:02:15+09:00" itemprop="datePublished">2015-07-09</time></span></div></div><div class="u-flex u-align-center s-pdv-5 mobile-hidden"></div><div class="u-flex u-align-center s-pdv-5 mobile-hidden"></div></div><div class="u-flex u-align-center s-flex-justiry-between s-pdv-5 u-shrink-0"><div class="ArticleAsideHeader__stock"><div class="js-stockbutton" data-position="top" data-props="{&quot;stock_status&quot;:false}"></div></div><div class="dropdown"><a class="dropdown-toggle" data-toggle="dropdown" href="#"><span class="fa fa-ellipsis-h fa-lg"></span></a><ul class="dropdown-menu dropdown-menu-right"><li><a href="/t-hiroyoshi/items/e9def50ba2c2249db04b.md"><span class="fa fa-fw fa-file-text-o"></span> Show article as Markdown</a></li><li><a data-target=".js-report-form" data-toggle="modal" href="#"><span class="fa fa-fw fa-flag"></span> Report article</a></li></ul></div></div></div></div></div><div class="container"><div class="row" id="article-body-wrapper"><div class="col-sm-9"><section class="markdownContent markdownContent-headingEnabled js-task-list-container clearfix position-relative" id="item-e9def50ba2c2249db04b" itemprop="articleBody"><div class="alert alert-warning"><i class="fa fa-clock-o"></i> More than 1 year has passed since last update.</div>
<h2>
<span id="ディープラーニングにおける物体領域認識の必要性" class="fragment"></span><a href="#%E3%83%87%E3%82%A3%E3%83%BC%E3%83%97%E3%83%A9%E3%83%BC%E3%83%8B%E3%83%B3%E3%82%B0%E3%81%AB%E3%81%8A%E3%81%91%E3%82%8B%E7%89%A9%E4%BD%93%E9%A0%98%E5%9F%9F%E8%AA%8D%E8%AD%98%E3%81%AE%E5%BF%85%E8%A6%81%E6%80%A7"><i class="fa fa-link"></i></a>ディープラーニングにおける物体領域認識の必要性</h2>

<p>最近ディープラーニングについて勉強していまして、あらかじめ人間によってトリミングや処理された認識しやすい下記のような画像の認識は90%以上の高確率で出来るようになりました。</p>

<p><a href="https://qiita-image-store.s3.amazonaws.com/0/72314/5342f8dd-8c41-580c-d42e-c993d8c79228.png" target="_blank" rel="nofollow noopener"><img src="https://qiita-image-store.s3.amazonaws.com/0/72314/5342f8dd-8c41-580c-d42e-c993d8c79228.png" alt="89bfbe03-6e3b-489d-8476-8979e3a1f557.png"></a></p>

<p>しかしこの前処理を人間がやっていたのではディープラーニングを使う利点が大きく削がれてしまいます。そこで複数の物体を含む画像からそれぞれの物体領域を認識し、その領域ごとにニューラルネットワークによる認識を行うプロセスいわゆるR-CNN(Regions with Convolutional Neural Network)を使う必要があります。R-CNNを使用する事で下の画像のような検出が可能になります(まだできてないけどCaptcha Breakerを作ってます)。</p>

<p><a href="https://qiita-image-store.s3.amazonaws.com/0/72314/437cf24e-a682-4200-4f38-04c5c164fad4.png" target="_blank" rel="nofollow noopener"><img src="https://qiita-image-store.s3.amazonaws.com/0/72314/437cf24e-a682-4200-4f38-04c5c164fad4.png" alt="8001.png"></a></p>

<p>そこで、物体領域認識にはいくつかの方法があるので簡単にまとめてみようと思います。</p>

<h2>
<span id="objectness" class="fragment"></span><a href="#objectness"><i class="fa fa-link"></i></a>Objectness</h2>

<p>古くから使われている物体認識方法です。1枚の画像を10,000枚以上に分割して顕著度、エッジ、色や場所を基としたスコア付けがなされたのち、スコアが高い部分が物体領域として認識されるという方法です。スコア付けは割と緩く行われるが精度は高く、処理速度も良好のようです。出力として画像中の座標と物体らしさのスコアが得られます。問題点として一度検出がスルーされてしまうと再帰させるのが難しいという点、物体の詳細な輪郭は得られない点があります。古くからある方法のため論文やドキュメントが多く、参照しやすいです。</p>

<p><a href="https://qiita-image-store.s3.amazonaws.com/0/72314/db0472b2-d5f9-5631-ae86-194b36406c76.jpeg" target="_blank" rel="nofollow noopener"><img src="https://qiita-image-store.s3.amazonaws.com/0/72314/db0472b2-d5f9-5631-ae86-194b36406c76.jpeg" alt="nmsMS+CC+SS_002053.jpg"></a></p>

<h2>
<span id="cpmcconstrained-parametric-min-cuts" class="fragment"></span><a href="#cpmcconstrained-parametric-min-cuts"><i class="fa fa-link"></i></a>CPMC(Constrained Parametric Min-Cuts)</h2>

<p>Objectnessと同様に古くからある物体認識方法です。前景として配置された点(Seeds)の周囲にグラフカット処理が行われ、それらを基に物体領域を認識するという方法。処理速度が非常に遅いがかなりの高精度で物体領域が検出できるようです。また強みとしてObjectnessでは得られない物体の輪郭が高精度で得られるという点があり、目的の物体を背景から切り離して処理したい時などに適しています。</p>

<p><a href="https://qiita-image-store.s3.amazonaws.com/0/72314/ea4817ff-8009-eae5-918d-9bdd814f91db.png" target="_blank" rel="nofollow noopener"><img src="https://qiita-image-store.s3.amazonaws.com/0/72314/ea4817ff-8009-eae5-918d-9bdd814f91db.png" alt="CPMC.png"></a></p>

<h2>
<span id="selective-search" class="fragment"></span><a href="#selective-search"><i class="fa fa-link"></i></a>Selective Search</h2>

<p>最近何かと流行っている物体認識方法。色やテクスチャ特徴を基に類似度が高い近接領域を段階ごとに結合していき、最終的に一枚の画像を一つの結合体にします。その段階的な変化を基に物体領域を認識するという方法。精度が高く、処理速度も高速ですがパラメータ調整が大変なようです。複数のパラメータ設定で並列処理することで認識率を上げることができます。物体の輪郭も得る事ができますがCPMCにの精度には及びません。物体の詳細な輪郭を得る必要がない場合は良い選択肢の一つになりそうです。</p>

<p><a href="https://qiita-image-store.s3.amazonaws.com/0/72314/7beb13a2-5bd0-1827-0dc6-ca26364f10a4.jpeg" target="_blank" rel="nofollow noopener"><img src="https://qiita-image-store.s3.amazonaws.com/0/72314/7beb13a2-5bd0-1827-0dc6-ca26364f10a4.jpeg" alt="image.png.jpeg"></a></p>

<h2>
<span id="object-proposals" class="fragment"></span><a href="#object-proposals"><i class="fa fa-link"></i></a>Object Proposals</h2>

<p>CPMCと類似している物体認識方法です。前景として配置された点(Seeds)からピクセルごとの結合を基に物体の境界予測を複数作成しその全体の傾向から物体領域を認識するという方法。CPMCと同様の長所、短所を持っていて処理速度はCPMCと同様遅いですが高精度の認識ができ、物体の輪郭も得る事ができます。物体をパーツごとに認識できる(鳥の羽の部分のみや人の顔の部分のみなど)ためより細かい画像分類などに向いています。動植物の分類などを目的としている場合は良い選択肢となりそうです。</p>

<p><a href="https://qiita-image-store.s3.amazonaws.com/0/72314/b6e98d73-d1be-c6be-9f21-c64aea89a9e8.png" target="_blank" rel="nofollow noopener"><img src="https://qiita-image-store.s3.amazonaws.com/0/72314/b6e98d73-d1be-c6be-9f21-c64aea89a9e8.png" alt="objectproposal.png"></a></p>

<h2>
<span id="まとめ" class="fragment"></span><a href="#%E3%81%BE%E3%81%A8%E3%82%81"><i class="fa fa-link"></i></a>まとめ</h2>

<p>物体領域認識はCNNによる認識の上流にくるので、CNNのチューニング以上に画像認識率に関わってきます。これらの他にも様々な方法があり、用途によって最適な物体領域認識方法を選択する必要が有ります。またこれらの物体領域検出方法も学習により精度が改善されるみたいなので色々と試してみたいです。</p>

<p>他に方法を見つけ次第随時追加していこうと思います。<br>
何か問題点、改善点ありましたら教えてください。</p>

<h2>
<span id="参考文献" class="fragment"></span><a href="#%E5%8F%82%E8%80%83%E6%96%87%E7%8C%AE"><i class="fa fa-link"></i></a>参考文献</h2>

<ul>
<li><a href="http://groups.inf.ed.ac.uk/calvin/objectness/" rel="nofollow noopener" target="_blank">Objectness measure V2.2</a></li>
<li><a href="http://koen.me/research/selectivesearch/" rel="nofollow noopener" target="_blank">Homepage of Koen van de Sande</a></li>
<li><a href="http://www2.isr.uc.pt/%7Ejoaoluis/papers/PAMI2012.pdf" rel="nofollow noopener" target="_blank">CPMC: Automatic Object Segmentation Using Constrained Parametric Min-Cuts By Joa ̃o Carreira and Cristian Sminchisescu</a></li>
<li><a href="http://www.philkr.net/home/gop" rel="nofollow noopener" target="_blank">Geodesic Object Proposals By Philipp Kr ̈ahenbu ̈hl and Vladlen Koltun</a></li>
</ul>
<div class="hidden"><form class="js-task-list-update" action="/t-hiroyoshi/items/e9def50ba2c2249db04b" accept-charset="UTF-8" method="post"><input name="utf8" type="hidden" value="&#x2713;" /><input type="hidden" name="_method" value="patch" /><input type="hidden" name="authenticity_token" value="r2oTOCTKTKefHwJOc9MGFswLM+UgdOJBOTYLhd0oo8/b7bWcGMzJEv0U7XZ9ARYnAnbsj8PA7nhbpbuPRP1uWw==" /><input type="hidden" name="updated_at_confirmation_in_unixtime" id="updated_at_confirmation_in_unixtime" value="1436432535" class="js-task-list-updated-at" /><textarea name="raw_body" id="raw_body" class="js-task-list-field">
## ディープラーニングにおける物体領域認識の必要性

最近ディープラーニングについて勉強していまして、あらかじめ人間によってトリミングや処理された認識しやすい下記のような画像の認識は90%以上の高確率で出来るようになりました。

![89bfbe03-6e3b-489d-8476-8979e3a1f557.png](https://qiita-image-store.s3.amazonaws.com/0/72314/5342f8dd-8c41-580c-d42e-c993d8c79228.png)

しかしこの前処理を人間がやっていたのではディープラーニングを使う利点が大きく削がれてしまいます。そこで複数の物体を含む画像からそれぞれの物体領域を認識し、その領域ごとにニューラルネットワークによる認識を行うプロセスいわゆるR-CNN(Regions with Convolutional Neural Network)を使う必要があります。R-CNNを使用する事で下の画像のような検出が可能になります(まだできてないけどCaptcha Breakerを作ってます)。

![8001.png](https://qiita-image-store.s3.amazonaws.com/0/72314/437cf24e-a682-4200-4f38-04c5c164fad4.png)

そこで、物体領域認識にはいくつかの方法があるので簡単にまとめてみようと思います。

## Objectness

古くから使われている物体認識方法です。1枚の画像を10,000枚以上に分割して顕著度、エッジ、色や場所を基としたスコア付けがなされたのち、スコアが高い部分が物体領域として認識されるという方法です。スコア付けは割と緩く行われるが精度は高く、処理速度も良好のようです。出力として画像中の座標と物体らしさのスコアが得られます。問題点として一度検出がスルーされてしまうと再帰させるのが難しいという点、物体の詳細な輪郭は得られない点があります。古くからある方法のため論文やドキュメントが多く、参照しやすいです。

![nmsMS+CC+SS_002053.jpg](https://qiita-image-store.s3.amazonaws.com/0/72314/db0472b2-d5f9-5631-ae86-194b36406c76.jpeg)

## CPMC(Constrained Parametric Min-Cuts)

Objectnessと同様に古くからある物体認識方法です。前景として配置された点(Seeds)の周囲にグラフカット処理が行われ、それらを基に物体領域を認識するという方法。処理速度が非常に遅いがかなりの高精度で物体領域が検出できるようです。また強みとしてObjectnessでは得られない物体の輪郭が高精度で得られるという点があり、目的の物体を背景から切り離して処理したい時などに適しています。

 ![CPMC.png](https://qiita-image-store.s3.amazonaws.com/0/72314/ea4817ff-8009-eae5-918d-9bdd814f91db.png)

## Selective Search

最近何かと流行っている物体認識方法。色やテクスチャ特徴を基に類似度が高い近接領域を段階ごとに結合していき、最終的に一枚の画像を一つの結合体にします。その段階的な変化を基に物体領域を認識するという方法。精度が高く、処理速度も高速ですがパラメータ調整が大変なようです。複数のパラメータ設定で並列処理することで認識率を上げることができます。物体の輪郭も得る事ができますがCPMCにの精度には及びません。物体の詳細な輪郭を得る必要がない場合は良い選択肢の一つになりそうです。

![image.png.jpeg](https://qiita-image-store.s3.amazonaws.com/0/72314/7beb13a2-5bd0-1827-0dc6-ca26364f10a4.jpeg)

## Object Proposals

CPMCと類似している物体認識方法です。前景として配置された点(Seeds)からピクセルごとの結合を基に物体の境界予測を複数作成しその全体の傾向から物体領域を認識するという方法。CPMCと同様の長所、短所を持っていて処理速度はCPMCと同様遅いですが高精度の認識ができ、物体の輪郭も得る事ができます。物体をパーツごとに認識できる(鳥の羽の部分のみや人の顔の部分のみなど)ためより細かい画像分類などに向いています。動植物の分類などを目的としている場合は良い選択肢となりそうです。

![objectproposal.png](https://qiita-image-store.s3.amazonaws.com/0/72314/b6e98d73-d1be-c6be-9f21-c64aea89a9e8.png)

## まとめ

物体領域認識はCNNによる認識の上流にくるので、CNNのチューニング以上に画像認識率に関わってきます。これらの他にも様々な方法があり、用途によって最適な物体領域認識方法を選択する必要が有ります。またこれらの物体領域検出方法も学習により精度が改善されるみたいなので色々と試してみたいです。

他に方法を見つけ次第随時追加していこうと思います。
何か問題点、改善点ありましたら教えてください。

## 参考文献

* [Objectness measure V2.2](http://groups.inf.ed.ac.uk/calvin/objectness/)
* [Homepage of Koen van de Sande](http://koen.me/research/selectivesearch/)
* [CPMC: Automatic Object Segmentation Using Constrained Parametric Min-Cuts By Joa ̃o Carreira and Cristian Sminchisescu](http://www2.isr.uc.pt/~joaoluis/papers/PAMI2012.pdf)
* [Geodesic Object Proposals By Philipp Kr ̈ahenbu ̈hl and Vladlen Koltun] (http://www.philkr.net/home/gop)
</textarea><input type="submit" name="commit" value="Save changes" data-disable-with="Save changes" /></form></div></section></div><div class="col-sm-3"><div class="socialButtons"><div class="socialButtons_twitter"><a class="twitter-share-button" data-text="ディープラーニングにおける様々な物体領域検出のアプローチ方法(R-CNN) by @t_hiroyoshi on @Qiita" data-url="http://qiita.com/t-hiroyoshi/items/e9def50ba2c2249db04b" href="https://twitter.com/share">Tweet</a></div><div class="socialButtons_hatebu"><a class="hatena-bookmark-button" data-hatena-bookmark-layout="simple-balloon" data-hatena-bookmark-title="ディープラーニングにおける様々な物体領域検出のアプローチ方法(R-CNN)" href="http://b.hatena.ne.jp/entry/http://qiita.com/t-hiroyoshi/items/e9def50ba2c2249db04b" title="Add to Hatena Bookmark"><img alt="Add to Hatena Bookmark" height="20" src="https://b.st-hatena.com/images/entry-button/button-only@2x.png" style="border: none;" width="20" /></a><script async="async" charset="utf-8" src="https://b.st-hatena.com/js/bookmark_button.js" type="text/javascript"></script></div><div class="socialButtons_googlePlus"><div class="g-plusone" data-href="http://qiita.com/t-hiroyoshi/items/e9def50ba2c2249db04b" data-size="medium"></div></div><div class="socialButtons_facebook"><div class="fb-like" data-action="like" data-href="http://qiita.com/t-hiroyoshi/items/e9def50ba2c2249db04b" data-layout="button_count" data-share="false" data-show-faces="false"></div></div><div class="socialButtons_pocket"><a class="pocket-btn" data-lang="en" data-pocket-count="horizontal" data-pocket-label="pocket"></a></div></div><section class="itemsShowAuthorInfo" itemprop="author" itemscope="" itemtype="http://schema.org/Person"><a href="/t-hiroyoshi"><img alt="" class="itemsShowAuthorInfo_userIcon" itemprop="image" src="https://qiita-image-store.s3.amazonaws.com/0/72314/profile-images/1473699117" /></a><div class="itemsShowAuthorInfo_profileStats"><strong class="itemsShowAuthorInfo_userName" itemprop="name"><a itemprop="url" href="/t-hiroyoshi">t-hiroyoshi</a></strong><div class="itemsShowAuthorInfo_contribution"><span class="itemsShowAuthorInfo_count">492</span><span class="itemsShowAuthorInfo_unit">Contribution</span></div><div id="js-react-on-rails-context" data-rails-context="{}"></div>
<div class="js-react-on-rails-component" data-component-name="UserFollowButton" data-props="{&quot;initial_followed_by&quot;:false,&quot;position&quot;:&quot;author-info&quot;,&quot;size&quot;:&quot;btn-xs&quot;,&quot;url_name&quot;:&quot;t-hiroyoshi&quot;}" data-trace="false" data-dom-id="UserFollowButton-react-component-dbd8736a-9070-4465-8fdb-86fe28f64138"></div>
    <div id="UserFollowButton-react-component-dbd8736a-9070-4465-8fdb-86fe28f64138"></div>
    
</div><section class="itemsShowAuthorPopularItems"><h5 class="itemsShowAuthorPopularItems_sectionTitle">人気の投稿</h5><ul class="itemsShowAuthorPopularItems_posts list-unstyled"><li itemscope="" itemtype="http://schema.org/Article"> <a itemprop="url" track="click" data-label="AuthorPopularItemsAtSidebar" href="/t-hiroyoshi/items/e9def50ba2c2249db04b">ディープラーニングにおける様々な物体領域検出のアプローチ方法(R-CNN)</a></li><li itemscope="" itemtype="http://schema.org/Article"> <a itemprop="url" track="click" data-label="AuthorPopularItemsAtSidebar" href="/t-hiroyoshi/items/3bba01dd11b1241f1336">DeepLearningフレームワークCaffeをCPU modeでMacにインストールする方法</a></li><li itemscope="" itemtype="http://schema.org/Article"> <a itemprop="url" track="click" data-label="AuthorPopularItemsAtSidebar" href="/t-hiroyoshi/items/137bc9b4b4b21865ba76">ReactでDrag&amp;Drop</a></li><li itemscope="" itemtype="http://schema.org/Article"> <a itemprop="url" track="click" data-label="AuthorPopularItemsAtSidebar" href="/t-hiroyoshi/items/2bf473fd06c352d97579">Caffeで手書き数字(MNIST)の認識学習をする</a></li><li itemscope="" itemtype="http://schema.org/Article"> <a itemprop="url" track="click" data-label="AuthorPopularItemsAtSidebar" href="/t-hiroyoshi/items/e556c4ca0e8631556584">Macでdeepdreamをやってみる</a></li></ul></section><section class="itemsShowAuthorInfo_organization"><h5 class="itemsShowAuthorInfo_organizationTitle">ORGANIZATION</h5><span itemprop="memberOf" itemscope="" itemtype="http://schema.org/Organization"><a itemprop="url" href="/organizations/shouldbee"><img alt="ShouldBee" class="itemsShowAuthorInfo_organizationLogo" itemprop="image" src="https://s3-ap-northeast-1.amazonaws.com/qiita-organization-image/b33de288accd2de8a446a7bd67039eb306bcb99a/original.jpg?1419476052" /></a></span><span itemprop="memberOf" itemscope="" itemtype="http://schema.org/Organization"><a itemprop="url" href="/organizations/shinonomeinc"><img alt="Shinonome, inc." class="itemsShowAuthorInfo_organizationLogo" itemprop="image" src="https://s3-ap-northeast-1.amazonaws.com/qiita-organization-image/94b7c7681ca9466387af33773359f44c04b00cb1/original.jpg?1488181031" /></a></span></section></section><div class="scroll-chaser"><div class="google-adsense"><style>.test-text-responsible { width: 200px; height: 200px; }@media(min-width: 1200px) {  .test-text-responsible { width: 250px; height: 250px; }}@media(max-width: 979px) and (min-width: 768px) {  .test-text-responsible { width: 120px; height: 240px; }}@media(max-width: 767px) {  .test-text-responsible { width: 320px; height: 50px; }}</style><script async="" src="http://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script><ins class="adsbygoogle test-text-responsible" data-ad-client="ca-pub-8127218772604357" data-ad-slot="3880091879" style="display:inline-block"></ins><script>(adsbygoogle = window.adsbygoogle || []).push({});</script></div></div><div class="js-react-on-rails-component" data-component-name="Toc" data-props="{&quot;body&quot;:&quot;\u003cul\u003e\n\u003cli\u003e\n\u003ca href=\&quot;#%E3%83%87%E3%82%A3%E3%83%BC%E3%83%97%E3%83%A9%E3%83%BC%E3%83%8B%E3%83%B3%E3%82%B0%E3%81%AB%E3%81%8A%E3%81%91%E3%82%8B%E7%89%A9%E4%BD%93%E9%A0%98%E5%9F%9F%E8%AA%8D%E8%AD%98%E3%81%AE%E5%BF%85%E8%A6%81%E6%80%A7\&quot;\u003eディープラーニングにおける物体領域認識の必要性\u003c/a\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\&quot;#objectness\&quot;\u003eObjectness\u003c/a\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\&quot;#cpmcconstrained-parametric-min-cuts\&quot;\u003eCPMC(Constrained Parametric Min-Cuts)\u003c/a\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\&quot;#selective-search\&quot;\u003eSelective Search\u003c/a\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\&quot;#object-proposals\&quot;\u003eObject Proposals\u003c/a\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\&quot;#%E3%81%BE%E3%81%A8%E3%82%81\&quot;\u003eまとめ\u003c/a\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\&quot;#%E5%8F%82%E8%80%83%E6%96%87%E7%8C%AE\&quot;\u003e参考文献\u003c/a\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n&quot;,&quot;wrapper&quot;:&quot;#article-body-wrapper&quot;}" data-trace="false" data-dom-id="Toc-react-component-1d43689e-2147-4d52-8a42-6c36cd372b75"></div>
    <div id="Toc-react-component-1d43689e-2147-4d52-8a42-6c36cd372b75"></div>
    
</div></div><div class="row"><div class="col-sm-9"><div class="ArticleFooter__menu"><div class="s-flex-align-center"><div class="js-likebutton" data-props="{&quot;like_status&quot;:false,&quot;like_count&quot;:156,&quot;show_count&quot;:true,&quot;uuid&quot;:&quot;e9def50ba2c2249db04b&quot;,&quot;likable_type&quot;:&quot;Article&quot;,&quot;position&quot;:&quot;article-footer&quot;}"></div><div class="ArticleFooter__userList"><div class="ArticleFooter__user"><div class="js-hovercard" data-hovercard-target-name="suin"><a itemprop="url" href="/suin"><img alt="suin" class="thumb thumb--xs" src="https://qiita-image-store.s3.amazonaws.com/0/889/profile-images/1473682133" /></a></div></div><div class="ArticleFooter__user"><div class="js-hovercard" data-hovercard-target-name="miseyu"><a itemprop="url" href="/miseyu"><img alt="miseyu" class="thumb thumb--xs" src="https://qiita-image-store.s3.amazonaws.com/0/5921/profile-images/1473682386" /></a></div></div><div class="ArticleFooter__user"><div class="js-hovercard" data-hovercard-target-name="mono0926"><a itemprop="url" href="/mono0926"><img alt="mono0926" class="thumb thumb--xs" src="https://qiita-image-store.s3.amazonaws.com/0/19398/profile-images/1473682701" /></a></div></div><div class="ArticleFooter__user"><div class="js-hovercard" data-hovercard-target-name="cheshire"><a itemprop="url" href="/cheshire"><img alt="cheshire" class="thumb thumb--xs" src="https://qiita-image-store.s3.amazonaws.com/0/53149/profile-images/1473692970" /></a></div></div><div class="ArticleFooter__user"><div class="js-hovercard" data-hovercard-target-name="mpyw"><a itemprop="url" href="/mpyw"><img alt="mpyw" class="thumb thumb--xs" src="https://qiita-image-store.s3.amazonaws.com/0/25060/profile-images/1473684251" /></a></div></div><div class="ArticleFooter__user"><div class="js-hovercard" data-hovercard-target-name="st450"><a itemprop="url" href="/st450"><img alt="st450" class="thumb thumb--xs" src="https://qiita-image-store.s3.amazonaws.com/0/63970/profile-images/1473696432" /></a></div></div><div class="ArticleFooter__user"><div class="js-hovercard" data-hovercard-target-name="UedaTakeyuki"><a itemprop="url" href="/UedaTakeyuki"><img alt="UedaTakeyuki" class="thumb thumb--xs" src="https://qiita-image-store.s3.amazonaws.com/0/46544/profile-images/1489714841" /></a></div></div><div class="ArticleFooter__user"><div class="js-hovercard" data-hovercard-target-name="yorksyo"><a itemprop="url" href="/yorksyo"><img alt="yorksyo" class="thumb thumb--xs" src="https://qiita-image-store.s3.amazonaws.com/0/44317/profile-images/1473689856" /></a></div></div><div class="ArticleFooter__user"><div class="js-hovercard" data-hovercard-target-name="mero"><a itemprop="url" href="/mero"><img alt="mero" class="thumb thumb--xs" src="https://qiita-image-store.s3.amazonaws.com/0/63104/profile-images/1473696161" /></a></div></div><div class="ArticleFooter__user"><div class="js-hovercard" data-hovercard-target-name="trkbt10"><a itemprop="url" href="/trkbt10"><img alt="trkbt10" class="thumb thumb--xs" src="https://qiita-image-store.s3.amazonaws.com/0/74461/profile-images/1473699844" /></a></div></div><div class="ArticleFooter__user"><a href="/t-hiroyoshi/items/e9def50ba2c2249db04b/likers"><span class="fa fa-ellipsis-h"></span></a></div></div></div><div class="u-flex u-align-center"><div class="ArticleFooter__stock"><div class="js-stockbutton" data-position="footer_menu" data-props="{&quot;stock_status&quot;:false}"></div></div><div class="ArticleFooter__editRequest"><a class="u-link-no-underline" data-toggle="tooltip" title="You can propose improvements about the article to the author 💪" href="/drafts/e9def50ba2c2249db04b/edit"><span class="fa fa-send-o fa-lg"></span> <span>Edit request</span></a></div><div class="dropdown ArticleFooter__dropdown"><a class="dropdown-toggle" data-toggle="dropdown" href="#"><span class="fa fa-ellipsis-h"></span></a><ul class="dropdown-menu dropdown-menu-right"><li><a href="/t-hiroyoshi/items/e9def50ba2c2249db04b.md"><span class="fa fa-fw fa-file-text-o"></span> Show article as Markdown</a></li><li><a data-target=".js-report-form" data-toggle="modal" href="#"><i class="fa fa-fw fa-flag"></i> Report article</a></li></ul></div></div></div><ul class="references js-referencesView"><li class="references_header"><i class="fa fa-fw fa-link"></i> Linked from these articles</li><li class="references_reference js-reference"><span>Linked from </span><a href="/Almond/items/ad56ce29112d6397a704#_reference-3e77a74e6dccb7ba5d31"><img alt="" width="18" height="18" src="https://qiita-image-store.s3.amazonaws.com/0/99765/profile-images/1473707887" />CNNの前処理としてOpenCVでBINGを使ってみた</a><time class="references_datetime js-dateTimeView" datetime="2015-11-09T02:48:39+00:00">over 1 year ago</time></li></ul><div class="itemsShowBody_articleColumnFooter"><div class="socialButtons"><div class="socialButtons_twitter"><a class="twitter-share-button" data-text="ディープラーニングにおける様々な物体領域検出のアプローチ方法(R-CNN) by @t_hiroyoshi on @Qiita" data-url="http://qiita.com/t-hiroyoshi/items/e9def50ba2c2249db04b" href="https://twitter.com/share">Tweet</a></div><div class="socialButtons_hatebu"><a class="hatena-bookmark-button" data-hatena-bookmark-layout="simple-balloon" data-hatena-bookmark-title="ディープラーニングにおける様々な物体領域検出のアプローチ方法(R-CNN)" href="http://b.hatena.ne.jp/entry/http://qiita.com/t-hiroyoshi/items/e9def50ba2c2249db04b" title="Add to Hatena Bookmark"><img alt="Add to Hatena Bookmark" height="20" src="https://b.st-hatena.com/images/entry-button/button-only@2x.png" style="border: none;" width="20" /></a><script async="async" charset="utf-8" src="https://b.st-hatena.com/js/bookmark_button.js" type="text/javascript"></script></div><div class="socialButtons_googlePlus"><div class="g-plusone" data-href="http://qiita.com/t-hiroyoshi/items/e9def50ba2c2249db04b" data-size="medium"></div></div><div class="socialButtons_facebook"><div class="fb-like" data-action="like" data-href="http://qiita.com/t-hiroyoshi/items/e9def50ba2c2249db04b" data-layout="button_count" data-share="false" data-show-faces="false"></div></div><div class="socialButtons_pocket"><a class="pocket-btn" data-lang="en" data-pocket-count="horizontal" data-pocket-label="pocket"></a></div></div></div><div class="itemsShowComment_wrapper" id="comments"><div class="js-react-on-rails-component" data-component-name="CommentListContainer" data-props="{&quot;currentUser&quot;:null,&quot;initialComments&quot;:[{&quot;banned&quot;:false,&quot;body&quot;:&quot;\u003cp\u003eCPMCのVisualStudio2012(C++)で実行できるコードを探しているのですがご存じでしょうか？\u003c/p\u003e\n&quot;,&quot;created_at&quot;:&quot;2016-08-05T15:39:43+09:00&quot;,&quot;expanded_references&quot;:&quot;&quot;,&quot;id&quot;:608236,&quot;is_team&quot;:false,&quot;item_id&quot;:314620,&quot;item_type&quot;:&quot;PublicDomainArticle&quot;,&quot;item_uuid&quot;:&quot;e9def50ba2c2249db04b&quot;,&quot;likable&quot;:false,&quot;liked&quot;:false,&quot;public_likes_count&quot;:0,&quot;raw_body&quot;:&quot;CPMCのVisualStudio2012(C++)で実行できるコードを探しているのですがご存じでしょうか？\n&quot;,&quot;reaction_types&quot;:[{&quot;image_url&quot;:&quot;https://cdn.qiita.com/emoji/twemoji/unicode/1f44d.png&quot;,&quot;name&quot;:&quot;+1&quot;},{&quot;image_url&quot;:&quot;https://cdn.qiita.com/emoji/twemoji/unicode/1f64f.png&quot;,&quot;name&quot;:&quot;pray&quot;},{&quot;image_url&quot;:&quot;https://cdn.qiita.com/emoji/twemoji/unicode/1f389.png&quot;,&quot;name&quot;:&quot;tada&quot;},{&quot;image_url&quot;:&quot;https://cdn.qiita.com/emoji/twemoji/unicode/1f647.png&quot;,&quot;name&quot;:&quot;bow&quot;},{&quot;image_url&quot;:&quot;https://cdn.qiita.com/emoji/twemoji/unicode/1f631.png&quot;,&quot;name&quot;:&quot;scream&quot;},{&quot;image_url&quot;:&quot;https://cdn.qiita.com/emoji/twemoji/unicode/1f440.png&quot;,&quot;name&quot;:&quot;eyes&quot;}],&quot;reactions&quot;:[],&quot;team&quot;:null,&quot;team_membership&quot;:null,&quot;updatable&quot;:false,&quot;url&quot;:&quot;http://qiita.com/t-hiroyoshi/items/e9def50ba2c2249db04b#comment-0574e084a542ea002ae1&quot;,&quot;user&quot;:{&quot;contribution&quot;:0,&quot;created_at&quot;:&quot;2016-07-27T17:35:37+09:00&quot;,&quot;id&quot;:135147,&quot;is_admin&quot;:false,&quot;profile_image_url&quot;:&quot;https://qiita-image-store.s3.amazonaws.com/0/135147/profile-images/1473764391&quot;,&quot;suspended&quot;:false,&quot;url_name&quot;:&quot;sacrifiseescape&quot;},&quot;uuid&quot;:&quot;0574e084a542ea002ae1&quot;,&quot;via_email&quot;:false}],&quot;monthly_public_image_uploadable_size_limit&quot;:null,&quot;total_uploaded_public_image_size_in_current_month&quot;:null,&quot;item&quot;:{&quot;id&quot;:314620,&quot;uuid&quot;:&quot;e9def50ba2c2249db04b&quot;,&quot;suspended&quot;:false,&quot;secret&quot;:false},&quot;owner&quot;:{&quot;url_name&quot;:&quot;t-hiroyoshi&quot;},&quot;is_team&quot;:false,&quot;is_project&quot;:false,&quot;logged_in&quot;:false,&quot;polling&quot;:false,&quot;mention_candidates&quot;:[{&quot;id&quot;:72314,&quot;url_name&quot;:&quot;t-hiroyoshi&quot;,&quot;profile_image_url&quot;:&quot;https://qiita-image-store.s3.amazonaws.com/0/72314/profile-images/1473699117&quot;},{&quot;id&quot;:135147,&quot;url_name&quot;:&quot;sacrifiseescape&quot;,&quot;profile_image_url&quot;:&quot;https://qiita-image-store.s3.amazonaws.com/0/135147/profile-images/1473764391&quot;}]}" data-trace="false" data-dom-id="CommentListContainer-react-component-ccd2e81f-e880-411f-8d75-e94a8528832a"></div>
    <div id="CommentListContainer-react-component-ccd2e81f-e880-411f-8d75-e94a8528832a"></div>
    
</div></div></div></div></article><div class="js-report-form modal fade reportForm"><div class="modal-dialog"><div class="modal-content"><div class="modal-header"><button name="button" type="submit" class="close" data-dismiss="modal">&times;</button><h4 class="modal-title">Report article</h4></div><div class="modal-body"><form action="/reports" accept-charset="UTF-8" method="post"><input name="utf8" type="hidden" value="&#x2713;" /><input type="hidden" name="authenticity_token" value="nSMl7qId0LV6A2k+40wE9wPC00m2Loe/notFu5biJojppINKnhtVABgIhgbtnhTGzb8MI1Wai4b8GPWxDzfrHA==" /><input type="hidden" name="redirect_path" id="redirect_path" value="/t-hiroyoshi/items/e9def50ba2c2249db04b" /><input type="hidden" name="item_uuid" id="item_uuid" value="e9def50ba2c2249db04b" /><p>Help us understand the problem. What is going on with this item?</p><br /><div class="form-group"><ul class="list-unstyled"><li><label><input type="radio" name="report_type" id="report_type_spam" value="spam" required="required" /> It&#39;s spam </label></li><li><label><input type="radio" name="report_type" id="report_type_harassment" value="harassment" required="required" /> It&#39;s abusive or harmful </label></li><li><label><input type="radio" name="report_type" id="report_type_inappropriate_content" value="inappropriate_content" required="required" /> It contains inappropriate content </label></li></ul></div><div class="reportForm_submitButtonContainer"><button name="button" type="submit" class="btn btn-primary reportForm_submitButton"><i class="fa fa-send"></i> Submit</button></div></form></div></div></div></div><script id="js-item" type="application/json">{ "url": "http://qiita.com/t-hiroyoshi/items/e9def50ba2c2249db04b", "id": 314620, "uuid": "e9def50ba2c2249db04b" }</script><script class="js-user" type="application/json">{&quot;id&quot;:72314,&quot;url_name&quot;:&quot;t-hiroyoshi&quot;,&quot;profile_image_url&quot;:&quot;https://qiita-image-store.s3.amazonaws.com/0/72314/profile-images/1473699117&quot;}</script><script language="JavaScript" src="//cdn.bigmining.com/private/js/qiita_bigmining.js" type="text/javascript"></script></div><footer class="footer"><div class="footer_inner"><div class="footer_container"><ul class="footer_links-left"><li class="footer_link"><a class="footer_copyright" href="http://increments.co.jp">© 2011-2017 Increments Inc.</a></li><li class="footer_link"><a href="http://qiita.com/terms">Terms</a></li><li class="footer_link"><a href="http://qiita.com/privacy">Privacy</a></li><li class="footer_link"><a href="http://help.qiita.com">Help</a></li><li class="footer_link"><a href="https://increments.zendesk.com/anonymous_requests/new">Contact</a></li></ul><ul class="footer_links-right"><li class="footer_link"><a href="http://qiita.com/about">About</a></li><li class="footer_link"><a href="/users">Users</a></li><li class="footer_link"><a href="/tags">Tags</a></li><li class="footer_link"><a href="http://blog.qiita.com">Blog</a></li><li class="footer_link"><a href="http://qiita.com/api/v2/docs">API</a></li><li class="footer_link"><a href="https://teams.qiita.com/">Team</a></li><li class="footer_link"><a href="http://kobito.qiita.com">Kobito</a></li><li class="footer_link"><a class="js-public-form-feedback-link" data-target=".js-feedback-form" data-toggle="modal" href=""><i class="fa fa-heart"></i> Feedback <i class="fa fa-caret-down"></i></a></li></ul></div></div></footer><div class="js-feedback-form modal fade feedbackForm"><div class="modal-dialog"><div class="modal-content"><div class="modal-header"><button name="button" type="submit" class="close" data-dismiss="modal">&times;</button><h4 class="modal-title">Feedback</h4></div><div class="modal-body"><form class="js-feedback-form-form" action="/feedbacks" accept-charset="UTF-8" method="post"><input name="utf8" type="hidden" value="&#x2713;" /><input type="hidden" name="authenticity_token" value="Y/UQavP7MU0a9XVfSwJ5ZlKcl6UOYP5wnrL4ncVtUJkXcrbOz/20+Hj+mmdF0GlXnOFIz+3U8kn8IUiXXLidDQ==" /><input type="hidden" name="redirect_path" id="redirect_path" value="/t-hiroyoshi/items/e9def50ba2c2249db04b" /><div class="form-group"><textarea name="feedback[message]" id="feedback_message" class="form-control js-feedback-form-text-area" placeholder="Please give us any feedback about Qiita." required="required" rows="5">
</textarea></div><div class="feedbackForm_submitButtonContainer"><button name="button" type="submit" class="btn btn-primary feedbackForm_submitButton"><i class="fa fa-send"></i> Submit</button><p class="feedbackForm_note">We don&#39;t reply to any feedback.<br />If you need help with Qiita, please send a support request from <a href="https://increments.zendesk.com/anonymous_requests/new">here</a>.</p></div><div style="position:fixed;top:-99999px;opacity:0.0001;"><input name="feedback[name]" type="text" /></div></form></div></div></div></div><script>// if (window.mixpanel instanceof Element) {
//   window.mixpanel = [];
// }
// (function(f,b){if(!b.__SV){var a,e,i,g;window.mixpanel=b;b._i=[];b.init=function(a,e,d){function f(b,h){var a=h.split(".");2==a.length&&(b=b[a[0]],h=a[1]);b[h]=function(){b.push([h].concat(Array.prototype.slice.call(arguments,0)))}}var c=b;"undefined"!==typeof d?c=b[d]=[]:d="mixpanel";c.people=c.people||[];c.toString=function(b){var a="mixpanel";"mixpanel"!==d&&(a+="."+d);b||(a+=" (stub)");return a};c.people.toString=function(){return c.toString(1)+".people (stub)"};i="disable track track_pageview track_links track_forms register register_once alias unregister identify name_tag set_config people.set people.set_once people.increment people.append people.track_charge people.clear_charges people.delete_user".split(" ");
// for(g=0;g<i.length;g++)f(c,i[g]);b._i.push([a,e,d])};b.__SV=1.2;a=f.createElement("script");a.type="text/javascript";a.async=!0;a.src="//cdn.mxpnl.com/libs/mixpanel-2.2.min.js";e=f.getElementsByTagName("script")[0];e.parentNode.insertBefore(a,e)}})(document,window.mixpanel||[]);</script><script src="http://cdn.qiita.com/assets/public-3af9c1d29a49f3320bb796fb5e75304b.min.js"></script><script>
  (function () {
    var script = document.getElementsByTagName('script')[0];
    var load = function (src, id) {
      var el = document.createElement('script');
      el.async = true;
      el.src = src;
      el.id = id;
      script.parentNode.insertBefore(el, script);
    };
      // Optimizely
      load('//cdn.optimizely.com/js/52738645.js', 'optimizely-jssdk');
      // Google Analytics
      window._gaq = window._gaq || [];
      var isCareer = location.hostname.split('.')[0] == 'career';
      if (isCareer) {
        window._gaq.push(['_setAccount', 'UA-24675221-11']);
        window._gaq.push(['_setDomainName', 'qiita.com']);
      } else {
        window._gaq.push(['_setAccount', 'UA-24675221-1']);
      }
      window._gaq.push(['_setCustomVar', 1, 'logged_in', 'false', 2]);
      window._gaq.push(['_trackPageview']);
      var src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
      load(src, 'google-analytics-jssdk');
    // Google Analytics - Universal Analytics
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
    (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
    m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','//www.google-analytics.com/analytics.js','ga');
        ga('create', 'UA-24675221-12', {
          
        });
          ga('create', 'UA-69878701-2', { name: 'user' });
          ga('user.send', 'pageview');
        ga('set', 'dimension1', 'false');
        ga('set', 'dimension3', 'false');
      ga('require', 'displayfeatures');
      ga('set', 'forceSSL', true);
      ga('send', 'pageview');
    // Google Tag Manager
      (function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
      new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
      j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
      '//www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
      })(window,document,'script','dataLayer','GTM-TBQWPN');
  })();
</script>
</body></html>