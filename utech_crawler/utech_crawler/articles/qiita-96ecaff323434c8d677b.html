<!DOCTYPE html><html xmlns:og="http://ogp.me/ns#"><head><meta charset="UTF-8" /><title>Chainerで始めるニューラルネットワーク - Qiita</title><meta content="width=device-width,initial-scale=1" name="viewport" /><meta content="Chainerは、Preferred Networksが開発したニューラルネットワークを実装するためのライブラリです。その特徴としては、以下のような点があります(ホームページより)。


高速: CUDAをサポートし、GPUを利用した高速な計算が可能
柔軟: 柔軟な記法により、畳み込み、リカレントなど、様々なタイプのニューラルネットを実装可能
直観的: ネットワーク構成を直観的に記述できる


個人的には、さらに一つ「インストールが簡単」というのも挙げたいと思います。
..." name="description" /><meta content="summary" name="twitter:card" /><meta content="@Qiita" name="twitter:site" /><meta content="icoxfog417" name="twitter:creator" /><meta content="Chainerで始めるニューラルネットワーク - Qiita" property="og:title" /><meta content="article" property="og:type" /><meta content="http://qiita.com/icoxfog417/items/96ecaff323434c8d677b" property="og:url" /><meta content="http://cdn.qiita.com/assets/qiita-fb-2887e7b4aad86fd8c25cea84846f2236.png" property="og:image" /><meta content="[Chainer](http://chainer.org/)は、Preferred Networksが開発したニューラルネットワークを実装するためのライブラリです。その特徴としては、以下のような点があります(ホームページより)。

*..." property="og:description" /><meta content="Qiita" property="og:site_name" /><meta content="564524038" property="fb:admins" /><link rel="shortcut icon" type="image/x-icon" href="http://cdn.qiita.com/assets/favicons/public/production-4ff10c1e1e2b5fcb353ff9cafdd56c70.ico" /><link rel="apple-touch-icon" type="image/png" href="http://cdn.qiita.com/assets/favicons/public/apple-touch-icon-f9a6afad761ec2306e10db2736187c8b.png" /><link href="/opensearch.xml" rel="search" title="Qiita" type="application/opensearchdescription+xml" /><link rel="stylesheet" media="all" href="http://cdn.qiita.com/assets/public-81dd63f4385f99b52aeab91266068ebd.min.css" /><meta name="csrf-param" content="authenticity_token" />
<meta name="csrf-token" content="sKcIfGj0h2pceBdaTUpLAbi8d6p6pzQJL3ZyB/GEHL2nwOzLlris/C8Ak2BwPKa7dg68lECkWh3sy7vg/xZK+A==" /></head><body class="without-js" id=""><noscript><iframe height="0" src="//www.googletagmanager.com/ns.html?id=GTM-TBQWPN" style="display:none;visibility:hidden" width="0"></iframe></noscript><script>
  document.body.className = document.body.className.replace('without-js', '') + ' with-js';
  window.Qiita = {"asset_host":"cdn.qiita.com","TLD":"com","controller_path":"public/items","controller_action":"public/items#show","controller":"items","action":"show","action_path":"public/items#show","env":"production","flash":{},"is_landing_page":false,"is_team_page":false,"request_parameters":{"controller":"public/items","action":"show","user_id":"icoxfog417","type":"items","id":"96ecaff323434c8d677b"},"root_domain":"qiita.com","variant":null,"config":{"mixpanel":{"career":"dd35af27e959781713d63fd7ca898a8d","per_team":"c0a2116368b33b44b5029ebd2cc9b094","public":"be87616606b0e26a87689099aab2c4e5","team":"b7c0342acba2dbc8742484d98788efb3"},"default_locale":"ja","locale":"en"},"team":null,"user":null,"GIT_BRANCH":null,"DEBUG":false};

</script>
<div class="headerContainer headerContainer-public" role="navigation"><div class="js-react-on-rails-component" data-component-name="HeaderContainer" data-props="{&quot;user&quot;:null,&quot;team&quot;:null,&quot;news&quot;:{&quot;type&quot;:&quot;Hot&quot;,&quot;content&quot;:&quot;Markdownによる情報共有サービス、Qiita:Team&quot;,&quot;url&quot;:&quot;https://teams.qiita.com?utm_source=qiita\u0026utm_medium=header_news&quot;},&quot;initial_unread_count&quot;:null,&quot;siteid_image&quot;:&quot;http://cdn.qiita.com/siteid-reverse.png&quot;,&quot;is_team_page&quot;:false,&quot;on_team_setting&quot;:false,&quot;show_post_menu&quot;:true,&quot;show_search_menu&quot;:true,&quot;is_fluid&quot;:false,&quot;locale&quot;:&quot;en&quot;}" data-trace="false" data-dom-id="HeaderContainer-react-component-aa41585f-0baf-42d3-8a7c-f121b944b739"></div>
    <div id="HeaderContainer-react-component-aa41585f-0baf-42d3-8a7c-f121b944b739"></div>
    
</div><div id="main"><script type="application/ld+json">{  "@context": "http://schema.org",  "@type": "BreadcrumbList",  "itemListElement": [    {      "@type": "ListItem",      "position": 1,      "item": {        "@id": "/",        "name": "Qiita"      }    },    {      "@type": "ListItem",      "position": 2,      "item": {        "@id": "/items",        "name": "Items"      }    },    {      "@type": "ListItem",      "position": 3,      "item": {        "@id": "/tags/%E6%A9%9F%E6%A2%B0%E5%AD%A6%E7%BF%92",        "name": "機械学習"      }    }  ]}</script><article itemscope="" itemtype="http://schema.org/Article"><div class="ArticleMainHeader "><div class="container"></div><div class="container"><div class="row s-flex-align-center"><div class="col-sm-9"><h1 class="ArticleMainHeader__title" itemprop="headline">Chainerで始めるニューラルネットワーク</h1><ul class="TagList"><li class="TagList__item" data-count="1835"><a class="u-link-unstyled TagList__label" href="/tags/%E6%A9%9F%E6%A2%B0%E5%AD%A6%E7%BF%92"><img alt="機械学習" class="TagList__icon" src="https://s3-ap-northeast-1.amazonaws.com/qiita-tag-image/a94d4d239b3b0b83723d5b56c050ffc54b8593e7/medium.jpg?1394635775" /><span>機械学習</span></a></li><li class="TagList__item" data-count="358"><a class="u-link-unstyled TagList__label" href="/tags/Chainer"><img alt="Chainer" class="TagList__icon" src="https://s3-ap-northeast-1.amazonaws.com/qiita-tag-image/755fdcf477b1d3db5946dad4f779ba11a5954c18/medium.jpg?1434432587" /><span>Chainer</span></a></li><li class="TagList__item" data-count="9910"><a class="u-link-unstyled TagList__label" href="/tags/Python"><img alt="Python" class="TagList__icon" src="https://s3-ap-northeast-1.amazonaws.com/qiita-tag-image/28fd3d6b220c89e6197fd82c02fd2fcd2bb66d81/medium.jpg?1383884245" /><span>Python</span></a></li></ul></div><div class="col-sm-3"><div class="itemsShowHeaderStock"><ul class="list-unstyled itemsShowHeaderStock_statusList"><li><div class="itemsShowHeaderStock_count stock"><span class="fa fa-thumbs-up"></span><span class="js-likecount">397</span></div><div class="itemsShowHeaderStock_countText">Like</div></li><li><div class="itemsShowHeaderStock_count" content="0 UserComments" itemprop="commentCount"><span class="fa fa-comment"></span>0</div><div class="itemsShowHeaderStock_countText">Comment</div></li></ul></div><div class="js-likebutton" data-props="{&quot;like_status&quot;:false,&quot;like_count&quot;:397,&quot;uuid&quot;:&quot;96ecaff323434c8d677b&quot;,&quot;likable_type&quot;:&quot;Article&quot;,&quot;position&quot;:&quot;article-header&quot;}"></div><ul class="list-inline ArticleMainHeader__users"><li class="js-hovercard" data-hovercard-target-name="shogiai"><a itemprop="url" href="/shogiai"><img alt="shogiai" class="thumb thumb--xs" src="https://qiita-image-store.s3.amazonaws.com/0/86977/profile-images/1473703926" /></a></li><li class="js-hovercard" data-hovercard-target-name="metheglin"><a itemprop="url" href="/metheglin"><img alt="metheglin" class="thumb thumb--xs" src="https://qiita-image-store.s3.amazonaws.com/0/36978/profile-images/1473687266" /></a></li><li class="js-hovercard" data-hovercard-target-name="nmby"><a itemprop="url" href="/nmby"><img alt="nmby" class="thumb thumb--xs" src="https://qiita-image-store.s3.amazonaws.com/0/84939/profile-images/1473703265" /></a></li><li class="js-hovercard" data-hovercard-target-name="TomokIshii"><a itemprop="url" href="/TomokIshii"><img alt="TomokIshii" class="thumb thumb--xs" src="https://qiita-image-store.s3.amazonaws.com/0/74152/profile-images/1473699746" /></a></li><li class="js-hovercard" data-hovercard-target-name="leon_AKQJT"><a itemprop="url" href="/leon_AKQJT"><img alt="leon_AKQJT" class="thumb thumb--xs" src="https://qiita-image-store.s3.amazonaws.com/0/35340/profile-images/1473686685" /></a></li><li class="js-hovercard" data-hovercard-target-name="TakesxiSximada"><a itemprop="url" href="/TakesxiSximada"><img alt="TakesxiSximada" class="thumb thumb--xs" src="https://qiita-image-store.s3.amazonaws.com/0/36261/profile-images/1473687011" /></a></li><li class="js-hovercard" data-hovercard-target-name="Tomatio13"><a itemprop="url" href="/Tomatio13"><img alt="Tomatio13" class="thumb thumb--xs" src="https://qiita-image-store.s3.amazonaws.com/0/75580/profile-images/1473700200" /></a></li><li class="js-hovercard" data-hovercard-target-name="bighope"><a itemprop="url" href="/bighope"><img alt="bighope" class="thumb thumb--xs" src="https://qiita-image-store.s3.amazonaws.com/0/83472/profile-images/1473702787" /></a></li><li class="js-hovercard" data-hovercard-target-name="TD72"><a itemprop="url" href="/TD72"><img alt="TD72" class="thumb thumb--xs" src="https://qiita-image-store.s3.amazonaws.com/0/76769/profile-images/1473700600" /></a></li><li class="js-hovercard" data-hovercard-target-name="azihsoyn"><a itemprop="url" href="/azihsoyn"><img alt="azihsoyn" class="thumb thumb--xs" src="https://qiita-image-store.s3.amazonaws.com/0/14577/profile-images/1477545988" /></a></li><li><a href="/icoxfog417/items/96ecaff323434c8d677b/likers"><span class="fa fa-ellipsis-h"></span></a></li></ul></div></div></div></div><div class="ArticleAsideHeader"><div class="container"><div class="u-flex u-space-between"><div class="u-flex u-flex-wrap"><div class="u-flex u-align-center s-pdv-5 u-flex-wrap"><div class="ArticleAsideHeader__author"><a href="/icoxfog417"><img class="thumb thumb--xs" src="https://qiita-image-store.s3.amazonaws.com/0/25990/profile-images/1484303516" alt="1484303516" /></a> <a class="u-link-unstyled" href="/icoxfog417">icoxfog417</a> </div><div class="ArticleAsideHeader__date"><meta content="2015-09-24T15:48:58+09:00" itemprop="datePublished" /><span data-toggle="tooltip" title="posted at 2015-09-24">Edited at <time datetime="2016-08-29T17:06:56+09:00" itemprop="dateModified">2016-08-29</time></span></div></div><div class="u-flex u-align-center s-pdv-5 mobile-hidden"><div class="ArticleAsideHeader__revision"> <a data-toggle="tooltip" title="Revisions" href="/icoxfog417/items/96ecaff323434c8d677b/revisions"><span class="fa fa-history"></span></a><span class="ArticleAsideHeader__revisionCount">7</span></div></div><div class="u-flex u-align-center s-pdv-5 mobile-hidden"></div></div><div class="u-flex u-align-center s-flex-justiry-between s-pdv-5 u-shrink-0"><div class="ArticleAsideHeader__stock"><div class="js-stockbutton" data-position="top" data-props="{&quot;stock_status&quot;:false}"></div></div><div class="dropdown"><a class="dropdown-toggle" data-toggle="dropdown" href="#"><span class="fa fa-ellipsis-h fa-lg"></span></a><ul class="dropdown-menu dropdown-menu-right"><li class="dropdown__item--mobile"><a href="/icoxfog417/items/96ecaff323434c8d677b/revisions"><span class="fa fa-fw fa-history"></span> Revisions<span>(7)</span></a></li><li><a href="/icoxfog417/items/96ecaff323434c8d677b.md"><span class="fa fa-fw fa-file-text-o"></span> Show article as Markdown</a></li><li><a data-target=".js-report-form" data-toggle="modal" href="#"><span class="fa fa-fw fa-flag"></span> Report article</a></li></ul></div></div></div></div></div><div class="container"><div class="row" id="article-body-wrapper"><div class="col-sm-9"><section class="markdownContent markdownContent-headingEnabled js-task-list-container clearfix position-relative" id="item-96ecaff323434c8d677b" itemprop="articleBody"><p><a href="http://chainer.org/" rel="nofollow noopener" target="_blank">Chainer</a>は、Preferred Networksが開発したニューラルネットワークを実装するためのライブラリです。その特徴としては、以下のような点があります(ホームページより)。</p>

<ul>
<li>高速: CUDAをサポートし、GPUを利用した高速な計算が可能</li>
<li>柔軟: 柔軟な記法により、畳み込み、リカレントなど、様々なタイプのニューラルネットを実装可能</li>
<li>直観的: ネットワーク構成を直観的に記述できる</li>
</ul>

<p>個人的には、さらに一つ「インストールが簡単」というのも挙げたいと思います。<br>
ディープラーニング系のフレームワークはどれもインストールが面倒なものが多いのですが、Chainerは依存ライブラリが少なく簡単に導入・・・できたんですが、1.5.0からCythonを使うようになりちょっと手間になりました。インストール方法については以下をご参照ください。</p>

<ul>
<li><a href="http://qiita.com/unnonouno/items/b1fd299b90dd7e134217" id="reference-d23e3d205246fa29e423">Mac</a></li>
<li><a href="http://qiita.com/icoxfog417/items/ca1521f9d62183cea234" id="reference-4ed506329af96f0bf590">Windows</a></li>
<li><a href="http://qiita.com/unnonouno/items/8d8118bb38a589f7dbfa" id="reference-a98590f3a5237b602146">AWS</a></li>
<li><a href="https://github.com/pfnet/chainer#installation" rel="nofollow noopener" target="_blank">公式インストール情報</a></li>
</ul>

<p>また、Chainerは上記の通り記法が直観的かつシンプルなので、単純なネットワークからより複雑な、いわゆるディープラーニングと呼ばれる領域まで幅広くカバーできます。他のディープラーニング系のライブラリはディープでない場合完全にオーバースペックですし、かといってシンプルなライブラリ(PyBrainなど)ではディープだと厳しい、という状況だったので、この点もメリットとして大きいと思います。</p>

<p>今回はそんな魅力的なChainerの使い方について解説しますが、Chainerを扱うには(割と深い)ニューラルネットワークに関する知識が必要不可欠です。そのため、ニューラルネット側の知識が不十分だとはまることがままあります(私ははまりました)。</p>

<p>よって、ここではまずニューラルネットワークの仕組みについてざっと説明し、後の段でそれをどうChainerで実装するのかついて解説していきたいと思います。</p>

<h1>
<span id="ニューラルネットワークの仕組み" class="fragment"></span><a href="#%E3%83%8B%E3%83%A5%E3%83%BC%E3%83%A9%E3%83%AB%E3%83%8D%E3%83%83%E3%83%88%E3%83%AF%E3%83%BC%E3%82%AF%E3%81%AE%E4%BB%95%E7%B5%84%E3%81%BF"><i class="fa fa-link"></i></a>ニューラルネットワークの仕組み</h1>

<h2>
<span id="構成" class="fragment"></span><a href="#%E6%A7%8B%E6%88%90"><i class="fa fa-link"></i></a>構成</h2>

<p>ニューラルネットワークの構成は、以下のようになっています(余談ですが、ノード間の線を引くのが毎回面倒でなりません)。</p>

<p><a href="https://qiita-image-store.s3.amazonaws.com/0/25990/7d32cf08-bd25-8bcb-592c-48ca2f432f89.png" target="_blank" rel="nofollow noopener"><img src="https://qiita-image-store.s3.amazonaws.com/0/25990/7d32cf08-bd25-8bcb-592c-48ca2f432f89.png" alt="image"></a></p>

<ul>
<li>ニューラルネットワークは、入力を受け取るinput層、出力を行うoutput層、その間の任意の数の隠れ層(hidden)から構成されます。上図では、隠れ層は1層になります。</li>
<li>各層には、任意の数のノードが存在します。このノードは、実体としては入力を受け取り値を出力する単なる関数です(後述します)。</li>
<li>入力に際しては、実際の入力とは別に独立した値を入れることがあります。これをバイアス(bias)ノードと呼びます(図中の灰色のノードで、通常値は1です。$ax+b$における$b$(切片)のようなものです)。</li>
</ul>

<h2>
<span id="伝播" class="fragment"></span><a href="#%E4%BC%9D%E6%92%AD"><i class="fa fa-link"></i></a>伝播</h2>

<p>inputからの入力がどのようにoutputまでたどり着くのか、詳しく見ていきます。<br>
下図は、隠れ層の第一ノードにinputからの入力が行われる様子を見やすくしたものです。</p>

<p><a href="https://qiita-image-store.s3.amazonaws.com/0/25990/5b092673-9046-1d95-4ef6-7a7727e32789.png" target="_blank" rel="nofollow noopener"><img src="https://qiita-image-store.s3.amazonaws.com/0/25990/5b092673-9046-1d95-4ef6-7a7727e32789.png" alt="image"></a></p>

<p>4つのinputが伝わっているのがわかります。inputはそのまま直に伝わるのでなく、重みがかけられます。<br>
ニューラルネットワークは脳の中のニューロンの構成をまねたものですが、これと同様入力(刺激)が伝播する際、弱められたり強められたりするものだと思ってください。数式的に表現すれば、入力が$x$だとしたら、$ax$という感じで$a$という重みが掛けられます。</p>

<p><a href="https://qiita-image-store.s3.amazonaws.com/0/25990/0cd8db7e-8b8c-550d-3fdd-a968df9cbda8.png" target="_blank" rel="nofollow noopener"><img src="https://qiita-image-store.s3.amazonaws.com/0/25990/0cd8db7e-8b8c-550d-3fdd-a968df9cbda8.png" alt="image"></a></p>

<p>さて、ここで<code>ax</code>という入力を受け取ったわけですが、ノードは受け取ったこの値をそのまま次の層に横流しするわけではありません。<br>
脳の中ではある閾値を超えた入力でないと次の層には伝播させないという仕組みがあるそうで、ここでもそれを真似て、受け取った入力を次層への出力へ変換します。数式的に表現すれば、入力を次層への出力に変換する関数を$h$とし、その出力値は$h(ax)$で表現できます。この関数$h$を、活性化関数と呼びます。</p>

<p>まとめると、ニューラルネットワークにおける値の伝播にとって重要な要素は、以下二点になります。</p>

<ul>
<li>重み(weight): 入力された値がどれくらい強化/減衰されるかを決定する</li>
<li>活性関数(activation function): 受け取った値を、どのように次の層へ渡すか</li>
</ul>

<p>端的に見れば、ニューラルネットワークは受け取った入力に対して重みをかけて出力しているに過ぎません。そのため、一層のニューラルネットワークは線形回帰やロジスティック回帰とほぼ同義になります。</p>

<p>そう考えると、ノード数、層数の操作がどのような意味を持つのかが明確になってきます。</p>

<ul>
<li>ノード数を増やす: 扱う変数を増やし、多数の要素を加味して値/境界を決定できるようにする</li>
<li>層数: 直線境界をどんどん組み合わせていき、複雑な境界を表現できるようにする(一層は線形、二層は凸領域、三層は凸領域の中に穴が開いたような領域・・・とどんどん複雑になる。<a href="http://qiita.com/icoxfog417/items/e574a9d61f9f680d578b" id="reference-5d02dd82d42a48cacc7c">はじめてのパターン認識 第7章 パーセプトロン型学習規則</a>参照)</li>
</ul>

<p>ニューラルネットワークを扱う場合、適当にノード数や層数をガチャガチャしてしまうこともあるかと思いますが、しっかりデータをプロットし適切なノード数・層数にあたりをつけることも肝要です。</p>

<h2>
<span id="学習" class="fragment"></span><a href="#%E5%AD%A6%E7%BF%92"><i class="fa fa-link"></i></a>学習</h2>

<p>ニューラルネットワークを学習させるためには、誤差逆伝播法(Backpropagation)という手法を用います。<br>
誤差とはニューラルネットワークから出力した値と、実際の値との間の差異になります。Backpropagationは、この誤差をその名の通り後ろ(出力層=output層)から伝播させていき、各層の重みを調整するという手法です。</p>

<p><a href="https://qiita-image-store.s3.amazonaws.com/0/25990/9d4d5518-97c7-b83e-7536-2044f6ec1d02.png" target="_blank" rel="nofollow noopener"><img src="https://qiita-image-store.s3.amazonaws.com/0/25990/9d4d5518-97c7-b83e-7536-2044f6ec1d02.png" alt="image"></a></p>

<p>Backpropagationの詳細は他に様々な説明があるためここでは深入りしませんが、重要な点は以下2点になります。</p>

<ul>
<li>誤差の計算方法(cost/loss function): ニューラルネットワークから出力した値と、正解データの間の誤差をどのように計算するか</li>
<li>重みを調整する方法(optimizer): 計算された誤差をもって、どのように重みを調整していくのかを決定します</li>
</ul>

<p>なお、どれくらいの学習データを利用して上記の「誤差を計算し、重みを更新する」という操作を行うかはいくつか手法があります。</p>

<ul>
<li>バッチ: 全学習データを用い、誤差の平均から一気に更新する</li>
<li>オンライン: データ一件ごとに逐次更新する</li>
<li>ミニバッチ: バッチとオンラインの中間のような手法。全学習データの中から幾つかサンプルを取り用いる(よく使われる手法)。</li>
</ul>

<p>利用した学習データに対して更新を終えるのが、1エポックというサイクルになります。通常は、このエポックを何回か繰り返して学習していきます。<br>
ただ、単純に繰り返しているとあまりよろしくないので、エポックの度に学習データをシャッフルしたり、ミニバッチの場合はミニバッチの取得位置をずらしたりランダムにサンプリングしたりします。</p>

<p>このエポックは学習の途中経過を確認したり、パラメーターの再調整を行ったりと、ニューラルネットワークの学習において重要な単位になっています。</p>

<h1>
<span id="chainerによる実装" class="fragment"></span><a href="#chainer%E3%81%AB%E3%82%88%E3%82%8B%E5%AE%9F%E8%A3%85"><i class="fa fa-link"></i></a>Chainerによる実装</h1>

<p>ニューラルネットワークについて説明した内容を、ここで一旦まとめておきます。</p>

<ul>
<li>構成: 複数のノードを持つ層を重ねることで構築される</li>
<li>伝播: 入力に対し重みをかけ、活性化関数を経由することで次層への出力へ変換する</li>
<li>学習: 誤差を計算し、それを基に各層の重みを調整する</li>
</ul>

<p>では、Chainerでの実装と上記のポイントを対応させながら見ていきます。</p>

<h2>
<span id="構成-1" class="fragment"></span><a href="#%E6%A7%8B%E6%88%90-1"><i class="fa fa-link"></i></a>構成</h2>

<p>Chainerでは、ニューラルネットワークは<code>Chain</code>で構成します(1.4まではFunctionSet)。<br>
以下は、今まで説明に使っていた4-3-2型のニューラルネットワークを定義したものです。</p>

<div class="code-frame" data-lang="py3"><div class="highlight"><pre>
<span class="kn">from</span> <span class="nn">chainer</span> <span class="k">import</span> <span class="n">Link</span><span class="p">,</span> <span class="n">Chain</span><span class="p">,</span> <span class="n">ChainList</span>
<span class="kn">import</span> <span class="nn">chainer.functions</span> <span class="k">as</span> <span class="nn">F</span>
<span class="kn">import</span> <span class="nn">chainer.links</span> <span class="k">as</span> <span class="nn">L</span>


<span class="k">class</span> <span class="nc">MyChain</span><span class="p">(</span><span class="n">Chain</span><span class="p">):</span>

    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">MyChain</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="n">__init__</span><span class="p">(</span>
            <span class="n">l1</span><span class="o">=</span><span class="n">L</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span>
            <span class="n">l2</span><span class="o">=</span><span class="n">L</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="nf">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">h</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">l1</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
        <span class="n">o</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">l2</span><span class="p">(</span><span class="n">h</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">o</span>
</pre></div></div>

<p>※注釈</p>

<ul>
<li>
<code>Chain</code>は継承しなくても差し支えないようですが、CPU/GPUのマイグレーションやモデルの保存などは<code>Chain</code>を継承しないとできないので、素直に継承した方がいいと思います。なお、単純な全結合であればわざわざクラスを作る必要はなく、<code>Chain(l1=..., l2=...)</code>で良いようです。</li>
<li>1.5からパラメーター付の関数(=最適化の対象となる)はLink、純粋な関数(sigmoidなど)はFunctionと役割が明確に分けられました。</li>
</ul>

<p>あれ、隠れ層は一層じゃなかったっけ?と思った方は最もだと思います。上記の<code>l1</code>、<code>l2</code>については以下の図を参照してください。</p>

<p><a href="https://qiita-image-store.s3.amazonaws.com/0/25990/cf9a08a2-5e50-0ad5-3d43-230188b4ca0c.png" target="_blank" rel="nofollow noopener"><img src="https://qiita-image-store.s3.amazonaws.com/0/25990/cf9a08a2-5e50-0ad5-3d43-230188b4ca0c.png" alt="image"></a></p>

<p>このように層と層の間の伝播を考えていくと、2層になるというからくりです。実際、<code>L.Linear</code>は伝播の際の重みを保持しており、入力に対しこの重みをかける操作を担います。</p>

<h2>
<span id="伝播-1" class="fragment"></span><a href="#%E4%BC%9D%E6%92%AD-1"><i class="fa fa-link"></i></a>伝播</h2>

<p>伝播の処理は、上記の通りChainクラスの<code>__call__</code>に実装を行います。</p>

<div class="code-frame" data-lang="text"><div class="highlight"><pre>
    def __call__(self, x):
        h = F.sigmoid(self.l1(x))
        o = self.l2(h)
        return o
</pre></div></div>

<p>※注釈</p>

<ul>
<li>1.4まで<code>forward</code>として書いていた処理は、<code>__call__</code>に書くことになります(Pythonでは、<code>__call__</code>を定義しておくと、例えば<code>model</code>というインスタンスから<code>model()</code>とすると<code>__call__</code>に書いた処理が呼べます)。</li>
</ul>

<p>ここでは入力<code>x</code>に対し重みをかけて(<code>self.l1(x)</code>)、次の層へは活性化関数としてよく利用されるシグモイド関数を経由した値を渡しています(<code>h=F.sigmoid(self.l1(x))</code>)。最後の出力では次の層へ渡すための処理は不要なので、活性化関数は使っていません(<code>o = self.l2(h)</code>)</p>

<h2>
<span id="学習-1" class="fragment"></span><a href="#%E5%AD%A6%E7%BF%92-1"><i class="fa fa-link"></i></a>学習</h2>

<p>学習に際しては、まず予測した値と実際の値との間の誤差を計算する必要があります。これは単純に関数として実装してもよいですが(Chainer内では<code>lossfun</code>という名前が一般的)、分類問題なら<code>Classifier</code>を使うと楽です。</p>

<div class="code-frame" data-lang="py3"><div class="highlight"><pre>
<span class="kn">from</span> <span class="nn">chainer.functions.loss.mean_squared_error</span> <span class="k">import</span> <span class="n">mean_squared_error</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">L</span><span class="o">.</span><span class="n">Classifier</span><span class="p">(</span><span class="n">MyChain</span><span class="p">(),</span> <span class="n">lossfun</span><span class="o">=</span><span class="n">mean_squared_error</span><span class="p">)</span>
</pre></div></div>

<p>実は<code>Classifier</code>も実体は<code>Link</code>、つまりパラメーターつきの関数で、<code>__call__</code>内で<code>MyChain</code>から出力される値と教師データの誤差を計算しています(計算のための<code>Function</code>は当然指定可能です(上記ではmean_squared_error))。</p>

<p>1.5ではこの<code>Link</code>をつなげられるようになった点が非常に大きく、モデルの再利用性がぐっと高くなりました。上記でも、本体のモデルとそれを利用して誤差を計算する処理とをきれいに分けて書くことができているのが分かると思います。</p>

<p>誤差を計算した後は、これが最小となるようモデルの最適化を行います(上述のBackpropagation)。この役割を担うのが<code>optimizer</code>となり、<a href="https://github.com/pfnet/chainer/blob/master/examples/mnist/train_mnist.py" rel="nofollow noopener" target="_blank">MNISTのexampleの学習の箇所</a>は、以下のようになっています。</p>

<div class="code-frame" data-lang="py3"><div class="highlight"><pre>
<span class="c"># Setup optimizer</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">optimizers</span><span class="o">.</span><span class="n">Adam</span><span class="p">()</span>
<span class="n">optimizer</span><span class="o">.</span><span class="n">setup</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>

<span class="o">...</span><span class="p">(</span><span class="n">中略</span><span class="p">)</span><span class="o">...</span>

<span class="c"># Learning loop</span>
<span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="n">six</span><span class="o">.</span><span class="n">moves</span><span class="o">.</span><span class="n">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">n_epoch</span> <span class="o">+</span> <span class="mi">1</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="s">'epoch'</span><span class="p">,</span> <span class="n">epoch</span><span class="p">)</span>

    <span class="c"># training</span>
    <span class="n">perm</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">permutation</span><span class="p">(</span><span class="n">N</span><span class="p">)</span>
    <span class="n">sum_accuracy</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">sum_loss</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">six</span><span class="o">.</span><span class="n">moves</span><span class="o">.</span><span class="n">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">N</span><span class="p">,</span> <span class="n">batchsize</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">chainer</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">xp</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">x_train</span><span class="p">[</span><span class="n">perm</span><span class="p">[</span><span class="n">i</span><span class="p">:</span><span class="n">i</span> <span class="o">+</span> <span class="n">batchsize</span><span class="p">]]))</span>
        <span class="n">t</span> <span class="o">=</span> <span class="n">chainer</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">xp</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">y_train</span><span class="p">[</span><span class="n">perm</span><span class="p">[</span><span class="n">i</span><span class="p">:</span><span class="n">i</span> <span class="o">+</span> <span class="n">batchsize</span><span class="p">]]))</span>

        <span class="c"># Pass the loss function (Classifier defines it) and its arguments</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">t</span><span class="p">)</span>
</pre></div></div>

<p>基本的なステップとしては、以下3つです。</p>

<ul>
<li>optimizerを作成(<code>optimizers.Adam()</code>)</li>
<li>optimizerにモデルをセット(<code>optimizer.setup(model)</code>)</li>
<li>optimizerでモデルを更新(<code>optimizer.update(model, x, t)</code>)</li>
</ul>

<p>中核となるのは更新を行っている<code>optimizer.update</code>です。1.5からはlossfunを引数に渡すことで自動的に渡されたlossfunによる誤差計算、伝播(backward)を行ってくれるようになりました。もちろん、今まで通り<code>model.zerograds()</code>で勾配を初期化してから自前で誤差の計算・伝播を行い(loss.backward)、<code>optimizer.update</code>を呼ぶことも可能です。</p>

<p>このように、Chainerではモデルを定義したらあとは簡単に最適化ができるよう設計されています(<code>Define-and-Run</code>)。</p>

<p>そして、学習したモデルは<code>Serializer</code>を利用することで簡単に保存/復元が可能です(<code>optimizer</code>についても保存可能です)。</p>

<div class="code-frame" data-lang="text"><div class="highlight"><pre>
serializers.save_hdf5('my.model', model)
serializers.load_hdf5('my.model', model)
</pre></div></div>

<p>後は、実際実装する上でのTipsを幾つか挙げておきます。</p>

<ul>
<li>Chainerはfloat32をメインで扱うため、ちゃんとこの型にしておかないとエラーになります。numpyはデフォルトだと<code>float64</code>のため注意です。</li>
<li>loss functionの想定している型をきちんと把握しておく必要があります。例えば、分類問題でよく利用される<code>softmax_cross_entropy.py</code>は、教師データが(ラベルを表す)int32型であることを想定しています。ここをfloatで渡すとエラーになるので注意してください。</li>
<li>1.5から?、計算処理のフローをグラフ表示できるようになりました(<a href="http://docs.chainer.org/en/stable/reference/graph.html" rel="nofollow noopener" target="_blank">Visualization of Computational Graph</a>)。モデルがきちんと構築できているか、確認するのによいでしょう。</li>
</ul>

<p>多分最初にはまるのは主に型系のエラーだと思います。Chainerは型に始まり型に終わる・・・かはわかりませんが、「型に始まる」のは間違いないので、この点に気を付けてぜひ利用してみてください。</p>
<div class="hidden"><form class="js-task-list-update" action="/icoxfog417/items/96ecaff323434c8d677b" accept-charset="UTF-8" method="post"><input name="utf8" type="hidden" value="&#x2713;" /><input type="hidden" name="_method" value="patch" /><input type="hidden" name="authenticity_token" value="OKU/5SLvjjI0c5loa7220MLOhTEFcgWsZk6Z+QnBE6AvwttS3KOlpEcLHVJWy1tqDHxODz9xa7il81AeB1NF5Q==" /><input type="hidden" name="updated_at_confirmation_in_unixtime" id="updated_at_confirmation_in_unixtime" value="1472458016" class="js-task-list-updated-at" /><textarea name="raw_body" id="raw_body" class="js-task-list-field">
[Chainer](http://chainer.org/)は、Preferred Networksが開発したニューラルネットワークを実装するためのライブラリです。その特徴としては、以下のような点があります(ホームページより)。

* 高速: CUDAをサポートし、GPUを利用した高速な計算が可能
* 柔軟: 柔軟な記法により、畳み込み、リカレントなど、様々なタイプのニューラルネットを実装可能
* 直観的: ネットワーク構成を直観的に記述できる

個人的には、さらに一つ「インストールが簡単」というのも挙げたいと思います。
ディープラーニング系のフレームワークはどれもインストールが面倒なものが多いのですが、Chainerは依存ライブラリが少なく簡単に導入・・・できたんですが、1.5.0からCythonを使うようになりちょっと手間になりました。インストール方法については以下をご参照ください。

* [Mac](http://qiita.com/unnonouno/items/b1fd299b90dd7e134217)
* [Windows](http://qiita.com/icoxfog417/items/ca1521f9d62183cea234)
* [AWS](http://qiita.com/unnonouno/items/8d8118bb38a589f7dbfa)
* [公式インストール情報](https://github.com/pfnet/chainer#installation)

また、Chainerは上記の通り記法が直観的かつシンプルなので、単純なネットワークからより複雑な、いわゆるディープラーニングと呼ばれる領域まで幅広くカバーできます。他のディープラーニング系のライブラリはディープでない場合完全にオーバースペックですし、かといってシンプルなライブラリ(PyBrainなど)ではディープだと厳しい、という状況だったので、この点もメリットとして大きいと思います。

今回はそんな魅力的なChainerの使い方について解説しますが、Chainerを扱うには(割と深い)ニューラルネットワークに関する知識が必要不可欠です。そのため、ニューラルネット側の知識が不十分だとはまることがままあります(私ははまりました)。

よって、ここではまずニューラルネットワークの仕組みについてざっと説明し、後の段でそれをどうChainerで実装するのかついて解説していきたいと思います。

# ニューラルネットワークの仕組み

## 構成

ニューラルネットワークの構成は、以下のようになっています(余談ですが、ノード間の線を引くのが毎回面倒でなりません)。

![image](https://qiita-image-store.s3.amazonaws.com/0/25990/7d32cf08-bd25-8bcb-592c-48ca2f432f89.png)

* ニューラルネットワークは、入力を受け取るinput層、出力を行うoutput層、その間の任意の数の隠れ層(hidden)から構成されます。上図では、隠れ層は1層になります。
* 各層には、任意の数のノードが存在します。このノードは、実体としては入力を受け取り値を出力する単なる関数です(後述します)。
* 入力に際しては、実際の入力とは別に独立した値を入れることがあります。これをバイアス(bias)ノードと呼びます(図中の灰色のノードで、通常値は1です。$ax+b$における$b$(切片)のようなものです)。

## 伝播

inputからの入力がどのようにoutputまでたどり着くのか、詳しく見ていきます。
下図は、隠れ層の第一ノードにinputからの入力が行われる様子を見やすくしたものです。

![image](https://qiita-image-store.s3.amazonaws.com/0/25990/5b092673-9046-1d95-4ef6-7a7727e32789.png)

4つのinputが伝わっているのがわかります。inputはそのまま直に伝わるのでなく、重みがかけられます。
ニューラルネットワークは脳の中のニューロンの構成をまねたものですが、これと同様入力(刺激)が伝播する際、弱められたり強められたりするものだと思ってください。数式的に表現すれば、入力が$x$だとしたら、$ax$という感じで$a$という重みが掛けられます。

![image](https://qiita-image-store.s3.amazonaws.com/0/25990/0cd8db7e-8b8c-550d-3fdd-a968df9cbda8.png)

さて、ここで`ax`という入力を受け取ったわけですが、ノードは受け取ったこの値をそのまま次の層に横流しするわけではありません。
脳の中ではある閾値を超えた入力でないと次の層には伝播させないという仕組みがあるそうで、ここでもそれを真似て、受け取った入力を次層への出力へ変換します。数式的に表現すれば、入力を次層への出力に変換する関数を$h$とし、その出力値は$h(ax)$で表現できます。この関数$h$を、活性化関数と呼びます。

まとめると、ニューラルネットワークにおける値の伝播にとって重要な要素は、以下二点になります。

* 重み(weight): 入力された値がどれくらい強化/減衰されるかを決定する
* 活性関数(activation function): 受け取った値を、どのように次の層へ渡すか

端的に見れば、ニューラルネットワークは受け取った入力に対して重みをかけて出力しているに過ぎません。そのため、一層のニューラルネットワークは線形回帰やロジスティック回帰とほぼ同義になります。

そう考えると、ノード数、層数の操作がどのような意味を持つのかが明確になってきます。

* ノード数を増やす: 扱う変数を増やし、多数の要素を加味して値/境界を決定できるようにする
* 層数: 直線境界をどんどん組み合わせていき、複雑な境界を表現できるようにする(一層は線形、二層は凸領域、三層は凸領域の中に穴が開いたような領域・・・とどんどん複雑になる。[はじめてのパターン認識 第7章 パーセプトロン型学習規則](http://qiita.com/icoxfog417/items/e574a9d61f9f680d578b)参照)

ニューラルネットワークを扱う場合、適当にノード数や層数をガチャガチャしてしまうこともあるかと思いますが、しっかりデータをプロットし適切なノード数・層数にあたりをつけることも肝要です。

## 学習

ニューラルネットワークを学習させるためには、誤差逆伝播法(Backpropagation)という手法を用います。
誤差とはニューラルネットワークから出力した値と、実際の値との間の差異になります。Backpropagationは、この誤差をその名の通り後ろ(出力層=output層)から伝播させていき、各層の重みを調整するという手法です。

![image](https://qiita-image-store.s3.amazonaws.com/0/25990/9d4d5518-97c7-b83e-7536-2044f6ec1d02.png)

Backpropagationの詳細は他に様々な説明があるためここでは深入りしませんが、重要な点は以下2点になります。

* 誤差の計算方法(cost/loss function): ニューラルネットワークから出力した値と、正解データの間の誤差をどのように計算するか
* 重みを調整する方法(optimizer): 計算された誤差をもって、どのように重みを調整していくのかを決定します

なお、どれくらいの学習データを利用して上記の「誤差を計算し、重みを更新する」という操作を行うかはいくつか手法があります。

* バッチ: 全学習データを用い、誤差の平均から一気に更新する
* オンライン: データ一件ごとに逐次更新する
* ミニバッチ: バッチとオンラインの中間のような手法。全学習データの中から幾つかサンプルを取り用いる(よく使われる手法)。

利用した学習データに対して更新を終えるのが、1エポックというサイクルになります。通常は、このエポックを何回か繰り返して学習していきます。
ただ、単純に繰り返しているとあまりよろしくないので、エポックの度に学習データをシャッフルしたり、ミニバッチの場合はミニバッチの取得位置をずらしたりランダムにサンプリングしたりします。

このエポックは学習の途中経過を確認したり、パラメーターの再調整を行ったりと、ニューラルネットワークの学習において重要な単位になっています。


# Chainerによる実装

ニューラルネットワークについて説明した内容を、ここで一旦まとめておきます。

* 構成: 複数のノードを持つ層を重ねることで構築される
* 伝播: 入力に対し重みをかけ、活性化関数を経由することで次層への出力へ変換する
* 学習: 誤差を計算し、それを基に各層の重みを調整する

では、Chainerでの実装と上記のポイントを対応させながら見ていきます。

## 構成

Chainerでは、ニューラルネットワークは`Chain`で構成します(1.4まではFunctionSet)。
以下は、今まで説明に使っていた4-3-2型のニューラルネットワークを定義したものです。

```py3
from chainer import Link, Chain, ChainList
import chainer.functions as F
import chainer.links as L


class MyChain(Chain):
    
    def __init__(self):
        super(MyChain, self).__init__(
            l1=L.Linear(4, 3),
            l2=L.Linear(3, 2)
        )
    
    def __call__(self, x):
        h = F.sigmoid(self.l1(x))
        o = self.l2(h)
        return o
```

※注釈

* `Chain`は継承しなくても差し支えないようですが、CPU/GPUのマイグレーションやモデルの保存などは`Chain`を継承しないとできないので、素直に継承した方がいいと思います。なお、単純な全結合であればわざわざクラスを作る必要はなく、`Chain(l1=..., l2=...)`で良いようです。
* 1.5からパラメーター付の関数(=最適化の対象となる)はLink、純粋な関数(sigmoidなど)はFunctionと役割が明確に分けられました。

あれ、隠れ層は一層じゃなかったっけ?と思った方は最もだと思います。上記の`l1`、`l2`については以下の図を参照してください。

![image](https://qiita-image-store.s3.amazonaws.com/0/25990/cf9a08a2-5e50-0ad5-3d43-230188b4ca0c.png)

このように層と層の間の伝播を考えていくと、2層になるというからくりです。実際、`L.Linear`は伝播の際の重みを保持しており、入力に対しこの重みをかける操作を担います。

## 伝播

伝播の処理は、上記の通りChainクラスの`__call__`に実装を行います。

```
    def __call__(self, x):
        h = F.sigmoid(self.l1(x))
        o = self.l2(h)
        return o
```

※注釈

* 1.4まで`forward`として書いていた処理は、`__call__`に書くことになります(Pythonでは、`__call__`を定義しておくと、例えば`model`というインスタンスから`model()`とすると`__call__`に書いた処理が呼べます)。

ここでは入力`x`に対し重みをかけて(`self.l1(x)`)、次の層へは活性化関数としてよく利用されるシグモイド関数を経由した値を渡しています(`h=F.sigmoid(self.l1(x))`)。最後の出力では次の層へ渡すための処理は不要なので、活性化関数は使っていません(`o = self.l2(h)`)

## 学習

学習に際しては、まず予測した値と実際の値との間の誤差を計算する必要があります。これは単純に関数として実装してもよいですが(Chainer内では`lossfun`という名前が一般的)、分類問題なら`Classifier`を使うと楽です。

```py3
from chainer.functions.loss.mean_squared_error import mean_squared_error

model = L.Classifier(MyChain(), lossfun=mean_squared_error)
```

実は`Classifier`も実体は`Link`、つまりパラメーターつきの関数で、`__call__`内で`MyChain`から出力される値と教師データの誤差を計算しています(計算のための`Function`は当然指定可能です(上記ではmean_squared_error))。

1.5ではこの`Link`をつなげられるようになった点が非常に大きく、モデルの再利用性がぐっと高くなりました。上記でも、本体のモデルとそれを利用して誤差を計算する処理とをきれいに分けて書くことができているのが分かると思います。

誤差を計算した後は、これが最小となるようモデルの最適化を行います(上述のBackpropagation)。この役割を担うのが`optimizer`となり、[MNISTのexampleの学習の箇所](https://github.com/pfnet/chainer/blob/master/examples/mnist/train_mnist.py)は、以下のようになっています。

```py3
# Setup optimizer
optimizer = optimizers.Adam()
optimizer.setup(model)

...(中略)...

# Learning loop
for epoch in six.moves.range(1, n_epoch + 1):
    print(&#39;epoch&#39;, epoch)

    # training
    perm = np.random.permutation(N)
    sum_accuracy = 0
    sum_loss = 0
    for i in six.moves.range(0, N, batchsize):
        x = chainer.Variable(xp.asarray(x_train[perm[i:i + batchsize]]))
        t = chainer.Variable(xp.asarray(y_train[perm[i:i + batchsize]]))

        # Pass the loss function (Classifier defines it) and its arguments
        optimizer.update(model, x, t)
```

基本的なステップとしては、以下3つです。

* optimizerを作成(`optimizers.Adam()`)
* optimizerにモデルをセット(`optimizer.setup(model)`)
* optimizerでモデルを更新(`optimizer.update(model, x, t)`)

中核となるのは更新を行っている`optimizer.update`です。1.5からはlossfunを引数に渡すことで自動的に渡されたlossfunによる誤差計算、伝播(backward)を行ってくれるようになりました。もちろん、今まで通り`model.zerograds()`で勾配を初期化してから自前で誤差の計算・伝播を行い(loss.backward)、`optimizer.update`を呼ぶことも可能です。

このように、Chainerではモデルを定義したらあとは簡単に最適化ができるよう設計されています(`Define-and-Run`)。

そして、学習したモデルは`Serializer`を利用することで簡単に保存/復元が可能です(`optimizer`についても保存可能です)。

```
serializers.save_hdf5(&#39;my.model&#39;, model)
serializers.load_hdf5(&#39;my.model&#39;, model)
```


後は、実際実装する上でのTipsを幾つか挙げておきます。

* Chainerはfloat32をメインで扱うため、ちゃんとこの型にしておかないとエラーになります。numpyはデフォルトだと`float64`のため注意です。
* loss functionの想定している型をきちんと把握しておく必要があります。例えば、分類問題でよく利用される`softmax_cross_entropy.py`は、教師データが(ラベルを表す)int32型であることを想定しています。ここをfloatで渡すとエラーになるので注意してください。
* 1.5から?、計算処理のフローをグラフ表示できるようになりました([Visualization of Computational Graph](http://docs.chainer.org/en/stable/reference/graph.html))。モデルがきちんと構築できているか、確認するのによいでしょう。

多分最初にはまるのは主に型系のエラーだと思います。Chainerは型に始まり型に終わる・・・かはわかりませんが、「型に始まる」のは間違いないので、この点に気を付けてぜひ利用してみてください。
</textarea><input type="submit" name="commit" value="Save changes" data-disable-with="Save changes" /></form></div></section></div><div class="col-sm-3"><div class="socialButtons"><div class="socialButtons_twitter"><a class="twitter-share-button" data-text="Chainerで始めるニューラルネットワーク by @icoxfog417 on @Qiita" data-url="http://qiita.com/icoxfog417/items/96ecaff323434c8d677b" href="https://twitter.com/share">Tweet</a></div><div class="socialButtons_hatebu"><a class="hatena-bookmark-button" data-hatena-bookmark-layout="simple-balloon" data-hatena-bookmark-title="Chainerで始めるニューラルネットワーク" href="http://b.hatena.ne.jp/entry/http://qiita.com/icoxfog417/items/96ecaff323434c8d677b" title="Add to Hatena Bookmark"><img alt="Add to Hatena Bookmark" height="20" src="https://b.st-hatena.com/images/entry-button/button-only@2x.png" style="border: none;" width="20" /></a><script async="async" charset="utf-8" src="https://b.st-hatena.com/js/bookmark_button.js" type="text/javascript"></script></div><div class="socialButtons_googlePlus"><div class="g-plusone" data-href="http://qiita.com/icoxfog417/items/96ecaff323434c8d677b" data-size="medium"></div></div><div class="socialButtons_facebook"><div class="fb-like" data-action="like" data-href="http://qiita.com/icoxfog417/items/96ecaff323434c8d677b" data-layout="button_count" data-share="false" data-show-faces="false"></div></div><div class="socialButtons_pocket"><a class="pocket-btn" data-lang="en" data-pocket-count="horizontal" data-pocket-label="pocket"></a></div></div><section class="itemsShowAuthorInfo" itemprop="author" itemscope="" itemtype="http://schema.org/Person"><a href="/icoxfog417"><img alt="" class="itemsShowAuthorInfo_userIcon" itemprop="image" src="https://qiita-image-store.s3.amazonaws.com/0/25990/profile-images/1484303516" /></a><div class="itemsShowAuthorInfo_profileStats"><strong class="itemsShowAuthorInfo_userName" itemprop="name"><a itemprop="url" href="/icoxfog417">icoxfog417</a></strong><div class="itemsShowAuthorInfo_contribution"><span class="itemsShowAuthorInfo_count">20387</span><span class="itemsShowAuthorInfo_unit">Contribution</span></div><div id="js-react-on-rails-context" data-rails-context="{}"></div>
<div class="js-react-on-rails-component" data-component-name="UserFollowButton" data-props="{&quot;initial_followed_by&quot;:false,&quot;position&quot;:&quot;author-info&quot;,&quot;size&quot;:&quot;btn-xs&quot;,&quot;url_name&quot;:&quot;icoxfog417&quot;}" data-trace="false" data-dom-id="UserFollowButton-react-component-9437ac51-1894-48a3-bfa1-255772d73001"></div>
    <div id="UserFollowButton-react-component-9437ac51-1894-48a3-bfa1-255772d73001"></div>
    
</div><section class="itemsShowAuthorPopularItems"><h5 class="itemsShowAuthorPopularItems_sectionTitle">人気の投稿</h5><ul class="itemsShowAuthorPopularItems_posts list-unstyled"><li itemscope="" itemtype="http://schema.org/Article"> <a itemprop="url" track="click" data-label="AuthorPopularItemsAtSidebar" href="/icoxfog417/items/e8f97a6acad07903b5b0">Pythonを書き始める前に見るべきTips</a></li><li itemscope="" itemtype="http://schema.org/Article"> <a itemprop="url" track="click" data-label="AuthorPopularItemsAtSidebar" href="/icoxfog417/items/adbbf445d357c924b8fc">画像処理の数式を見て石になった時のための、金の針</a></li><li itemscope="" itemtype="http://schema.org/Article"> <a itemprop="url" track="click" data-label="AuthorPopularItemsAtSidebar" href="/icoxfog417/items/242439ecd1a477ece312">ゼロからDeepまで学ぶ強化学習</a></li><li itemscope="" itemtype="http://schema.org/Article"> <a itemprop="url" track="click" data-label="AuthorPopularItemsAtSidebar" href="/icoxfog417/items/65e800c3a2094457c3a0">はじめるDeep learning</a></li><li itemscope="" itemtype="http://schema.org/Article"> <a itemprop="url" track="click" data-label="AuthorPopularItemsAtSidebar" href="/icoxfog417/items/5d79b3336226aa51e30d">React.js 実戦投入への道</a></li></ul></section><section class="itemsShowAuthorInfo_organization"><h5 class="itemsShowAuthorInfo_organizationTitle">ORGANIZATION</h5><span itemprop="memberOf" itemscope="" itemtype="http://schema.org/Organization"><a itemprop="url" href="/organizations/tis"><img alt="TIS株式会社" class="itemsShowAuthorInfo_organizationLogo" itemprop="image" src="https://s3-ap-northeast-1.amazonaws.com/qiita-organization-image/5710e4c30854dd4ab3658e7f585930ab0d81a12c/original.jpg?1484790468" /></a></span></section></section><div class="scroll-chaser"><div class="google-adsense"><style>.test-text-responsible { width: 200px; height: 200px; }@media(min-width: 1200px) {  .test-text-responsible { width: 250px; height: 250px; }}@media(max-width: 979px) and (min-width: 768px) {  .test-text-responsible { width: 120px; height: 240px; }}@media(max-width: 767px) {  .test-text-responsible { width: 320px; height: 50px; }}</style><script async="" src="http://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script><ins class="adsbygoogle test-text-responsible" data-ad-client="ca-pub-8127218772604357" data-ad-slot="3880091879" style="display:inline-block"></ins><script>(adsbygoogle = window.adsbygoogle || []).push({});</script></div></div><div class="js-react-on-rails-component" data-component-name="Toc" data-props="{&quot;body&quot;:&quot;\u003cul\u003e\n\u003cli\u003e\n\u003ca href=\&quot;#%E3%83%8B%E3%83%A5%E3%83%BC%E3%83%A9%E3%83%AB%E3%83%8D%E3%83%83%E3%83%88%E3%83%AF%E3%83%BC%E3%82%AF%E3%81%AE%E4%BB%95%E7%B5%84%E3%81%BF\&quot;\u003eニューラルネットワークの仕組み\u003c/a\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003ca href=\&quot;#%E6%A7%8B%E6%88%90\&quot;\u003e構成\u003c/a\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\&quot;#%E4%BC%9D%E6%92%AD\&quot;\u003e伝播\u003c/a\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\&quot;#%E5%AD%A6%E7%BF%92\&quot;\u003e学習\u003c/a\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\&quot;#chainer%E3%81%AB%E3%82%88%E3%82%8B%E5%AE%9F%E8%A3%85\&quot;\u003eChainerによる実装\u003c/a\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003ca href=\&quot;#%E6%A7%8B%E6%88%90-1\&quot;\u003e構成\u003c/a\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\&quot;#%E4%BC%9D%E6%92%AD-1\&quot;\u003e伝播\u003c/a\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\&quot;#%E5%AD%A6%E7%BF%92-1\&quot;\u003e学習\u003c/a\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n&quot;,&quot;wrapper&quot;:&quot;#article-body-wrapper&quot;}" data-trace="false" data-dom-id="Toc-react-component-2a2962eb-3fcd-4d70-b5e8-c90a85755159"></div>
    <div id="Toc-react-component-2a2962eb-3fcd-4d70-b5e8-c90a85755159"></div>
    
</div></div><div class="row"><div class="col-sm-9"><div class="ArticleFooter__menu"><div class="s-flex-align-center"><div class="js-likebutton" data-props="{&quot;like_status&quot;:false,&quot;like_count&quot;:397,&quot;show_count&quot;:true,&quot;uuid&quot;:&quot;96ecaff323434c8d677b&quot;,&quot;likable_type&quot;:&quot;Article&quot;,&quot;position&quot;:&quot;article-footer&quot;}"></div><div class="ArticleFooter__userList"><div class="ArticleFooter__user"><div class="js-hovercard" data-hovercard-target-name="shogiai"><a itemprop="url" href="/shogiai"><img alt="shogiai" class="thumb thumb--xs" src="https://qiita-image-store.s3.amazonaws.com/0/86977/profile-images/1473703926" /></a></div></div><div class="ArticleFooter__user"><div class="js-hovercard" data-hovercard-target-name="metheglin"><a itemprop="url" href="/metheglin"><img alt="metheglin" class="thumb thumb--xs" src="https://qiita-image-store.s3.amazonaws.com/0/36978/profile-images/1473687266" /></a></div></div><div class="ArticleFooter__user"><div class="js-hovercard" data-hovercard-target-name="nmby"><a itemprop="url" href="/nmby"><img alt="nmby" class="thumb thumb--xs" src="https://qiita-image-store.s3.amazonaws.com/0/84939/profile-images/1473703265" /></a></div></div><div class="ArticleFooter__user"><div class="js-hovercard" data-hovercard-target-name="TomokIshii"><a itemprop="url" href="/TomokIshii"><img alt="TomokIshii" class="thumb thumb--xs" src="https://qiita-image-store.s3.amazonaws.com/0/74152/profile-images/1473699746" /></a></div></div><div class="ArticleFooter__user"><div class="js-hovercard" data-hovercard-target-name="leon_AKQJT"><a itemprop="url" href="/leon_AKQJT"><img alt="leon_AKQJT" class="thumb thumb--xs" src="https://qiita-image-store.s3.amazonaws.com/0/35340/profile-images/1473686685" /></a></div></div><div class="ArticleFooter__user"><div class="js-hovercard" data-hovercard-target-name="TakesxiSximada"><a itemprop="url" href="/TakesxiSximada"><img alt="TakesxiSximada" class="thumb thumb--xs" src="https://qiita-image-store.s3.amazonaws.com/0/36261/profile-images/1473687011" /></a></div></div><div class="ArticleFooter__user"><div class="js-hovercard" data-hovercard-target-name="Tomatio13"><a itemprop="url" href="/Tomatio13"><img alt="Tomatio13" class="thumb thumb--xs" src="https://qiita-image-store.s3.amazonaws.com/0/75580/profile-images/1473700200" /></a></div></div><div class="ArticleFooter__user"><div class="js-hovercard" data-hovercard-target-name="bighope"><a itemprop="url" href="/bighope"><img alt="bighope" class="thumb thumb--xs" src="https://qiita-image-store.s3.amazonaws.com/0/83472/profile-images/1473702787" /></a></div></div><div class="ArticleFooter__user"><div class="js-hovercard" data-hovercard-target-name="TD72"><a itemprop="url" href="/TD72"><img alt="TD72" class="thumb thumb--xs" src="https://qiita-image-store.s3.amazonaws.com/0/76769/profile-images/1473700600" /></a></div></div><div class="ArticleFooter__user"><div class="js-hovercard" data-hovercard-target-name="azihsoyn"><a itemprop="url" href="/azihsoyn"><img alt="azihsoyn" class="thumb thumb--xs" src="https://qiita-image-store.s3.amazonaws.com/0/14577/profile-images/1477545988" /></a></div></div><div class="ArticleFooter__user"><a href="/icoxfog417/items/96ecaff323434c8d677b/likers"><span class="fa fa-ellipsis-h"></span></a></div></div></div><div class="u-flex u-align-center"><div class="ArticleFooter__stock"><div class="js-stockbutton" data-position="footer_menu" data-props="{&quot;stock_status&quot;:false}"></div></div><div class="ArticleFooter__editRequest"><a class="u-link-no-underline" data-toggle="tooltip" title="You can propose improvements about the article to the author 💪" href="/drafts/96ecaff323434c8d677b/edit"><span class="fa fa-send-o fa-lg"></span> <span>Edit request</span></a></div><div class="dropdown ArticleFooter__dropdown"><a class="dropdown-toggle" data-toggle="dropdown" href="#"><span class="fa fa-ellipsis-h"></span></a><ul class="dropdown-menu dropdown-menu-right"><li><a href="/icoxfog417/items/96ecaff323434c8d677b.md"><span class="fa fa-fw fa-file-text-o"></span> Show article as Markdown</a></li><li><a data-target=".js-report-form" data-toggle="modal" href="#"><i class="fa fa-fw fa-flag"></i> Report article</a></li></ul></div></div></div><ul class="references js-referencesView"><li class="references_header"><i class="fa fa-fw fa-link"></i> Linked from these articles</li><a class="references_toggleOldReferences js-toggleOldReferences" href="#"><i class="fa fa-expand js-toggleOldReferencesIcon"></i><span class="js-toggleOldReferencesText">Show old 3 links</span></a><li class="references_reference js-reference js-oldReference"><span>Linked from </span><a href="/shu223/items/a4fc17eb3356a6068553#_reference-c0d85905e9b2960180a8"><img alt="" width="18" height="18" src="https://qiita-image-store.s3.amazonaws.com/0/3180/profile-images/1473682733" />ディープラーニングの有名ライブラリ5種を最短距離で試す半日コース（TensorFlow, Chainer, Caffe, DeepDream, 画風変換）</a><time class="references_datetime js-dateTimeView" datetime="2016-01-12T00:34:06+00:00">about 1 year ago</time></li><li class="references_reference js-reference js-oldReference"><span>Linked from </span><a href="/ichiroex/items/e0486a6dea1f14c2cfc2#_reference-4fdb3dc96dd270c10b70"><img alt="" width="18" height="18" src="https://qiita-image-store.s3.amazonaws.com/0/92685/profile-images/1473705706" />深層学習フレームワークChainerの勉強に役立つページのまとめ</a><time class="references_datetime js-dateTimeView" datetime="2016-04-05T15:03:21+00:00">12 months ago</time></li><li class="references_reference js-reference js-oldReference"><span>Linked from </span><a href="/hikobotch/items/d8ff5bebcf70083de089#_reference-4d490296044c6195798c"><img alt="" width="18" height="18" src="https://qiita-image-store.s3.amazonaws.com/0/79218/profile-images/1473701367" />chainerでミニバッチ学習時のランダム処理有無の違いを確認した</a><time class="references_datetime js-dateTimeView" datetime="2016-05-07T16:01:55+00:00">11 months ago</time></li><li class="references_reference js-reference"><span>Linked from </span><a href="/icoxfog417/items/242439ecd1a477ece312#_reference-a72e6ac9adb3ebab3795"><img alt="" width="18" height="18" src="https://qiita-image-store.s3.amazonaws.com/0/25990/profile-images/1484303516" />ゼロからDeepまで学ぶ強化学習</a><time class="references_datetime js-dateTimeView" datetime="2016-06-07T08:03:42+00:00">9 months ago</time></li><li class="references_reference js-reference"><span>Linked from </span><a href="/jintaka1989/items/3b70b5c5541620536fa2#_reference-e2ab69e1ecc179701681"><img alt="" width="18" height="18" src="https://qiita-image-store.s3.amazonaws.com/0/131965/profile-images/1473718461" />TensorFlowのチュートリアルを通して、人工知能の原理について学習する</a><time class="references_datetime js-dateTimeView" datetime="2016-07-01T08:02:02+00:00">9 months ago</time></li><li class="references_reference js-reference"><span>Linked from </span><a href="/jintaka1989/items/bfcf9cc9b0c2f597d419#_reference-94ca6cd8ea4d47ed09ef"><img alt="" width="18" height="18" src="https://qiita-image-store.s3.amazonaws.com/0/131965/profile-images/1473718461" />各機械学習ライブラリの比較をまとめる</a><time class="references_datetime js-dateTimeView" datetime="2016-07-04T00:05:07+00:00">9 months ago</time></li><li class="references_reference js-reference"><span>Linked from </span><a href="/moroku0519/items/3188382ad85a8654cc42#_reference-928bd42c2ffde93cea50"><img alt="" width="18" height="18" src="https://qiita-image-store.s3.amazonaws.com/0/28622/profile-images/1473685226" />ニューラルネットワークとは</a><time class="references_datetime js-dateTimeView" datetime="2016-10-23T09:25:27+00:00">5 months ago</time></li><li class="references_reference js-reference"><span>Linked from </span><a href="/moroku0519/items/5fd17f3e5105439871ec#_reference-8816fc6bf2f9bc462a15"><img alt="" width="18" height="18" src="https://qiita-image-store.s3.amazonaws.com/0/28622/profile-images/1473685226" />誤差逆伝播法</a><time class="references_datetime js-dateTimeView" datetime="2017-02-26T03:12:47+00:00">21 days ago</time></li></ul><div class="itemsShowBody_articleColumnFooter"><div class="socialButtons"><div class="socialButtons_twitter"><a class="twitter-share-button" data-text="Chainerで始めるニューラルネットワーク by @icoxfog417 on @Qiita" data-url="http://qiita.com/icoxfog417/items/96ecaff323434c8d677b" href="https://twitter.com/share">Tweet</a></div><div class="socialButtons_hatebu"><a class="hatena-bookmark-button" data-hatena-bookmark-layout="simple-balloon" data-hatena-bookmark-title="Chainerで始めるニューラルネットワーク" href="http://b.hatena.ne.jp/entry/http://qiita.com/icoxfog417/items/96ecaff323434c8d677b" title="Add to Hatena Bookmark"><img alt="Add to Hatena Bookmark" height="20" src="https://b.st-hatena.com/images/entry-button/button-only@2x.png" style="border: none;" width="20" /></a><script async="async" charset="utf-8" src="https://b.st-hatena.com/js/bookmark_button.js" type="text/javascript"></script></div><div class="socialButtons_googlePlus"><div class="g-plusone" data-href="http://qiita.com/icoxfog417/items/96ecaff323434c8d677b" data-size="medium"></div></div><div class="socialButtons_facebook"><div class="fb-like" data-action="like" data-href="http://qiita.com/icoxfog417/items/96ecaff323434c8d677b" data-layout="button_count" data-share="false" data-show-faces="false"></div></div><div class="socialButtons_pocket"><a class="pocket-btn" data-lang="en" data-pocket-count="horizontal" data-pocket-label="pocket"></a></div></div></div><div class="itemsShowComment_wrapper" id="comments"><div class="js-react-on-rails-component" data-component-name="CommentListContainer" data-props="{&quot;currentUser&quot;:null,&quot;initialComments&quot;:[],&quot;monthly_public_image_uploadable_size_limit&quot;:null,&quot;total_uploaded_public_image_size_in_current_month&quot;:null,&quot;item&quot;:{&quot;id&quot;:330858,&quot;uuid&quot;:&quot;96ecaff323434c8d677b&quot;,&quot;suspended&quot;:false,&quot;secret&quot;:false},&quot;owner&quot;:{&quot;url_name&quot;:&quot;icoxfog417&quot;},&quot;is_team&quot;:false,&quot;is_project&quot;:false,&quot;logged_in&quot;:false,&quot;polling&quot;:false,&quot;mention_candidates&quot;:[{&quot;id&quot;:25990,&quot;url_name&quot;:&quot;icoxfog417&quot;,&quot;profile_image_url&quot;:&quot;https://qiita-image-store.s3.amazonaws.com/0/25990/profile-images/1484303516&quot;}]}" data-trace="false" data-dom-id="CommentListContainer-react-component-c62fd2cb-6a7e-499f-bf4f-ea45b1f3fc63"></div>
    <div id="CommentListContainer-react-component-c62fd2cb-6a7e-499f-bf4f-ea45b1f3fc63"></div>
    
</div></div></div></div></article><div class="js-report-form modal fade reportForm"><div class="modal-dialog"><div class="modal-content"><div class="modal-header"><button name="button" type="submit" class="close" data-dismiss="modal">&times;</button><h4 class="modal-title">Report article</h4></div><div class="modal-body"><form action="/reports" accept-charset="UTF-8" method="post"><input name="utf8" type="hidden" value="&#x2713;" /><input type="hidden" name="authenticity_token" value="1EgfLJcRHDtZPPpK7usY5gu+K8ktJk/DNfq71wafikfDL/ubaV03rSpEfnDTnfVcxQzg9xclIdf2R3IwCA3cAg==" /><input type="hidden" name="redirect_path" id="redirect_path" value="/icoxfog417/items/96ecaff323434c8d677b" /><input type="hidden" name="item_uuid" id="item_uuid" value="96ecaff323434c8d677b" /><p>Help us understand the problem. What is going on with this item?</p><br /><div class="form-group"><ul class="list-unstyled"><li><label><input type="radio" name="report_type" id="report_type_spam" value="spam" required="required" /> It&#39;s spam </label></li><li><label><input type="radio" name="report_type" id="report_type_harassment" value="harassment" required="required" /> It&#39;s abusive or harmful </label></li><li><label><input type="radio" name="report_type" id="report_type_inappropriate_content" value="inappropriate_content" required="required" /> It contains inappropriate content </label></li></ul></div><div class="reportForm_submitButtonContainer"><button name="button" type="submit" class="btn btn-primary reportForm_submitButton"><i class="fa fa-send"></i> Submit</button></div></form></div></div></div></div><script id="js-item" type="application/json">{ "url": "http://qiita.com/icoxfog417/items/96ecaff323434c8d677b", "id": 330858, "uuid": "96ecaff323434c8d677b" }</script><script class="js-user" type="application/json">{&quot;id&quot;:25990,&quot;url_name&quot;:&quot;icoxfog417&quot;,&quot;profile_image_url&quot;:&quot;https://qiita-image-store.s3.amazonaws.com/0/25990/profile-images/1484303516&quot;}</script><script language="JavaScript" src="//cdn.bigmining.com/private/js/qiita_bigmining.js" type="text/javascript"></script></div><footer class="footer"><div class="footer_inner"><div class="footer_container"><ul class="footer_links-left"><li class="footer_link"><a class="footer_copyright" href="http://increments.co.jp">© 2011-2017 Increments Inc.</a></li><li class="footer_link"><a href="http://qiita.com/terms">Terms</a></li><li class="footer_link"><a href="http://qiita.com/privacy">Privacy</a></li><li class="footer_link"><a href="http://help.qiita.com">Help</a></li><li class="footer_link"><a href="https://increments.zendesk.com/anonymous_requests/new">Contact</a></li></ul><ul class="footer_links-right"><li class="footer_link"><a href="http://qiita.com/about">About</a></li><li class="footer_link"><a href="/users">Users</a></li><li class="footer_link"><a href="/tags">Tags</a></li><li class="footer_link"><a href="http://blog.qiita.com">Blog</a></li><li class="footer_link"><a href="http://qiita.com/api/v2/docs">API</a></li><li class="footer_link"><a href="https://teams.qiita.com/">Team</a></li><li class="footer_link"><a href="http://kobito.qiita.com">Kobito</a></li><li class="footer_link"><a class="js-public-form-feedback-link" data-target=".js-feedback-form" data-toggle="modal" href=""><i class="fa fa-heart"></i> Feedback <i class="fa fa-caret-down"></i></a></li></ul></div></div></footer><div class="js-feedback-form modal fade feedbackForm"><div class="modal-dialog"><div class="modal-content"><div class="modal-header"><button name="button" type="submit" class="close" data-dismiss="modal">&times;</button><h4 class="modal-title">Feedback</h4></div><div class="modal-body"><form class="js-feedback-form-form" action="/feedbacks" accept-charset="UTF-8" method="post"><input name="utf8" type="hidden" value="&#x2713;" /><input type="hidden" name="authenticity_token" value="Nk5hMhoZ5Ji+Lt1Qw59kqgthNHZrjzaGXD8Dxh6RHaUhKYWF5FXPDs1WWWr+6YkQxdP/SFGMWJKfgsohEANL4A==" /><input type="hidden" name="redirect_path" id="redirect_path" value="/icoxfog417/items/96ecaff323434c8d677b" /><div class="form-group"><textarea name="feedback[message]" id="feedback_message" class="form-control js-feedback-form-text-area" placeholder="Please give us any feedback about Qiita." required="required" rows="5">
</textarea></div><div class="feedbackForm_submitButtonContainer"><button name="button" type="submit" class="btn btn-primary feedbackForm_submitButton"><i class="fa fa-send"></i> Submit</button><p class="feedbackForm_note">We don&#39;t reply to any feedback.<br />If you need help with Qiita, please send a support request from <a href="https://increments.zendesk.com/anonymous_requests/new">here</a>.</p></div><div style="position:fixed;top:-99999px;opacity:0.0001;"><input name="feedback[name]" type="text" /></div></form></div></div></div></div><script>// if (window.mixpanel instanceof Element) {
//   window.mixpanel = [];
// }
// (function(f,b){if(!b.__SV){var a,e,i,g;window.mixpanel=b;b._i=[];b.init=function(a,e,d){function f(b,h){var a=h.split(".");2==a.length&&(b=b[a[0]],h=a[1]);b[h]=function(){b.push([h].concat(Array.prototype.slice.call(arguments,0)))}}var c=b;"undefined"!==typeof d?c=b[d]=[]:d="mixpanel";c.people=c.people||[];c.toString=function(b){var a="mixpanel";"mixpanel"!==d&&(a+="."+d);b||(a+=" (stub)");return a};c.people.toString=function(){return c.toString(1)+".people (stub)"};i="disable track track_pageview track_links track_forms register register_once alias unregister identify name_tag set_config people.set people.set_once people.increment people.append people.track_charge people.clear_charges people.delete_user".split(" ");
// for(g=0;g<i.length;g++)f(c,i[g]);b._i.push([a,e,d])};b.__SV=1.2;a=f.createElement("script");a.type="text/javascript";a.async=!0;a.src="//cdn.mxpnl.com/libs/mixpanel-2.2.min.js";e=f.getElementsByTagName("script")[0];e.parentNode.insertBefore(a,e)}})(document,window.mixpanel||[]);</script><script src="http://cdn.qiita.com/assets/public-3af9c1d29a49f3320bb796fb5e75304b.min.js"></script><script>
  (function () {
    var script = document.getElementsByTagName('script')[0];
    var load = function (src, id) {
      var el = document.createElement('script');
      el.async = true;
      el.src = src;
      el.id = id;
      script.parentNode.insertBefore(el, script);
    };
      // Optimizely
      load('//cdn.optimizely.com/js/52738645.js', 'optimizely-jssdk');
      // Google Analytics
      window._gaq = window._gaq || [];
      var isCareer = location.hostname.split('.')[0] == 'career';
      if (isCareer) {
        window._gaq.push(['_setAccount', 'UA-24675221-11']);
        window._gaq.push(['_setDomainName', 'qiita.com']);
      } else {
        window._gaq.push(['_setAccount', 'UA-24675221-1']);
      }
      window._gaq.push(['_setCustomVar', 1, 'logged_in', 'false', 2]);
      window._gaq.push(['_trackPageview']);
      var src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
      load(src, 'google-analytics-jssdk');
    // Google Analytics - Universal Analytics
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
    (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
    m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','//www.google-analytics.com/analytics.js','ga');
        ga('create', 'UA-24675221-12', {
          
        });
        ga('set', 'dimension1', 'false');
        ga('set', 'dimension3', 'false');
      ga('require', 'displayfeatures');
      ga('set', 'forceSSL', true);
      ga('send', 'pageview');
    // Google Tag Manager
      (function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
      new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
      j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
      '//www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
      })(window,document,'script','dataLayer','GTM-TBQWPN');
  })();
</script>
</body></html>