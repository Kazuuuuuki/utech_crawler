<!DOCTYPE html><html xmlns:og="http://ogp.me/ns#"><head><meta charset="UTF-8" /><title>ディープラーニングの有名ライブラリ5種を最短距離で試す半日コース（TensorFlow, Chainer, Caffe, DeepDream, 画風変換） - Qiita</title><meta content="width=device-width,initial-scale=1" name="viewport" /><meta content="「いつか勉強しよう」と人工知能／機械学習／ディープラーニング（Deep Learning）といったトピックの記事の見つけてはアーカイブしてきたものの、結局2015年は何一つやらずに終わってしまったので、とにかく一歩でも足を踏み出すべく、 本質的な理解等はさておき、とにかく試してみる ということをやってみました。

試したのは、TensorFlow、Chainer、Caffe といった機械学習およびディープラーニングの代表的なライブラリ／フレームワーク3種と、2015年に..." name="description" /><meta content="summary" name="twitter:card" /><meta content="@Qiita" name="twitter:site" /><meta content="shu223" name="twitter:creator" /><meta content="ディープラーニングの有名ライブラリ5種を最短距離で試す半日コース（TensorFlow, Chainer, Caffe, DeepDream, 画風変換） - Qiita" property="og:title" /><meta content="article" property="og:type" /><meta content="http://qiita.com/shu223/items/a4fc17eb3356a6068553" property="og:url" /><meta content="http://cdn.qiita.com/assets/qiita-fb-2887e7b4aad86fd8c25cea84846f2236.png" property="og:image" /><meta content="「いつか勉強しよう」と人工知能／機械学習／ディープラーニング（Deep Learning）といったトピックの記事の見つけてはアーカイブしてきたものの、結局2015年は何一つやらずに終わってしまったので、とにかく一歩でも足を踏み出すべく..." property="og:description" /><meta content="Qiita" property="og:site_name" /><meta content="564524038" property="fb:admins" /><link rel="shortcut icon" type="image/x-icon" href="http://cdn.qiita.com/assets/favicons/public/production-4ff10c1e1e2b5fcb353ff9cafdd56c70.ico" /><link rel="apple-touch-icon" type="image/png" href="http://cdn.qiita.com/assets/favicons/public/apple-touch-icon-f9a6afad761ec2306e10db2736187c8b.png" /><link href="/opensearch.xml" rel="search" title="Qiita" type="application/opensearchdescription+xml" /><link rel="stylesheet" media="all" href="http://cdn.qiita.com/assets/public-81dd63f4385f99b52aeab91266068ebd.min.css" /><meta name="csrf-param" content="authenticity_token" />
<meta name="csrf-token" content="6y1xRWLT2V57XUjqPmR7QVqohU6KSQlw08/9h96eqE3CbwJKsjAnxyZV93FvJcBPFQTJgEZdm/vWwlvvJ6X9bw==" /></head><body class="without-js" id=""><noscript><iframe height="0" src="//www.googletagmanager.com/ns.html?id=GTM-TBQWPN" style="display:none;visibility:hidden" width="0"></iframe></noscript><script>
  document.body.className = document.body.className.replace('without-js', '') + ' with-js';
  window.Qiita = {"asset_host":"cdn.qiita.com","TLD":"com","controller_path":"public/items","controller_action":"public/items#show","controller":"items","action":"show","action_path":"public/items#show","env":"production","flash":{},"is_landing_page":false,"is_team_page":false,"request_parameters":{"controller":"public/items","action":"show","user_id":"shu223","type":"items","id":"a4fc17eb3356a6068553"},"root_domain":"qiita.com","variant":null,"config":{"mixpanel":{"career":"dd35af27e959781713d63fd7ca898a8d","per_team":"c0a2116368b33b44b5029ebd2cc9b094","public":"be87616606b0e26a87689099aab2c4e5","team":"b7c0342acba2dbc8742484d98788efb3"},"default_locale":"ja","locale":"en"},"team":null,"user":null,"GIT_BRANCH":null,"DEBUG":false};

</script>
<div class="headerContainer headerContainer-public" role="navigation"><div class="js-react-on-rails-component" data-component-name="HeaderContainer" data-props="{&quot;user&quot;:null,&quot;team&quot;:null,&quot;news&quot;:{&quot;type&quot;:&quot;募集&quot;,&quot;content&quot;:&quot;QiitaやQiita:Teamを良くしたいエンジニア&quot;,&quot;url&quot;:&quot;http://increments.co.jp/jobs/engineers?utm_source=qiita\u0026utm_medium=header_news&quot;},&quot;initial_unread_count&quot;:null,&quot;siteid_image&quot;:&quot;http://cdn.qiita.com/siteid-reverse.png&quot;,&quot;is_team_page&quot;:false,&quot;on_team_setting&quot;:false,&quot;show_post_menu&quot;:true,&quot;show_search_menu&quot;:true,&quot;is_fluid&quot;:false,&quot;locale&quot;:&quot;en&quot;}" data-trace="false" data-dom-id="HeaderContainer-react-component-305fbcbc-4d9e-43e6-8dfb-22fd0e262ef0"></div>
    <div id="HeaderContainer-react-component-305fbcbc-4d9e-43e6-8dfb-22fd0e262ef0"></div>
    
</div><div id="main"><script type="application/ld+json">{  "@context": "http://schema.org",  "@type": "BreadcrumbList",  "itemListElement": [    {      "@type": "ListItem",      "position": 1,      "item": {        "@id": "/",        "name": "Qiita"      }    },    {      "@type": "ListItem",      "position": 2,      "item": {        "@id": "/items",        "name": "Items"      }    },    {      "@type": "ListItem",      "position": 3,      "item": {        "@id": "/tags/DeepLearning",        "name": "DeepLearning"      }    }  ]}</script><article itemscope="" itemtype="http://schema.org/Article"><div class="ArticleMainHeader "><div class="container"></div><div class="container"><div class="row s-flex-align-center"><div class="col-sm-9"><h1 class="ArticleMainHeader__title" itemprop="headline">ディープラーニングの有名ライブラリ5種を最短距離で試す半日コース（TensorFlow, Chainer, Caffe, DeepDream, 画風変換）</h1><ul class="TagList"><li class="TagList__item" data-count="1075"><a class="u-link-unstyled TagList__label" href="/tags/DeepLearning"><img alt="DeepLearning" class="TagList__icon" src="https://s3-ap-northeast-1.amazonaws.com/qiita-tag-image/eac844d1d880a38fc3be5ebf534cad5182b64ebf/medium.jpg?1453002020" /><span>DeepLearning</span></a></li><li class="TagList__item" data-count="9910"><a class="u-link-unstyled TagList__label" href="/tags/Python"><img alt="Python" class="TagList__icon" src="https://s3-ap-northeast-1.amazonaws.com/qiita-tag-image/28fd3d6b220c89e6197fd82c02fd2fcd2bb66d81/medium.jpg?1383884245" /><span>Python</span></a></li><li class="TagList__item" data-count="786"><a class="u-link-unstyled TagList__label" href="/tags/TensorFlow"><img alt="TensorFlow" class="TagList__icon" src="https://s3-ap-northeast-1.amazonaws.com/qiita-tag-image/a35c51e3bff4af3c505656bda4abdef2e00684c8/medium.jpg?1447140205" /><span>TensorFlow</span></a></li><li class="TagList__item" data-count="1835"><a class="u-link-unstyled TagList__label" href="/tags/%E6%A9%9F%E6%A2%B0%E5%AD%A6%E7%BF%92"><img alt="機械学習" class="TagList__icon" src="https://s3-ap-northeast-1.amazonaws.com/qiita-tag-image/a94d4d239b3b0b83723d5b56c050ffc54b8593e7/medium.jpg?1394635775" /><span>機械学習</span></a></li><li class="TagList__item" data-count="322"><a class="u-link-unstyled TagList__label" href="/tags/%E7%94%BB%E5%83%8F%E5%87%A6%E7%90%86"><img alt="画像処理" class="TagList__icon" src="https://s3-ap-northeast-1.amazonaws.com/qiita-tag-image/4c43dc9a30e781489de25e68c0325ddb3279016e/medium.jpg?1422923133" /><span>画像処理</span></a></li></ul></div><div class="col-sm-3"><div class="itemsShowHeaderStock"><ul class="list-unstyled itemsShowHeaderStock_statusList"><li><div class="itemsShowHeaderStock_count stock"><span class="fa fa-thumbs-up"></span><span class="js-likecount">1271</span></div><div class="itemsShowHeaderStock_countText">Like</div></li><li><div class="itemsShowHeaderStock_count" content="0 UserComments" itemprop="commentCount"><span class="fa fa-comment"></span>0</div><div class="itemsShowHeaderStock_countText">Comment</div></li></ul></div><div class="js-likebutton" data-props="{&quot;like_status&quot;:false,&quot;like_count&quot;:1271,&quot;uuid&quot;:&quot;a4fc17eb3356a6068553&quot;,&quot;likable_type&quot;:&quot;Article&quot;,&quot;position&quot;:&quot;article-header&quot;}"></div><ul class="list-inline ArticleMainHeader__users"><li class="js-hovercard" data-hovercard-target-name="makipe"><a itemprop="url" href="/makipe"><img alt="makipe" class="thumb thumb--xs" src="https://qiita-image-store.s3.amazonaws.com/0/69821/profile-images/1473698272" /></a></li><li class="js-hovercard" data-hovercard-target-name="lyuich"><a itemprop="url" href="/lyuich"><img alt="lyuich" class="thumb thumb--xs" src="https://qiita-image-store.s3.amazonaws.com/0/73617/profile-images/1473699563" /></a></li><li class="js-hovercard" data-hovercard-target-name="cb400sp2"><a itemprop="url" href="/cb400sp2"><img alt="cb400sp2" class="thumb thumb--xs" src="https://qiita-image-store.s3.amazonaws.com/0/7821/profile-images/1473680740" /></a></li><li class="js-hovercard" data-hovercard-target-name="sasaki77"><a itemprop="url" href="/sasaki77"><img alt="sasaki77" class="thumb thumb--xs" src="https://qiita-image-store.s3.amazonaws.com/0/99572/profile-images/1473707832" /></a></li><li class="js-hovercard" data-hovercard-target-name="sayamada"><a itemprop="url" href="/sayamada"><img alt="sayamada" class="thumb thumb--xs" src="https://qiita-image-store.s3.amazonaws.com/0/44722/profile-images/1473690004" /></a></li><li class="js-hovercard" data-hovercard-target-name="sadayuki-matsuno"><a itemprop="url" href="/sadayuki-matsuno"><img alt="sadayuki-matsuno" class="thumb thumb--xs" src="https://qiita-image-store.s3.amazonaws.com/0/55672/profile-images/1473693753" /></a></li><li class="js-hovercard" data-hovercard-target-name="mamo"><a itemprop="url" href="/mamo"><img alt="mamo" class="thumb thumb--xs" src="https://qiita-image-store.s3.amazonaws.com/0/32284/profile-images/1475060588" /></a></li><li class="js-hovercard" data-hovercard-target-name="syuhei"><a itemprop="url" href="/syuhei"><img alt="syuhei" class="thumb thumb--xs" src="https://qiita-image-store.s3.amazonaws.com/0/20848/profile-images/1473683137" /></a></li><li class="js-hovercard" data-hovercard-target-name="takuti"><a itemprop="url" href="/takuti"><img alt="takuti" class="thumb thumb--xs" src="https://qiita-image-store.s3.amazonaws.com/0/32315/profile-images/1479023405" /></a></li><li class="js-hovercard" data-hovercard-target-name="knao124"><a itemprop="url" href="/knao124"><img alt="knao124" class="thumb thumb--xs" src="https://qiita-image-store.s3.amazonaws.com/0/32783/profile-images/1473685978" /></a></li><li><a href="/shu223/items/a4fc17eb3356a6068553/likers"><span class="fa fa-ellipsis-h"></span></a></li></ul></div></div></div></div><div class="ArticleAsideHeader"><div class="container"><div class="u-flex u-space-between"><div class="u-flex u-flex-wrap"><div class="u-flex u-align-center s-pdv-5 u-flex-wrap"><div class="ArticleAsideHeader__author"><a href="/shu223"><img class="thumb thumb--xs" src="https://qiita-image-store.s3.amazonaws.com/0/3180/profile-images/1473682733" alt="1473682733" /></a> <a class="u-link-unstyled" href="/shu223">shu223</a> </div><div class="ArticleAsideHeader__date"><meta content="2016-01-12T09:34:06+09:00" itemprop="datePublished" /><span data-toggle="tooltip" title="posted at 2016-01-12">Edited at <time datetime="2017-02-16T17:13:52+09:00" itemprop="dateModified">2017-02-16</time></span></div></div><div class="u-flex u-align-center s-pdv-5 mobile-hidden"><div class="ArticleAsideHeader__revision"> <a data-toggle="tooltip" title="Revisions" href="/shu223/items/a4fc17eb3356a6068553/revisions"><span class="fa fa-history"></span></a><span class="ArticleAsideHeader__revisionCount">4</span></div></div><div class="u-flex u-align-center s-pdv-5 mobile-hidden"></div></div><div class="u-flex u-align-center s-flex-justiry-between s-pdv-5 u-shrink-0"><div class="ArticleAsideHeader__stock"><div class="js-stockbutton" data-position="top" data-props="{&quot;stock_status&quot;:false}"></div></div><div class="dropdown"><a class="dropdown-toggle" data-toggle="dropdown" href="#"><span class="fa fa-ellipsis-h fa-lg"></span></a><ul class="dropdown-menu dropdown-menu-right"><li class="dropdown__item--mobile"><a href="/shu223/items/a4fc17eb3356a6068553/revisions"><span class="fa fa-fw fa-history"></span> Revisions<span>(4)</span></a></li><li><a href="/shu223/items/a4fc17eb3356a6068553.md"><span class="fa fa-fw fa-file-text-o"></span> Show article as Markdown</a></li><li><a data-target=".js-report-form" data-toggle="modal" href="#"><span class="fa fa-fw fa-flag"></span> Report article</a></li></ul></div></div></div></div></div><div class="container"><div class="row" id="article-body-wrapper"><div class="col-sm-9"><section class="markdownContent markdownContent-headingEnabled js-task-list-container clearfix position-relative" id="item-a4fc17eb3356a6068553" itemprop="articleBody"><p>「いつか勉強しよう」と人工知能／機械学習／ディープラーニング（Deep Learning）といったトピックの記事の見つけてはアーカイブしてきたものの、結局2015年は何一つやらずに終わってしまったので、とにかく一歩でも足を踏み出すべく、 <strong>本質的な理解等はさておき、とにかく試してみる</strong> ということをやってみました。</p>

<p>試したのは、TensorFlow、Chainer、Caffe といった機械学習およびディープラーニングの代表的なライブラリ／フレームワーク3種と、2015年に話題になったディープラーニングを利用したアプリケーション2種（DeepDream、chainer-gogh）。</p>

<p><a href="http://f.st-hatena.com/images/fotolife/s/shu223/20160105/20160105091448.jpg" target="_blank" rel="nofollow noopener"><img src="http://f.st-hatena.com/images/fotolife/s/shu223/20160105/20160105091448.jpg" width="600"></a></p>

<p><span class="deco">（DeepDreamで試した結果画像）</span></p>

<p>タイトルに半日と書きましたが、たとえばTensorFlowは<b>環境構築だけなら10分</b>もあれば終わるでしょうし、<b>Chainerなんてコマンド一発なので5秒</b>くらいです。Caffeは僕はハマりましたが、<b>うまくいった最短手順</b>を書いているので、同じ環境の方はすんなりいくかもしれません。</p>

<p>おすすめは、<strong>Chaffe &amp; DeepDream（要Caffe）は飛ばして、TensorFlow, Chainer&amp;画風変換を試す</strong> コースです。環境構築にハマらないので簡単に終わると思います（実行時間はかかりますが）。僕のように「気にはなってたけど全然触ってない」という方はぜひ今日の昼休みにでもお試しください！</p>

<p>試した環境：</p>

<ul>
<li>Mac OS X 10.11.1 El Capitan</li>
<li>Xcode 7.2 インストール済み</li>
</ul>

<h2>
<span id="tensorflow" class="fragment"></span><a href="#tensorflow"><i class="fa fa-link"></i></a>TensorFlow</h2>

<p>2015年11月に発表された、Google製の機械学習ライブラリ。「テンソルフロー」と読むそうです。同社のサービスでも実際に使われているとのこと。</p>

<blockquote>
<p>よく話を聞く音声認識や翻訳だけでなく、Googleフォトの被写体認識や顔認識、ウェブ検索結果の最適化、Gmailのメール分別、新生メールソフトInboxの自動返信文作成、さらにYouTubeや広告事業まで、ほとんどのプロダクトを支える新たな根幹技術となっています。</p>

<p>TensorFlow の特徴は、データフローグラフとして表せればなんでも処理でき、その気になればローレベルのオペレータも手書きできる汎用性、Googleの実製品で使われる高いパフォーマンス、CPUでもGPUでも走りノートPCから巨大なデータセンターまで同じコードで動きモバイル端末にもデプロイできるスケーラビリティ、計算機科学の研究から実プロダクトまで扱える効率性、ドキュメンテーションやサンプルが揃いPythonでもC++でも書ける扱いやすさなどなど。</p>
</blockquote>

<ul>
<li><a href="http://japanese.engadget.com/2015/11/09/google-tensorflow/" class="autolink" rel="nofollow noopener" target="_blank">http://japanese.engadget.com/2015/11/09/google-tensorflow/</a></li>
</ul>

<h3>
<span id="オープン化の狙い" class="fragment"></span><a href="#%E3%82%AA%E3%83%BC%E3%83%97%E3%83%B3%E5%8C%96%E3%81%AE%E7%8B%99%E3%81%84"><i class="fa fa-link"></i></a>オープン化の狙い</h3>

<p>ライセンスは商用利用も可能な Apache 2.0 で、自社製品のコアにもなっているこんなすごいものをなぜ Google はオープン化したのか？というところは気になるところです。</p>

<blockquote>
<p>TensorFlowをオープンソース化することで、学術研究者からエンジニア、趣味として取り組むユーザーまで、あらゆる人々の機械学習コミュニティーが、研究論文よりも動作するコードを介してアイデアを格段にすばやく交換できるようになると期待している。これが機械学習に関する研究の促進につながり、最終的に技術がすべての人々にとってより適切に機能するものになるだろう。さらに、TensorFlowの応用分野は機械学習だけにとどまらない。タンパク質のフォールディングから宇宙データの処理にいたるまで、非常に複雑なデータの解明に取り組むあらゆる分野の研究者らにとって有用であるかもしれない。</p>
</blockquote>

<ul>
<li><a href="http://japan.cnet.com/news/service/35073215/" class="autolink" rel="nofollow noopener" target="_blank">http://japan.cnet.com/news/service/35073215/</a></li>
</ul>

<blockquote>
<p>Googleいわく、機械学習はこれからの画期的なプロダクトや技術に欠かせない重要な要素となるもので、世界中で研究が進められているものの、標準となるツールが存在していないことが課題。Google では TensorFlow を研究者から学生、製品開発者まで使える標準ツールとして提供することで、機械学習や機械知能そのものの研究と普及を加速したい考えです。</p>
</blockquote>

<ul>
<li><a href="http://japanese.engadget.com/2015/11/09/google-tensorflow/" class="autolink" rel="nofollow noopener" target="_blank">http://japanese.engadget.com/2015/11/09/google-tensorflow/</a></li>
</ul>

<h3>
<span id="環境構築手順所要時間10分" class="fragment"></span><a href="#%E7%92%B0%E5%A2%83%E6%A7%8B%E7%AF%89%E6%89%8B%E9%A0%86%E6%89%80%E8%A6%81%E6%99%82%E9%96%9310%E5%88%86"><i class="fa fa-link"></i></a>環境構築手順（所要時間：10分）</h3>

<p>OS X El Capitan (10.11.1) へのインストール手順です。</p>

<ul>
<li><a href="https://www.tensorflow.org/versions/master/get_started/os_setup.html" class="autolink" rel="nofollow noopener" target="_blank">https://www.tensorflow.org/versions/master/get_started/os_setup.html</a></li>
</ul>

<h4>
<span id="1-pip-をインストール" class="fragment"></span><a href="#1-pip-%E3%82%92%E3%82%A4%E3%83%B3%E3%82%B9%E3%83%88%E3%83%BC%E3%83%AB"><i class="fa fa-link"></i></a>1. pip をインストール</h4>

<div class="code-frame" data-lang="bash"><div class="highlight"><pre>
<span class="nv">$ </span>sudo easy_install pip
</pre></div></div>

<h4>
<span id="2-virtualenv-をインストール" class="fragment"></span><a href="#2-virtualenv-%E3%82%92%E3%82%A4%E3%83%B3%E3%82%B9%E3%83%88%E3%83%BC%E3%83%AB"><i class="fa fa-link"></i></a>2. Virtualenv をインストール</h4>

<div class="code-frame" data-lang="bash"><div class="highlight"><pre>
<span class="nv">$ </span>sudo pip install --upgrade virtualenv
</pre></div></div>

<h4>
<span id="3-virtualenv-環境を作成" class="fragment"></span><a href="#3-virtualenv-%E7%92%B0%E5%A2%83%E3%82%92%E4%BD%9C%E6%88%90"><i class="fa fa-link"></i></a>3. Virtualenv 環境を作成</h4>

<div class="code-frame" data-lang="bash"><div class="highlight"><pre>
<span class="nv">$ </span>virtualenv --system-site-packages ~/tensorflow
</pre></div></div>

<p>（上記コマンドだと <code>~/tensorflow</code> につくられる）</p>

<h4>
<span id="4-つくった環境をアクティベート" class="fragment"></span><a href="#4-%E3%81%A4%E3%81%8F%E3%81%A3%E3%81%9F%E7%92%B0%E5%A2%83%E3%82%92%E3%82%A2%E3%82%AF%E3%83%86%E3%82%A3%E3%83%99%E3%83%BC%E3%83%88"><i class="fa fa-link"></i></a>4. つくった環境をアクティベート</h4>

<div class="code-frame" data-lang="bash"><div class="highlight"><pre>
<span class="nv">$ </span><span class="nb">source</span> ~/tensorflow/bin/activate
</pre></div></div>

<p>→ コマンドプロンプトが変わる</p>

<h4>
<span id="5-tensorflow-をインストール" class="fragment"></span><a href="#5-tensorflow-%E3%82%92%E3%82%A4%E3%83%B3%E3%82%B9%E3%83%88%E3%83%BC%E3%83%AB"><i class="fa fa-link"></i></a>5. TensorFlow をインストール</h4>

<div class="code-frame" data-lang="bash">
<div class="code-lang"><span class="bold">for_Python2.7</span></div>
<div class="highlight"><pre>
<span class="nv">$ </span>pip install --upgrade tensorflow
</pre></div>
</div>

<div class="code-frame" data-lang="bash">
<div class="code-lang"><span class="bold">for_Python3.n</span></div>
<div class="highlight"><pre>
<span class="nv">$ </span>pip3 install --upgrade tensorflow
</pre></div>
</div>

<blockquote>
<p>Successfully installed appdirs-1.4.0 numpy-1.12.0 packaging-16.8 protobuf-3.2.0 setuptools-34.2.0 tensorflow-1.0.0 wheel-0.29.0</p>
</blockquote>

<p>以上です。</p>

<h3>
<span id="動作確認hello-world-を実行してみる" class="fragment"></span><a href="#%E5%8B%95%E4%BD%9C%E7%A2%BA%E8%AA%8Dhello-world-%E3%82%92%E5%AE%9F%E8%A1%8C%E3%81%97%E3%81%A6%E3%81%BF%E3%82%8B"><i class="fa fa-link"></i></a>動作確認：Hello World を実行してみる</h3>

<p>スクリプトを作成し、適当なファイル名で保存します。</p>

<div class="code-frame" data-lang="python"><div class="highlight"><pre>
<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="kn">as</span> <span class="nn">tf</span>
<span class="kn">import</span> <span class="nn">multiprocessing</span> <span class="kn">as</span> <span class="nn">mp</span>

<span class="n">core_num</span> <span class="o">=</span> <span class="n">mp</span><span class="o">.</span><span class="n">cpu_count</span><span class="p">()</span>
<span class="n">config</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">ConfigProto</span><span class="p">(</span>
    <span class="n">inter_op_parallelism_threads</span><span class="o">=</span><span class="n">core_num</span><span class="p">,</span>
    <span class="n">intra_op_parallelism_threads</span><span class="o">=</span><span class="n">core_num</span> <span class="p">)</span>
<span class="n">sess</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Session</span><span class="p">(</span><span class="n">config</span><span class="o">=</span><span class="n">config</span><span class="p">)</span>

<span class="n">hello</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="s">'hello, tensorflow!'</span><span class="p">)</span>
<span class="k">print</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">hello</span><span class="p">)</span>
</pre></div></div>

<p>TensorFlow 環境で実行します。</p>

<div class="code-frame" data-lang="bash"><div class="highlight"><pre>
<span class="o">(</span>tensorflow<span class="o">)</span><span class="nv">$ </span>python <span class="o">{</span>ファイル名<span class="o">}</span>.py
</pre></div></div>

<p>実行結果：</p>

<div class="code-frame" data-lang="text"><div class="highlight"><pre>
I tensorflow/core/common_runtime/local_device.cc:25] Local device intra op parallelism threads: 4
I tensorflow/core/common_runtime/local_session.cc:45] Local session inter op parallelism threads: 4
hello, tensorflow!
</pre></div></div>

<p>参考ページ：</p>

<ul>
<li><a href="http://dev.classmethod.jp/machine-learning/tensorflow-hello-world/" class="autolink" rel="nofollow noopener" target="_blank">http://dev.classmethod.jp/machine-learning/tensorflow-hello-world/</a></li>
</ul>

<h3>
<span id="手書き数字を学習してみる" class="fragment"></span><a href="#%E6%89%8B%E6%9B%B8%E3%81%8D%E6%95%B0%E5%AD%97%E3%82%92%E5%AD%A6%E7%BF%92%E3%81%97%E3%81%A6%E3%81%BF%E3%82%8B"><i class="fa fa-link"></i></a>手書き数字を学習してみる</h3>

<p>TensorFlow オフィシャルページに、「<a href="https://www.tensorflow.org/versions/master/tutorials/mnist/beginners/index.html" rel="nofollow noopener" target="_blank">MNIST For ML Beginners</a>」という手書き文字データセットを利用したチュートリアルがあります。</p>

<p><a href="http://f.st-hatena.com/images/fotolife/s/shu223/20160105/20160105090618.png" target="_blank" rel="nofollow noopener"><img src="http://f.st-hatena.com/images/fotolife/s/shu223/20160105/20160105090618.png" alt=""></a></p>

<p><span class="deco">（MNISTデータセット）</span></p>

<p>ここでは一番手っ取り早そうな、公式チュートリアルのコード（GitHubにある）を実行する方法を試すことにします。</p>

<p>ソースコードを clone してきて、</p>

<div class="code-frame" data-lang="bash"><div class="highlight"><pre>
<span class="nv">$ </span>git clone --recurse-submodules https://github.com/tensorflow/tensorflow
</pre></div></div>

<p>fully_connected_feed.py の30,31行目を次のように修正します。<sup id="fnref1"><a href="#fn1" rel="footnote" title='これをやらないと、実行時に "ImportError: No module named examples.tutorials.mnist" というエラーが出ます。'>1</a></sup></p>

<ul>
<li>修正前</li>
</ul>

<div class="code-frame" data-lang="python"><div class="highlight"><pre>
<span class="kn">from</span> <span class="nn">tensorflow.examples.tutorials.mnist</span> <span class="kn">import</span> <span class="n">input_data</span>
<span class="kn">from</span> <span class="nn">tensorflow.examples.tutorials.mnist</span> <span class="kn">import</span> <span class="n">mnist</span>
</pre></div></div>

<ul>
<li>修正後</li>
</ul>

<div class="code-frame" data-lang="python"><div class="highlight"><pre>
<span class="kn">import</span> <span class="nn">input_data</span>
<span class="kn">import</span> <span class="nn">mnist</span>
</pre></div></div>

<p>fully_connected_feed.py を実行します。</p>

<div class="code-frame" data-lang="bash"><div class="highlight"><pre>
<span class="nv">$ </span><span class="nb">cd </span>tensorflow/
<span class="nv">$ </span>python tensorflow/examples/tutorials/mnist/fully_connected_feed.py 
</pre></div></div>

<p>MNISTデータセットを手動でダウンロードしたりする必要はなく、このスクリプトが<b>データセットの取得からモデルの学習まで</b>やってくれます。</p>

<p>実行結果：</p>

<div class="code-frame" data-lang="text"><div class="highlight"><pre>
Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.
Extracting data/train-images-idx3-ubyte.gz
//中略
Step 0: loss = 2.32 (0.025 sec)
Step 100: loss = 2.19 (0.003 sec)
Step 200: loss = 1.97 (0.003 sec)
//中略
Step 1900: loss = 0.46 (0.004 sec)
Training Data Eval:
  Num examples: 55000  Num correct: 49489  Precision @ 1: 0.8998
Validation Data Eval:
  Num examples: 5000  Num correct: 4534  Precision @ 1: 0.9068
Test Data Eval:
  Num examples: 10000  Num correct: 9019  Precision @ 1: 0.9019
</pre></div></div>

<p>データセットのダウンロード、トレーニング、テストデータでの評価が行われています。最終的な精度は約90%。</p>

<p>参考ページ：</p>

<ul>
<li><a href="http://nextdeveloper.hatenablog.com/entry/2015/11/10/204609" class="autolink" rel="nofollow noopener" target="_blank">http://nextdeveloper.hatenablog.com/entry/2015/11/10/204609</a></li>
<li><a href="http://qiita.com/sergeant-wizard/items/fdf4d64a0d221a81da34" class="autolink" id="reference-46c52b084ca91314f23c">http://qiita.com/sergeant-wizard/items/fdf4d64a0d221a81da34</a></li>
</ul>

<h3>
<span id="学習結果を可視化する-tensorboard-を試す" class="fragment"></span><a href="#%E5%AD%A6%E7%BF%92%E7%B5%90%E6%9E%9C%E3%82%92%E5%8F%AF%E8%A6%96%E5%8C%96%E3%81%99%E3%82%8B-tensorboard-%E3%82%92%E8%A9%A6%E3%81%99"><i class="fa fa-link"></i></a>学習結果を可視化する TensorBoard を試す</h3>

<p>なんと、学習結果をグラフにしてくれたり、モデルをビジュアライズして表示してくれる TensorBoard というものも用意してくれているようです。</p>

<p>学習経過のログデータのあるディレクトリを<b>絶対パスで</b>指定 <sup id="fnref2"><a href="#fn2" rel="footnote" title="パスが間違ってても TensorBoard は起動するのですが、アクセスしてもグラフ等は表示されません。">2</a></sup> して <code>tensorboard</code> コマンドを実行すると、</p>

<div class="code-frame" data-lang="bash"><div class="highlight"><pre>
<span class="nv">$ </span>tensorboard --logdir<span class="o">=</span>/Users/xxxx/xxxx/tensorflow/tensorflow/data
</pre></div></div>

<p>TensorBoard が起動します。</p>

<div class="code-frame" data-lang="text"><div class="highlight"><pre>
Starting TensorBoard on port 6006
(You can navigate to http://localhost:6006)
</pre></div></div>

<p>で、このURLにブラウザからアクセスするとGUIが表示され、</p>

<p>学習回数とxentropy_mean（交差エントロピー）の関係を示すグラフや、</p>

<p><a href="http://f.st-hatena.com/images/fotolife/s/shu223/20160105/20160105090658.jpg" target="_blank" rel="nofollow noopener"><img src="http://f.st-hatena.com/images/fotolife/s/shu223/20160105/20160105090658.jpg" width="400"></a></p>

<p>モデル（ニューラルネットワーク）を可視化したものを見ることができます。</p>

<p><a href="http://f.st-hatena.com/images/fotolife/s/shu223/20160105/20160105090721.jpg" target="_blank" rel="nofollow noopener"><img src="http://f.st-hatena.com/images/fotolife/s/shu223/20160105/20160105090721.jpg" width="538"></a></p>

<h3>
<span id="more" class="fragment"></span><a href="#more"><i class="fa fa-link"></i></a>More</h3>

<ul>
<li><a href="http://qiita.com/shuhei_f/items/9251084b00ed9319033e" class="autolink" id="reference-62f5778dc6e62008a60c">http://qiita.com/shuhei_f/items/9251084b00ed9319033e</a></li>
<li>
<a href="http://qiita.com/uramonk/items/c207c948ccb6cd0a1346" class="autolink" id="reference-e5673ac9b8dd40f0cf08">http://qiita.com/uramonk/items/c207c948ccb6cd0a1346</a>

<ul>
<li>チュートリアルのコードをコメントで解説してくれています</li>
</ul>
</li>
<li>
<a href="http://qiita.com/haminiku/items/36982ae65a770565458d" class="autolink" id="reference-c79706199501a670fa17">http://qiita.com/haminiku/items/36982ae65a770565458d</a>

<ul>
<li>上級チュートリアルの解説もあり</li>
</ul>
</li>
<li>
<a href="http://d.hatena.ne.jp/sugyan/20151124/1448292129" class="autolink" rel="nofollow noopener" target="_blank">http://d.hatena.ne.jp/sugyan/20151124/1448292129</a>

<ul>
<li>
<b>学習結果を使って自分で書いた数字を識別してもらう</b>ところまで試されています</li>
<li>コードも公開</li>
</ul>
</li>
</ul>

<h2>
<span id="chainer" class="fragment"></span><a href="#chainer"><i class="fa fa-link"></i></a>Chainer</h2>

<p>Preferred Networks社が開発したニューラルネットワークを実装するためのライブラリ。2015年6月公開。特徴としては、</p>

<ul>
<li>Python のライブラリとして提供</li>
<li>あらゆるニューラルネットの構造に柔軟に対応</li>
<li>動的な計算グラフ構築による直感的なコード</li>
<li>GPU をサポートし、複数 GPU をつかった学習も直感的に記述可能</li>
</ul>

<p>が挙げられています。</p>

<ul>
<li><a href="https://research.preferred.jp/2015/06/deep-learning-chainer/" class="autolink" rel="nofollow noopener" target="_blank">https://research.preferred.jp/2015/06/deep-learning-chainer/</a></li>
</ul>

<h3>
<span id="tensorflow-との比較" class="fragment"></span><a href="#tensorflow-%E3%81%A8%E3%81%AE%E6%AF%94%E8%BC%83"><i class="fa fa-link"></i></a>TensorFlow との比較</h3>

<p>上記特徴を見ると TensorFlow とポジショニング的には似ているように見えたので、どんな違いがあるのかググッてみました。</p>

<blockquote>
<p>たぶんできることそのものに大きな違いはないんだろうけど、Chainerの場合マルチGPUにするときには自分でGPUの管理をしなきゃなんないのが、TenrorFlowだともうちょっとラクなのかなあと思ったりする。</p>
</blockquote>

<ul>
<li><a href="http://d.hatena.ne.jp/shi3z/20151122/1448150781" class="autolink" rel="nofollow noopener" target="_blank">http://d.hatena.ne.jp/shi3z/20151122/1448150781</a></li>
</ul>

<blockquote>
<p>TensorFlow、GPU使うのにリビルドが必要で、そのためにbazelが必要で、そのためにJava8が必要で、しかもGPUにCC3.5以上の制約があるみたいで、使えるなら使えば？感が凄い。同じPythonならChainerの方が敷居が低く感じる。 </p>
</blockquote>

<ul>
<li><a href="https://twitter.com/hrmk/status/663935918768656384" class="autolink" rel="nofollow noopener" target="_blank">https://twitter.com/hrmk/status/663935918768656384</a></li>
</ul>

<blockquote>
<p>TensorFlowはDistBeliefの2倍の速いそうなのですが、Chainerはそれを上回っていました。</p>

<p>記述量的にはそこまで変わらないですし個人的にはChainerの方が扱い易いというのが感想です(慣れの問題だとは思いますが。)。</p>
</blockquote>

<ul>
<li><a href="http://blog.albert2005.co.jp/2015/11/12/tensorflow%E3%81%A8chainer%E3%81%AE%E6%AF%94%E8%BC%83/" class="autolink" rel="nofollow noopener" target="_blank">http://blog.albert2005.co.jp/2015/11/12/tensorflow%E3%81%A8chainer%E3%81%AE%E6%AF%94%E8%BC%83/</a></li>
</ul>

<blockquote>
<p>TensorFlow,Chainerとも精度は同じでした。そもそもMNISTは問題が簡単なのでDeep Learningでなくても高い精度が出るそうです。実行時間はChainerの方が速かったのです。</p>
</blockquote>

<ul>
<li><a href="http://qiita.com/supersaiakujin/items/bc05b9f329aca48329ac" class="autolink" id="reference-3693cda6fbeae35f24fe">http://qiita.com/supersaiakujin/items/bc05b9f329aca48329ac</a></li>
</ul>

<h3>
<span id="インストール手順所要時間5秒" class="fragment"></span><a href="#%E3%82%A4%E3%83%B3%E3%82%B9%E3%83%88%E3%83%BC%E3%83%AB%E6%89%8B%E9%A0%86%E6%89%80%E8%A6%81%E6%99%82%E9%96%935%E7%A7%92"><i class="fa fa-link"></i></a>インストール手順（所要時間：5秒）</h3>

<p>公式ドキュメントに <a href="http://docs.chainer.org/en/stable/install.html" rel="nofollow noopener" target="_blank">Install Guide</a> というページがあるのですが、Ubuntu, CentOS 向けに書かれているようなので、Mac向けのはないかなと探してたら、本家Webサイトに QUICK START という項目がありました。</p>

<ul>
<li><a href="http://chainer.org/" class="autolink" rel="nofollow noopener" target="_blank">http://chainer.org/</a></li>
</ul>

<p>やることは</p>

<div class="code-frame" data-lang="bash"><div class="highlight"><pre>
<span class="nv">$ </span>pip install chainer
</pre></div></div>

<p>これだけ。</p>

<div class="code-frame" data-lang="text"><div class="highlight"><pre>
Successfully installed chainer-1.5.1 filelock-2.0.5
</pre></div></div>

<p>素晴らしい！</p>

<h3>
<span id="手書き数字を学習してみる-1" class="fragment"></span><a href="#%E6%89%8B%E6%9B%B8%E3%81%8D%E6%95%B0%E5%AD%97%E3%82%92%E5%AD%A6%E7%BF%92%E3%81%97%E3%81%A6%E3%81%BF%E3%82%8B-1"><i class="fa fa-link"></i></a>手書き数字を学習してみる</h3>

<p>公式リポジトリにサンプルが用意されています。cloneしてきてスクリプトを実行するだけ。</p>

<div class="code-frame" data-lang="bash"><div class="highlight"><pre>
<span class="nv">$ </span>git clone https://github.com/pfnet/chainer.git
<span class="nv">$ </span>python chainer/examples/mnist/train_mnist.py
</pre></div></div>

<p>MNISTデータセットのダウンロードと、学習、テストが行われます。</p>

<div class="code-frame" data-lang="text"><div class="highlight"><pre>
load MNIST dataset
Downloading train-images-idx3-ubyte.gz...
（中略）
epoch 1
graph generated
train mean loss=0.190947790003, accuracy=0.942850003242
test  mean loss=0.0990746175707, accuracy=0.96930000484
（中略）
epoch 20
train mean loss=0.0104963570454, accuracy=0.996966669559
test  mean loss=0.102703116325, accuracy=0.982000006437
</pre></div></div>

<p>最終的な識別精度は98%になったようです。</p>

<h3>
<span id="more-1" class="fragment"></span><a href="#more-1"><i class="fa fa-link"></i></a>More</h3>

<ul>
<li><a href="http://cvl-robot.hateblo.jp/entry/2015/06/11/223928" class="autolink" rel="nofollow noopener" target="_blank">http://cvl-robot.hateblo.jp/entry/2015/06/11/223928</a></li>
<li><a href="http://hi-king.hatenablog.com/entry/2015/06/11/021144" class="autolink" rel="nofollow noopener" target="_blank">http://hi-king.hatenablog.com/entry/2015/06/11/021144</a></li>
<li><a href="http://hi-king.hatenablog.com/entry/2015/06/27/194630" class="autolink" rel="nofollow noopener" target="_blank">http://hi-king.hatenablog.com/entry/2015/06/27/194630</a></li>
<li><a href="http://qiita.com/icoxfog417/items/96ecaff323434c8d677b" class="autolink" id="reference-c0d85905e9b2960180a8">http://qiita.com/icoxfog417/items/96ecaff323434c8d677b</a></li>
<li><a href="http://qiita.com/mokemokechicken/items/cc9b2c96f6e4a43c123c" class="autolink" id="reference-5d039335d628ad78f33d">http://qiita.com/mokemokechicken/items/cc9b2c96f6e4a43c123c</a></li>
<li><a href="http://d.hatena.ne.jp/shi3z/20150628/1435502562" class="autolink" rel="nofollow noopener" target="_blank">http://d.hatena.ne.jp/shi3z/20150628/1435502562</a></li>
<li><a href="http://studylog.hateblo.jp/entry/2015/07/14/000635" class="autolink" rel="nofollow noopener" target="_blank">http://studylog.hateblo.jp/entry/2015/07/14/000635</a></li>
</ul>

<h2>
<span id="caffe" class="fragment"></span><a href="#caffe"><i class="fa fa-link"></i></a>Caffe</h2>

<p>C++で実装されたディープラーニングのオープンソースライブラリ。カリフォルニア大学バークレー校の研究センターBVLCが中心となって開発、C++・Python・MATLABで利用可能。</p>

<p>具体的な公開日はわかりませんが、ChainerやTensorFlowの登場以前から存在する分、ネットで見つかるおもしろそうなディープラーニングを利用した研究や試みはCaffeをベースにしたものを多く見かける気がします。</p>

<h3>
<span id="環境構築手順所要時間約4時間" class="fragment"></span><a href="#%E7%92%B0%E5%A2%83%E6%A7%8B%E7%AF%89%E6%89%8B%E9%A0%86%E6%89%80%E8%A6%81%E6%99%82%E9%96%93%E7%B4%844%E6%99%82%E9%96%93"><i class="fa fa-link"></i></a>環境構築手順（所要時間：約4時間）</h3>

<p>所要時間は個人差（環境差）があると思いますが、<strong>確実にTensorFlowやChainerよりは時間がかかる</strong> と思います。依存ライブラリが多く、その中にはインストールの待ち時間が長いものがありますし、各自の環境に依存した設定を手動で行う必要があるので、そのあたりでハマることもあると思います。また個人的にはnumpyのバージョンが違うというエラーにかなり悩まされました。</p>

<p>GPUが絡むとハマりそうなのでCPUモードで、インストールしていきます。PyCaffeも入れます。</p>

<h4>
<span id="1-諸々インストール" class="fragment"></span><a href="#1-%E8%AB%B8%E3%80%85%E3%82%A4%E3%83%B3%E3%82%B9%E3%83%88%E3%83%BC%E3%83%AB"><i class="fa fa-link"></i></a>1. 諸々インストール</h4>

<div class="code-frame" data-lang="bash"><div class="highlight"><pre>
<span class="nv">$ </span>brew install --fresh -vd snappy leveldb gflags glog szip lmdb
<span class="nv">$ </span>brew tap homebrew/science
<span class="nv">$ </span>brew install hdf5 opencv
<span class="nv">$ </span>brew install --build-from-source --with-python --fresh -vd protobuf
<span class="nv">$ </span>brew install --build-from-source --fresh -vd boost boost-python
<span class="nv">$ </span>brew install openblas
</pre></div></div>

<p><span class="deco">※1 opencv のインストールはかなり時間がかかります。</span></p>

<p><span class="deco">※2 OpenBLAS は入れなくてもいいそうですが（Macでは標準でBLASが入っているとのこと）、この後の手順で Makefile の <code>BLAS_INCLUDE</code> のパスを修正したりしてから make を実行しても <code>fatal error: 'cblas.h' file not found</code> が出てしまうので、入れることにしました。</span></p>

<h4>
<span id="2-caffe-をclone" class="fragment"></span><a href="#2-caffe-%E3%82%92clone"><i class="fa fa-link"></i></a>2. caffe をclone</h4>

<div class="code-frame" data-lang="bash"><div class="highlight"><pre>
<span class="nv">$ </span>git clone https://github.com/BVLC/caffe.git
</pre></div></div>

<h4>
<span id="3-makefileconfig-作成" class="fragment"></span><a href="#3-makefileconfig-%E4%BD%9C%E6%88%90"><i class="fa fa-link"></i></a>3. Makefile.config 作成</h4>

<p>雛形からコピーしてきて、編集します。</p>

<div class="code-frame" data-lang="bash"><div class="highlight"><pre>
<span class="nv">$ </span><span class="nb">cd </span>caffe
<span class="nv">$ </span>cp Makefile.config.example Makefile.config
</pre></div></div>

<ul>
<li>
<code># CPU_ONLY := 1</code> のコメントアウトを外す</li>
<li>
<code>BLAS := atlas</code> を <code>BLAS := open</code> に変更する</li>
<li>以下のコメントアウトを外す</li>
</ul>

<div class="code-frame" data-lang="text"><div class="highlight"><pre>
# BLAS_INCLUDE := $(shell brew --prefix openblas)/include
# BLAS_LIB := $(shell brew --prefix openblas)/lib
</pre></div></div>

<ul>
<li>
<code>PYTHON_INCLUDE</code> のパスを自分の環境に合わせて書き換える <sup id="fnref3"><a href="#fn3" rel="footnote" title="/usr/include が最近のOSXでなくなってることに関しては、$ xcode-select --install をすればいいみたいなのですが、古いコマンドラインツールをダウンロードしないといけないっぽく、あまりXcodeまわりの環境をいじりたくないので直接pythonのincludeパスを指定するようにしました">3</a></sup>

<ul>
<li>修正前
<code>
PYTHON_INCLUDE := /usr/include/python2.7 \
/usr/lib/python2.7/dist-packages/numpy/core/include
</code>
</li>
<li>修正後
<code>
PYTHON_INCLUDE := /usr/local/Cellar/python/2.7.11/Frameworks/Python.framework/Versions/2.7/include/python2.7 \
/usr/local/lib/python2.7/site-packages/numpy/core/include/
</code>
</li>
</ul>
</li>
</ul>

<h4>
<span id="4-ビルドテスト" class="fragment"></span><a href="#4-%E3%83%93%E3%83%AB%E3%83%89%E3%83%86%E3%82%B9%E3%83%88"><i class="fa fa-link"></i></a>4. ビルド＆テスト</h4>

<div class="code-frame" data-lang="bash"><div class="highlight"><pre>
<span class="nv">$ </span>make clean
<span class="nv">$ </span>make all -j4
<span class="nv">$ </span>make <span class="nb">test</span> -j4
<span class="nv">$ </span>make runtest
</pre></div></div>

<p>ここでエラーがでなければインストール成功です。</p>

<div class="code-frame" data-lang="text"><div class="highlight"><pre>
[  PASSED  ] 927 tests.
</pre></div></div>

<h4>
<span id="5-pycaffe-に必要なライブラリをインストール" class="fragment"></span><a href="#5-pycaffe-%E3%81%AB%E5%BF%85%E8%A6%81%E3%81%AA%E3%83%A9%E3%82%A4%E3%83%96%E3%83%A9%E3%83%AA%E3%82%92%E3%82%A4%E3%83%B3%E3%82%B9%E3%83%88%E3%83%BC%E3%83%AB"><i class="fa fa-link"></i></a>5. PyCaffe に必要なライブラリをインストール</h4>

<p>caffe/python フォルダに移動し、PyCaffe に必要なライブラリをインストールします。</p>

<div class="code-frame" data-lang="bash"><div class="highlight"><pre>
<span class="nv">$ </span><span class="nb">cd </span>python/
<span class="nv">$ </span><span class="k">for</span> li in <span class="k">$(</span>cat requirements.txt<span class="k">)</span><span class="p">;</span> <span class="k">do</span> sudo pip install <span class="nv">$li</span><span class="p">;</span> <span class="k">done</span> 
</pre></div></div>

<h4>
<span id="6-pycaffe-のビルド" class="fragment"></span><a href="#6-pycaffe-%E3%81%AE%E3%83%93%E3%83%AB%E3%83%89"><i class="fa fa-link"></i></a>6. PyCaffe のビルド</h4>

<div class="code-frame" data-lang="bash"><div class="highlight"><pre>
<span class="nv">$ </span><span class="nb">cd</span> ../
<span class="nv">$ </span>make pycaffe
<span class="nv">$ </span>make distribute
</pre></div></div>

<h4>
<span id="7-環境変数を設定" class="fragment"></span><a href="#7-%E7%92%B0%E5%A2%83%E5%A4%89%E6%95%B0%E3%82%92%E8%A8%AD%E5%AE%9A"><i class="fa fa-link"></i></a>7. 環境変数を設定</h4>

<p>Caffe用の環境変数を設定します。~/.bashrc に下記を追記し、</p>

<div class="code-frame" data-lang="text"><div class="highlight"><pre>
export PYTHONPATH={caffe/pythonのパス}:$PYTHONPATH
</pre></div></div>

<p><code>source ~/.bashrc</code> で反映します。</p>

<h4>
<span id="8-動作確認" class="fragment"></span><a href="#8-%E5%8B%95%E4%BD%9C%E7%A2%BA%E8%AA%8D"><i class="fa fa-link"></i></a>8. 動作確認</h4>

<p>PythonのインタプリタからCaffeをimportしてみて、問題が起きなければOK。</p>

<div class="code-frame" data-lang="bash"><div class="highlight"><pre>
<span class="nv">$ </span>python 
&gt;&gt;&gt; import caffe
</pre></div></div>

<p>ちなみに本記事では最終的にうまくいった手順のみを書いていますが、<strong>大いにハマったトラブルシューティングの過程</strong> も別記事として書いておきました。</p>

<ul>
<li><a href="http://d.hatena.ne.jp/shu223/20160103/1452000295" rel="nofollow noopener" target="_blank">Caffe（PyCaffe）のインストールでハマったメモ - Over&amp;Out その後</a></li>
</ul>

<h4>
<span id="参考ページ" class="fragment"></span><a href="#%E5%8F%82%E8%80%83%E3%83%9A%E3%83%BC%E3%82%B8"><i class="fa fa-link"></i></a>参考ページ：</h4>

<ul>
<li>
<a href="http://caffe.berkeleyvision.org/install_osx.html" class="autolink" rel="nofollow noopener" target="_blank">http://caffe.berkeleyvision.org/install_osx.html</a> （公式ページ）</li>
<li><a href="http://qiita.com/t-hiroyoshi/items/3bba01dd11b1241f1336" class="autolink" id="reference-6d85d4c6c24a3b1a1941">http://qiita.com/t-hiroyoshi/items/3bba01dd11b1241f1336</a></li>
<li><a href="http://qiita.com/knao124/items/c76e974cfbaabb5542e8" class="autolink" id="reference-64a0c3a95a434133842b">http://qiita.com/knao124/items/c76e974cfbaabb5542e8</a></li>
<li><a href="http://ichyo.jp/posts/caffe-install/" class="autolink" rel="nofollow noopener" target="_blank">http://ichyo.jp/posts/caffe-install/</a></li>
</ul>

<h2>
<span id="deepdream" class="fragment"></span><a href="#deepdream"><i class="fa fa-link"></i></a>DeepDream</h2>

<p>ここからひとつレイヤーは上がって、ディープラーニングライブラリ／フレームワークを利用した応用アプリケーション的なものをいくつか試してみます。</p>

<p>DeepDream は <a href="http://googleresearch.blogspot.jp/2015/07/deepdream-code-example-for-visualizing.html" rel="nofollow noopener" target="_blank">2015年7月にGoogleが公開</a> したOSSで、</p>

<blockquote>
<p>画像から少しでも見覚えのある物体を見つけ出し、それを再構成して出力する</p>

<p>人工神経回路網は10～30のレイヤーから構成されており、1枚目のレイヤーは画像の情報をインプットして「角」や「端」を探し、2枚目・3枚目と続くレイヤーは基本的な物体の情報を把握、最終的なレイヤーが情報を組み立てて物体が「何か」を判断する、という仕組みです。</p>
</blockquote>

<ul>
<li><a href="http://gigazine.net/news/20150707-deep-dreaming-fear/" class="autolink" rel="nofollow noopener" target="_blank">http://gigazine.net/news/20150707-deep-dreaming-fear/</a></li>
</ul>

<p>というもの。</p>

<h3>
<span id="環境構築の手順所要時間10分" class="fragment"></span><a href="#%E7%92%B0%E5%A2%83%E6%A7%8B%E7%AF%89%E3%81%AE%E6%89%8B%E9%A0%86%E6%89%80%E8%A6%81%E6%99%82%E9%96%9310%E5%88%86"><i class="fa fa-link"></i></a>環境構築の手順（所要時間：10分）</h3>

<p><strong>要Caffe</strong>（インストール手順は上述）。Caffeさえ入っていればさっくり試せます。</p>

<h4>
<span id="1-ipython-notebook-をインストール-4" class="fragment"></span><a href="#1-ipython-notebook-%E3%82%92%E3%82%A4%E3%83%B3%E3%82%B9%E3%83%88%E3%83%BC%E3%83%AB-4"><i class="fa fa-link"></i></a>1. iPython notebook をインストール <sup id="fnref4"><a href="#fn4" rel="footnote" title="なぜか ipython: command not found になったので こちら を参考にインストールしなおしました">4</a></sup>
</h4>

<div class="code-frame" data-lang="bash"><div class="highlight"><pre>
<span class="nv">$ </span>pip install ipython
<span class="nv">$ </span>pip install ipython<span class="o">[</span>notebook<span class="o">]</span>
</pre></div></div>

<h4>
<span id="2-deepdream-を-clone" class="fragment"></span><a href="#2-deepdream-%E3%82%92-clone"><i class="fa fa-link"></i></a>2. DeepDream を clone</h4>

<p>Caffe のあるフォルダと同階層に DeepDream のソースを clone します。</p>

<div class="code-frame" data-lang="bash"><div class="highlight"><pre>
<span class="nv">$ </span>git clone git@github.com:google/deepdream.git
</pre></div></div>

<h4>
<span id="3-モデルをダウンロード" class="fragment"></span><a href="#3-%E3%83%A2%E3%83%87%E3%83%AB%E3%82%92%E3%83%80%E3%82%A6%E3%83%B3%E3%83%AD%E3%83%BC%E3%83%89"><i class="fa fa-link"></i></a>3. モデルをダウンロード</h4>

<p><a href="http://dl.caffe.berkeleyvision.org/bvlc_googlenet.caffemodel" rel="nofollow noopener" target="_blank">ここ</a> から学習済みのcaffeモデルをダウンロードし、{caffeのパス}/models/bvlc_googlenet/ に保存します。</p>

<h3>
<span id="試す" class="fragment"></span><a href="#%E8%A9%A6%E3%81%99"><i class="fa fa-link"></i></a>試す</h3>

<p>cloneしてきたdeepdreamフォルダに移動し、iPython notebookを起動します。</p>

<div class="code-frame" data-lang="bash"><div class="highlight"><pre>
<span class="nv">$ </span><span class="nb">cd </span>deepdream
<span class="nv">$ </span>ipython trust dream.ipynb
<span class="nv">$ </span>ipython notebook
</pre></div></div>

<p>ブラウザが立ち上がるので、dream.ipynb を選択して、上部にある再生ボタンをポチポチ押していき、最後まで到達したらしばらく待っていると・・・ deepdream/frames/ フォルダに結果画像が 0000.jpg, 0001.jpg, ...と出力されていきます。</p>

<p><a href="http://f.st-hatena.com/images/fotolife/s/shu223/20160105/20160105091354.jpg" target="_blank" rel="nofollow noopener"><img src="http://f.st-hatena.com/images/fotolife/s/shu223/20160105/20160105091354.jpg" width="600"></a></p>

<p><span class="deco">（左：0000.jpg と、右 0010.jpg）</span></p>

<p>手っ取り早く好きな画像で試したい場合は、sky1024px.jpg にリネームして同じ場所に置いておけばOKです。または dream.ipynb の画像名を指定している箇所を編集します。</p>

<p>さわやかな食事風景が、</p>

<p><a href="http://f.st-hatena.com/images/fotolife/s/shu223/20160105/20160105091426.jpg" target="_blank" rel="nofollow noopener"><img src="http://f.st-hatena.com/images/fotolife/s/shu223/20160105/20160105091426.jpg" width="600"></a></p>

<p>こうなりました。</p>

<p><a href="http://f.st-hatena.com/images/fotolife/s/shu223/20160105/20160105091448.jpg" target="_blank" rel="nofollow noopener"><img src="http://f.st-hatena.com/images/fotolife/s/shu223/20160105/20160105091448.jpg" width="600"></a></p>

<p>参考記事：</p>

<ul>
<li><a href="http://qiita.com/t-hiroyoshi/items/e556c4ca0e8631556584" class="autolink" id="reference-db6b512ba4614741728d">http://qiita.com/t-hiroyoshi/items/e556c4ca0e8631556584</a></li>
<li><a href="http://qiita.com/icoxfog417/items/175f69d06f4e590face9" class="autolink" id="reference-ebaa078cef0aac972ba8">http://qiita.com/icoxfog417/items/175f69d06f4e590face9</a></li>
</ul>

<h2>
<span id="画風変換アルゴリズム-chainer-gogh" class="fragment"></span><a href="#%E7%94%BB%E9%A2%A8%E5%A4%89%E6%8F%9B%E3%82%A2%E3%83%AB%E3%82%B4%E3%83%AA%E3%82%BA%E3%83%A0-chainer-gogh"><i class="fa fa-link"></i></a>画風変換アルゴリズム chainer-gogh</h2>

<p>mattya氏が2015年9月に公開した、Deep Neural Networkを使って画像を好きな画風に変換できるプログラム。</p>

<ul>
<li><a href="https://research.preferred.jp/2015/09/chainer-gogh/" class="autolink" rel="nofollow noopener" target="_blank">https://research.preferred.jp/2015/09/chainer-gogh/</a></li>
</ul>

<p>Chainerを利用。アルゴリズムの元論文は <a href="http://arxiv.org/abs/1508.06576" rel="nofollow noopener" target="_blank">A Neural Algorithm of Artistic Style</a> 。</p>

<h3>
<span id="環境構築の手順所要時間1分" class="fragment"></span><a href="#%E7%92%B0%E5%A2%83%E6%A7%8B%E7%AF%89%E3%81%AE%E6%89%8B%E9%A0%86%E6%89%80%E8%A6%81%E6%99%82%E9%96%931%E5%88%86"><i class="fa fa-link"></i></a>環境構築の手順（所要時間：1分）</h3>

<h4>
<span id="1-ソースを-clone" class="fragment"></span><a href="#1-%E3%82%BD%E3%83%BC%E3%82%B9%E3%82%92-clone"><i class="fa fa-link"></i></a>1. ソースを clone</h4>

<div class="code-frame" data-lang="bash"><div class="highlight"><pre>
<span class="nv">$ </span>git clone https://github.com/mattya/chainer-gogh.git
</pre></div></div>

<h4>
<span id="2-モデルをダウンロード" class="fragment"></span><a href="#2-%E3%83%A2%E3%83%87%E3%83%AB%E3%82%92%E3%83%80%E3%82%A6%E3%83%B3%E3%83%AD%E3%83%BC%E3%83%89"><i class="fa fa-link"></i></a>2. モデルをダウンロード</h4>

<p>モデルを下記URLからダウンロードし、cloneしてきた chainer-gogh フォルダ配下に置きます。</p>

<ul>
<li><a href="https://gist.github.com/mavenlin/d802a5849de39225bcc6" class="autolink" rel="nofollow noopener" target="_blank">https://gist.github.com/mavenlin/d802a5849de39225bcc6</a></li>
</ul>

<h3>
<span id="実行する" class="fragment"></span><a href="#%E5%AE%9F%E8%A1%8C%E3%81%99%E3%82%8B"><i class="fa fa-link"></i></a>実行する</h3>

<p>お手軽にCPU実行してみます。コンテンツ画像（input.png）とスタイル画像（style.png）を用意して chainer-gogh フォルダ配下に置き、スクリプトを実行するだけ。</p>

<div class="code-frame" data-lang="bash"><div class="highlight"><pre>
python chainer-gogh.py -m nin -i input.png -s style.png -o output_dir -g -1
</pre></div></div>

<p><a href="http://f.st-hatena.com/images/fotolife/s/shu223/20160105/20160105091523.jpg" target="_blank" rel="nofollow noopener"><img src="http://f.st-hatena.com/images/fotolife/s/shu223/20160105/20160105091523.jpg" width="600"></a></p>

<p><span class="deco">（左：input.png、右：style.png）</span></p>

<p><a href="http://f.st-hatena.com/images/fotolife/s/shu223/20160105/20160105091655.png" target="_blank" rel="nofollow noopener"><img src="http://f.st-hatena.com/images/fotolife/s/shu223/20160105/20160105091655.png" alt=""></a></p>

<p><span class="deco">（結果画像）</span></p>

<h2>
<span id="今後の展望" class="fragment"></span><a href="#%E4%BB%8A%E5%BE%8C%E3%81%AE%E5%B1%95%E6%9C%9B"><i class="fa fa-link"></i></a>今後の展望</h2>

<p>今回は環境構築と既に用意されているサンプルを実行してみただけなので、次のステップとしては、下記記事の例のように、OpenCVを活用して自前データセットつくって、Chainer なり TensorFlow なりで画像識別をやってみたいと思っています。</p>

<ul>
<li><a href="http://bohemia.hatenablog.com/entry/2015/11/22/161858" class="autolink" rel="nofollow noopener" target="_blank">http://bohemia.hatenablog.com/entry/2015/11/22/161858</a></li>
<li><a href="http://bohemia.hatenablog.com/entry/2015/11/22/174603" class="autolink" rel="nofollow noopener" target="_blank">http://bohemia.hatenablog.com/entry/2015/11/22/174603</a></li>
</ul>

<p>ただデータセット収集はそれなりに時間かかりそうなので、下記記事のように既存のデータセットを Chainer および TensorFlow に食わせるところから始めるのが現実的かも。</p>

<ul>
<li><a href="http://rest-term.com/archives/3172/" class="autolink" rel="nofollow noopener" target="_blank">http://rest-term.com/archives/3172/</a></li>
</ul>

<p>また、iOSエンジニアとしては、モバイルデバイスでの利用についても模索したいと思っています。</p>

<ul>
<li><a href="http://d.hatena.ne.jp/shu223/20141212/1418300463" rel="nofollow noopener" target="_blank">iOSと機械学習 - Over&amp;Out その後</a></li>
</ul>

<p>あらかじめ学習済みモデルを用意して識別専用として利用するだけなら可能なのか、学習機能自体をモバイル側でやってみたらどんだけ重いのか（そもそもできるのか）とか。TensorFlow は「モバイル端末にもデプロイ可能」と謳ってますし。</p>

<p>あと、画像以外にも、自然言語処理への利用等も試してみたいです。</p>

<p>おわり。</p>

<h2>
<span id="関連記事" class="fragment"></span><a href="#%E9%96%A2%E9%80%A3%E8%A8%98%E4%BA%8B"><i class="fa fa-link"></i></a>関連記事</h2>

<ul>
<li><a href="http://qiita.com/shu223/items/9cbde46c0690f1952750" id="reference-0ea55ab2bd6ac7b7aac3">機械学習はじめの一歩に役立つ記事のまとめ</a></li>
</ul>

<div class="footnotes">
<hr>
<ol>

<li id="fn1">
<p>これをやらないと、実行時に "ImportError: No module named examples.tutorials.mnist" というエラーが出ます。 <a href="#fnref1">↩</a></p>
</li>

<li id="fn2">
<p>パスが間違ってても TensorBoard は起動するのですが、アクセスしてもグラフ等は表示されません。 <a href="#fnref2">↩</a></p>
</li>

<li id="fn3">
<p><code>/usr/include</code> が最近のOSXでなくなってることに関しては、<code>$ xcode-select --install</code> をすればいいみたいなのですが、古いコマンドラインツールをダウンロードしないといけないっぽく、あまりXcodeまわりの環境をいじりたくないので直接pythonのincludeパスを指定するようにしました <a href="#fnref3">↩</a></p>
</li>

<li id="fn4">
<p>なぜか ipython: command not found になったので <a href="http://stackoverflow.com/questions/16745923/ipython-command-not-found-terminal-osx-pip-installed" rel="nofollow noopener" target="_blank">こちら</a> を参考にインストールしなおしました <a href="#fnref4">↩</a></p>
</li>

</ol>
</div>
<div class="hidden"><form class="js-task-list-update" action="/shu223/items/a4fc17eb3356a6068553" accept-charset="UTF-8" method="post"><input name="utf8" type="hidden" value="&#x2713;" /><input type="hidden" name="_method" value="patch" /><input type="hidden" name="authenticity_token" value="l6SYjUDuD+Pf09xNP3zVn/DI+COHxkFBHY1B34cv8p6+5uuCkA3xeoLbY9ZuPW6Rv2S07UvS08oYgOe3fhSnvA==" /><input type="hidden" name="updated_at_confirmation_in_unixtime" id="updated_at_confirmation_in_unixtime" value="1487232832" class="js-task-list-updated-at" /><textarea name="raw_body" id="raw_body" class="js-task-list-field">
「いつか勉強しよう」と人工知能／機械学習／ディープラーニング（Deep Learning）といったトピックの記事の見つけてはアーカイブしてきたものの、結局2015年は何一つやらずに終わってしまったので、とにかく一歩でも足を踏み出すべく、 **本質的な理解等はさておき、とにかく試してみる** ということをやってみました。


試したのは、TensorFlow、Chainer、Caffe といった機械学習およびディープラーニングの代表的なライブラリ／フレームワーク3種と、2015年に話題になったディープラーニングを利用したアプリケーション2種（DeepDream、chainer-gogh）。

&lt;img src=&quot;http://f.st-hatena.com/images/fotolife/s/shu223/20160105/20160105091448.jpg&quot; width=&quot;600&quot;&gt;

&lt;span class=&quot;deco&quot; style=&quot;font-size:small;&quot;&gt;（DeepDreamで試した結果画像）&lt;/span&gt;


タイトルに半日と書きましたが、たとえばTensorFlowは&lt;b&gt;環境構築だけなら10分&lt;/b&gt;もあれば終わるでしょうし、&lt;b&gt;Chainerなんてコマンド一発なので5秒&lt;/b&gt;くらいです。Caffeは僕はハマりましたが、&lt;b&gt;うまくいった最短手順&lt;/b&gt;を書いているので、同じ環境の方はすんなりいくかもしれません。


おすすめは、**Chaffe &amp; DeepDream（要Caffe）は飛ばして、TensorFlow, Chainer&amp;画風変換を試す** コースです。環境構築にハマらないので簡単に終わると思います（実行時間はかかりますが）。僕のように「気にはなってたけど全然触ってない」という方はぜひ今日の昼休みにでもお試しください！


試した環境：

- Mac OS X 10.11.1 El Capitan
- Xcode 7.2 インストール済み


##TensorFlow

2015年11月に発表された、Google製の機械学習ライブラリ。「テンソルフロー」と読むそうです。同社のサービスでも実際に使われているとのこと。

&gt; よく話を聞く音声認識や翻訳だけでなく、Googleフォトの被写体認識や顔認識、ウェブ検索結果の最適化、Gmailのメール分別、新生メールソフトInboxの自動返信文作成、さらにYouTubeや広告事業まで、ほとんどのプロダクトを支える新たな根幹技術となっています。

&gt; TensorFlow の特徴は、データフローグラフとして表せればなんでも処理でき、その気になればローレベルのオペレータも手書きできる汎用性、Googleの実製品で使われる高いパフォーマンス、CPUでもGPUでも走りノートPCから巨大なデータセンターまで同じコードで動きモバイル端末にもデプロイできるスケーラビリティ、計算機科学の研究から実プロダクトまで扱える効率性、ドキュメンテーションやサンプルが揃いPythonでもC++でも書ける扱いやすさなどなど。

- http://japanese.engadget.com/2015/11/09/google-tensorflow/


###オープン化の狙い

ライセンスは商用利用も可能な Apache 2.0 で、自社製品のコアにもなっているこんなすごいものをなぜ Google はオープン化したのか？というところは気になるところです。

&gt; TensorFlowをオープンソース化することで、学術研究者からエンジニア、趣味として取り組むユーザーまで、あらゆる人々の機械学習コミュニティーが、研究論文よりも動作するコードを介してアイデアを格段にすばやく交換できるようになると期待している。これが機械学習に関する研究の促進につながり、最終的に技術がすべての人々にとってより適切に機能するものになるだろう。さらに、TensorFlowの応用分野は機械学習だけにとどまらない。タンパク質のフォールディングから宇宙データの処理にいたるまで、非常に複雑なデータの解明に取り組むあらゆる分野の研究者らにとって有用であるかもしれない。

- http://japan.cnet.com/news/service/35073215/


&gt; Googleいわく、機械学習はこれからの画期的なプロダクトや技術に欠かせない重要な要素となるもので、世界中で研究が進められているものの、標準となるツールが存在していないことが課題。Google では TensorFlow を研究者から学生、製品開発者まで使える標準ツールとして提供することで、機械学習や機械知能そのものの研究と普及を加速したい考えです。

- http://japanese.engadget.com/2015/11/09/google-tensorflow/


###環境構築手順（所要時間：10分）

OS X El Capitan (10.11.1) へのインストール手順です。

- https://www.tensorflow.org/versions/master/get_started/os_setup.html


####1. pip をインストール

```bash
$ sudo easy_install pip
```


####2. Virtualenv をインストール

```bash
$ sudo pip install --upgrade virtualenv
```


####3. Virtualenv 環境を作成

```bash
$ virtualenv --system-site-packages ~/tensorflow
```

（上記コマンドだと `~/tensorflow` につくられる）

####4. つくった環境をアクティベート

```bash
$ source ~/tensorflow/bin/activate
```

→ コマンドプロンプトが変わる


####5. TensorFlow をインストール

```bash:for_Python2.7
$ pip install --upgrade tensorflow
```

```bash:for_Python3.n
$ pip3 install --upgrade tensorflow
```

&gt; Successfully installed appdirs-1.4.0 numpy-1.12.0 packaging-16.8 protobuf-3.2.0 setuptools-34.2.0 tensorflow-1.0.0 wheel-0.29.0

以上です。


###動作確認：Hello World を実行してみる

スクリプトを作成し、適当なファイル名で保存します。

```python
import tensorflow as tf
import multiprocessing as mp
 
core_num = mp.cpu_count()
config = tf.ConfigProto(
    inter_op_parallelism_threads=core_num,
    intra_op_parallelism_threads=core_num )
sess = tf.Session(config=config)
 
hello = tf.constant(&#39;hello, tensorflow!&#39;)
print sess.run(hello)
```


TensorFlow 環境で実行します。

```bash
(tensorflow)$ python {ファイル名}.py
```


実行結果：

```
I tensorflow/core/common_runtime/local_device.cc:25] Local device intra op parallelism threads: 4
I tensorflow/core/common_runtime/local_session.cc:45] Local session inter op parallelism threads: 4
hello, tensorflow!
```


参考ページ：

- http://dev.classmethod.jp/machine-learning/tensorflow-hello-world/


###手書き数字を学習してみる

TensorFlow オフィシャルページに、「[MNIST For ML Beginners](https://www.tensorflow.org/versions/master/tutorials/mnist/beginners/index.html)」という手書き文字データセットを利用したチュートリアルがあります。

![](http://f.st-hatena.com/images/fotolife/s/shu223/20160105/20160105090618.png)

&lt;span class=&quot;deco&quot; style=&quot;font-size:small;&quot;&gt;（MNISTデータセット）&lt;/span&gt;


ここでは一番手っ取り早そうな、公式チュートリアルのコード（GitHubにある）を実行する方法を試すことにします。


ソースコードを clone してきて、

```bash
$ git clone --recurse-submodules https://github.com/tensorflow/tensorflow
```


fully_connected_feed.py の30,31行目を次のように修正します。[^1]

[^1]: これをやらないと、実行時に &quot;ImportError: No module named examples.tutorials.mnist&quot; というエラーが出ます。

- 修正前

```python
from tensorflow.examples.tutorials.mnist import input_data
from tensorflow.examples.tutorials.mnist import mnist
```

- 修正後

```python
import input_data
import mnist
```


fully_connected_feed.py を実行します。

```bash
$ cd tensorflow/
$ python tensorflow/examples/tutorials/mnist/fully_connected_feed.py 
```

MNISTデータセットを手動でダウンロードしたりする必要はなく、このスクリプトが&lt;b&gt;データセットの取得からモデルの学習まで&lt;/b&gt;やってくれます。


実行結果：

```
Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.
Extracting data/train-images-idx3-ubyte.gz
//中略
Step 0: loss = 2.32 (0.025 sec)
Step 100: loss = 2.19 (0.003 sec)
Step 200: loss = 1.97 (0.003 sec)
//中略
Step 1900: loss = 0.46 (0.004 sec)
Training Data Eval:
  Num examples: 55000  Num correct: 49489  Precision @ 1: 0.8998
Validation Data Eval:
  Num examples: 5000  Num correct: 4534  Precision @ 1: 0.9068
Test Data Eval:
  Num examples: 10000  Num correct: 9019  Precision @ 1: 0.9019
```

データセットのダウンロード、トレーニング、テストデータでの評価が行われています。最終的な精度は約90%。


参考ページ：

- http://nextdeveloper.hatenablog.com/entry/2015/11/10/204609
- http://qiita.com/sergeant-wizard/items/fdf4d64a0d221a81da34


###学習結果を可視化する TensorBoard を試す

なんと、学習結果をグラフにしてくれたり、モデルをビジュアライズして表示してくれる TensorBoard というものも用意してくれているようです。


学習経過のログデータのあるディレクトリを&lt;b&gt;絶対パスで&lt;/b&gt;指定 [^2] して `tensorboard` コマンドを実行すると、

```bash
$ tensorboard --logdir=/Users/xxxx/xxxx/tensorflow/tensorflow/data
```

[^2]: パスが間違ってても TensorBoard は起動するのですが、アクセスしてもグラフ等は表示されません。

TensorBoard が起動します。

```
Starting TensorBoard on port 6006
(You can navigate to http://localhost:6006)
```


で、このURLにブラウザからアクセスするとGUIが表示され、


学習回数とxentropy_mean（交差エントロピー）の関係を示すグラフや、

&lt;img src=&quot;http://f.st-hatena.com/images/fotolife/s/shu223/20160105/20160105090658.jpg&quot; width=&quot;400&quot;&gt;


モデル（ニューラルネットワーク）を可視化したものを見ることができます。

&lt;img src=&quot;http://f.st-hatena.com/images/fotolife/s/shu223/20160105/20160105090721.jpg&quot; width=&quot;538&quot;&gt;


###More

- http://qiita.com/shuhei_f/items/9251084b00ed9319033e
- http://qiita.com/uramonk/items/c207c948ccb6cd0a1346
  - チュートリアルのコードをコメントで解説してくれています
- http://qiita.com/haminiku/items/36982ae65a770565458d
  - 上級チュートリアルの解説もあり
- http://d.hatena.ne.jp/sugyan/20151124/1448292129
  - &lt;b&gt;学習結果を使って自分で書いた数字を識別してもらう&lt;/b&gt;ところまで試されています
  - コードも公開


##Chainer

Preferred Networks社が開発したニューラルネットワークを実装するためのライブラリ。2015年6月公開。特徴としては、

- Python のライブラリとして提供
- あらゆるニューラルネットの構造に柔軟に対応
- 動的な計算グラフ構築による直感的なコード
- GPU をサポートし、複数 GPU をつかった学習も直感的に記述可能

が挙げられています。

- https://research.preferred.jp/2015/06/deep-learning-chainer/


###TensorFlow との比較

上記特徴を見ると TensorFlow とポジショニング的には似ているように見えたので、どんな違いがあるのかググッてみました。

&gt; たぶんできることそのものに大きな違いはないんだろうけど、Chainerの場合マルチGPUにするときには自分でGPUの管理をしなきゃなんないのが、TenrorFlowだともうちょっとラクなのかなあと思ったりする。

- http://d.hatena.ne.jp/shi3z/20151122/1448150781


&gt; TensorFlow、GPU使うのにリビルドが必要で、そのためにbazelが必要で、そのためにJava8が必要で、しかもGPUにCC3.5以上の制約があるみたいで、使えるなら使えば？感が凄い。同じPythonならChainerの方が敷居が低く感じる。 

- https://twitter.com/hrmk/status/663935918768656384


&gt; TensorFlowはDistBeliefの2倍の速いそうなのですが、Chainerはそれを上回っていました。

&gt; 記述量的にはそこまで変わらないですし個人的にはChainerの方が扱い易いというのが感想です(慣れの問題だとは思いますが。)。

- http://blog.albert2005.co.jp/2015/11/12/tensorflow%E3%81%A8chainer%E3%81%AE%E6%AF%94%E8%BC%83/


&gt; TensorFlow,Chainerとも精度は同じでした。そもそもMNISTは問題が簡単なのでDeep Learningでなくても高い精度が出るそうです。実行時間はChainerの方が速かったのです。

- http://qiita.com/supersaiakujin/items/bc05b9f329aca48329ac


###インストール手順（所要時間：5秒）

公式ドキュメントに [Install Guide](http://docs.chainer.org/en/stable/install.html) というページがあるのですが、Ubuntu, CentOS 向けに書かれているようなので、Mac向けのはないかなと探してたら、本家Webサイトに QUICK START という項目がありました。

- http://chainer.org/


やることは

```bash
$ pip install chainer
```

これだけ。

```
Successfully installed chainer-1.5.1 filelock-2.0.5
```

素晴らしい！


###手書き数字を学習してみる

公式リポジトリにサンプルが用意されています。cloneしてきてスクリプトを実行するだけ。

```bash
$ git clone https://github.com/pfnet/chainer.git
$ python chainer/examples/mnist/train_mnist.py
```


MNISTデータセットのダウンロードと、学習、テストが行われます。

```
load MNIST dataset
Downloading train-images-idx3-ubyte.gz...
（中略）
epoch 1
graph generated
train mean loss=0.190947790003, accuracy=0.942850003242
test  mean loss=0.0990746175707, accuracy=0.96930000484
（中略）
epoch 20
train mean loss=0.0104963570454, accuracy=0.996966669559
test  mean loss=0.102703116325, accuracy=0.982000006437
```

最終的な識別精度は98%になったようです。


###More

- http://cvl-robot.hateblo.jp/entry/2015/06/11/223928
- http://hi-king.hatenablog.com/entry/2015/06/11/021144
- http://hi-king.hatenablog.com/entry/2015/06/27/194630
- http://qiita.com/icoxfog417/items/96ecaff323434c8d677b
- http://qiita.com/mokemokechicken/items/cc9b2c96f6e4a43c123c
- http://d.hatena.ne.jp/shi3z/20150628/1435502562
- http://studylog.hateblo.jp/entry/2015/07/14/000635


##Caffe

C++で実装されたディープラーニングのオープンソースライブラリ。カリフォルニア大学バークレー校の研究センターBVLCが中心となって開発、C++・Python・MATLABで利用可能。


具体的な公開日はわかりませんが、ChainerやTensorFlowの登場以前から存在する分、ネットで見つかるおもしろそうなディープラーニングを利用した研究や試みはCaffeをベースにしたものを多く見かける気がします。


###環境構築手順（所要時間：約4時間）

所要時間は個人差（環境差）があると思いますが、**確実にTensorFlowやChainerよりは時間がかかる** と思います。依存ライブラリが多く、その中にはインストールの待ち時間が長いものがありますし、各自の環境に依存した設定を手動で行う必要があるので、そのあたりでハマることもあると思います。また個人的にはnumpyのバージョンが違うというエラーにかなり悩まされました。


GPUが絡むとハマりそうなのでCPUモードで、インストールしていきます。PyCaffeも入れます。


####1. 諸々インストール

```bash
$ brew install --fresh -vd snappy leveldb gflags glog szip lmdb
$ brew tap homebrew/science
$ brew install hdf5 opencv
$ brew install --build-from-source --with-python --fresh -vd protobuf
$ brew install --build-from-source --fresh -vd boost boost-python
$ brew install openblas
```

&lt;span class=&quot;deco&quot; style=&quot;color:#FF0000;font-size:small;&quot;&gt;※1 opencv のインストールはかなり時間がかかります。&lt;/span&gt;

&lt;span class=&quot;deco&quot; style=&quot;font-size:small;&quot;&gt;※2 OpenBLAS は入れなくてもいいそうですが（Macでは標準でBLASが入っているとのこと）、この後の手順で Makefile の `BLAS_INCLUDE` のパスを修正したりしてから make を実行しても `fatal error: &#39;cblas.h&#39; file not found` が出てしまうので、入れることにしました。&lt;/span&gt;


####2. caffe をclone

```bash
$ git clone https://github.com/BVLC/caffe.git
```


####3. Makefile.config 作成

雛形からコピーしてきて、編集します。

```bash
$ cd caffe
$ cp Makefile.config.example Makefile.config
```


- `# CPU_ONLY := 1` のコメントアウトを外す
- `BLAS := atlas` を `BLAS := open` に変更する
- 以下のコメントアウトを外す

```
# BLAS_INCLUDE := $(shell brew --prefix openblas)/include
# BLAS_LIB := $(shell brew --prefix openblas)/lib
```

- `PYTHON_INCLUDE` のパスを自分の環境に合わせて書き換える [^3]
  - 修正前
```
PYTHON_INCLUDE := /usr/include/python2.7 \
    /usr/lib/python2.7/dist-packages/numpy/core/include
```
  - 修正後
```
PYTHON_INCLUDE := /usr/local/Cellar/python/2.7.11/Frameworks/Python.framework/Versions/2.7/include/python2.7 \
    /usr/local/lib/python2.7/site-packages/numpy/core/include/
```

[^3]: `/usr/include` が最近のOSXでなくなってることに関しては、`$ xcode-select --install` をすればいいみたいなのですが、古いコマンドラインツールをダウンロードしないといけないっぽく、あまりXcodeまわりの環境をいじりたくないので直接pythonのincludeパスを指定するようにしました

####4. ビルド＆テスト

```bash
$ make clean
$ make all -j4
$ make test -j4
$ make runtest
```

ここでエラーがでなければインストール成功です。

```
[  PASSED  ] 927 tests.
```


####5. PyCaffe に必要なライブラリをインストール

caffe/python フォルダに移動し、PyCaffe に必要なライブラリをインストールします。

```bash
$ cd python/
$ for li in $(cat requirements.txt); do sudo pip install $li; done 
```


####6. PyCaffe のビルド

```bash
$ cd ../
$ make pycaffe
$ make distribute
```


####7. 環境変数を設定

Caffe用の環境変数を設定します。~/.bashrc に下記を追記し、

```
export PYTHONPATH={caffe/pythonのパス}:$PYTHONPATH
```

`source ~/.bashrc` で反映します。


####8. 動作確認

PythonのインタプリタからCaffeをimportしてみて、問題が起きなければOK。

```bash
$ python 
&gt;&gt;&gt; import caffe
```


ちなみに本記事では最終的にうまくいった手順のみを書いていますが、**大いにハマったトラブルシューティングの過程** も別記事として書いておきました。

- [Caffe（PyCaffe）のインストールでハマったメモ - Over&amp;Out その後](http://d.hatena.ne.jp/shu223/20160103/1452000295)


####参考ページ：

- http://caffe.berkeleyvision.org/install_osx.html （公式ページ）
- http://qiita.com/t-hiroyoshi/items/3bba01dd11b1241f1336
- http://qiita.com/knao124/items/c76e974cfbaabb5542e8
- http://ichyo.jp/posts/caffe-install/


##DeepDream

ここからひとつレイヤーは上がって、ディープラーニングライブラリ／フレームワークを利用した応用アプリケーション的なものをいくつか試してみます。


DeepDream は [2015年7月にGoogleが公開](http://googleresearch.blogspot.jp/2015/07/deepdream-code-example-for-visualizing.html) したOSSで、

&gt; 画像から少しでも見覚えのある物体を見つけ出し、それを再構成して出力する

&gt; 人工神経回路網は10～30のレイヤーから構成されており、1枚目のレイヤーは画像の情報をインプットして「角」や「端」を探し、2枚目・3枚目と続くレイヤーは基本的な物体の情報を把握、最終的なレイヤーが情報を組み立てて物体が「何か」を判断する、という仕組みです。

- http://gigazine.net/news/20150707-deep-dreaming-fear/

というもの。


###環境構築の手順（所要時間：10分）

**要Caffe**（インストール手順は上述）。Caffeさえ入っていればさっくり試せます。


####1. iPython notebook をインストール [^4]

```bash
$ pip install ipython
$ pip install ipython[notebook]
```

[^4]: なぜか ipython: command not found になったので [こちら](http://stackoverflow.com/questions/16745923/ipython-command-not-found-terminal-osx-pip-installed) を参考にインストールしなおしました

####2. DeepDream を clone

Caffe のあるフォルダと同階層に DeepDream のソースを clone します。

```bash
$ git clone git@github.com:google/deepdream.git
```


####3. モデルをダウンロード

[ここ](http://dl.caffe.berkeleyvision.org/bvlc_googlenet.caffemodel) から学習済みのcaffeモデルをダウンロードし、{caffeのパス}/models/bvlc_googlenet/ に保存します。


###試す

cloneしてきたdeepdreamフォルダに移動し、iPython notebookを起動します。

```bash
$ cd deepdream
$ ipython trust dream.ipynb
$ ipython notebook
```


ブラウザが立ち上がるので、dream.ipynb を選択して、上部にある再生ボタンをポチポチ押していき、最後まで到達したらしばらく待っていると・・・ deepdream/frames/ フォルダに結果画像が 0000.jpg, 0001.jpg, ...と出力されていきます。

&lt;img src=&quot;http://f.st-hatena.com/images/fotolife/s/shu223/20160105/20160105091354.jpg&quot; width=&quot;600&quot;&gt;

&lt;span class=&quot;deco&quot; style=&quot;font-size:small;&quot;&gt;（左：0000.jpg と、右 0010.jpg）&lt;/span&gt;



手っ取り早く好きな画像で試したい場合は、sky1024px.jpg にリネームして同じ場所に置いておけばOKです。または dream.ipynb の画像名を指定している箇所を編集します。


さわやかな食事風景が、

&lt;img src=&quot;http://f.st-hatena.com/images/fotolife/s/shu223/20160105/20160105091426.jpg&quot; width=&quot;600&quot;&gt;


こうなりました。

&lt;img src=&quot;http://f.st-hatena.com/images/fotolife/s/shu223/20160105/20160105091448.jpg&quot; width=&quot;600&quot;&gt;



参考記事：

- http://qiita.com/t-hiroyoshi/items/e556c4ca0e8631556584
- http://qiita.com/icoxfog417/items/175f69d06f4e590face9


##画風変換アルゴリズム chainer-gogh

mattya氏が2015年9月に公開した、Deep Neural Networkを使って画像を好きな画風に変換できるプログラム。

- https://research.preferred.jp/2015/09/chainer-gogh/


Chainerを利用。アルゴリズムの元論文は [A Neural Algorithm of Artistic Style](http://arxiv.org/abs/1508.06576) 。


###環境構築の手順（所要時間：1分）

####1. ソースを clone

```bash
$ git clone https://github.com/mattya/chainer-gogh.git
```


####2. モデルをダウンロード

モデルを下記URLからダウンロードし、cloneしてきた chainer-gogh フォルダ配下に置きます。

- https://gist.github.com/mavenlin/d802a5849de39225bcc6


###実行する

お手軽にCPU実行してみます。コンテンツ画像（input.png）とスタイル画像（style.png）を用意して chainer-gogh フォルダ配下に置き、スクリプトを実行するだけ。

```bash
python chainer-gogh.py -m nin -i input.png -s style.png -o output_dir -g -1
```

&lt;img src=&quot;http://f.st-hatena.com/images/fotolife/s/shu223/20160105/20160105091523.jpg&quot; width=&quot;600&quot;&gt;

&lt;span class=&quot;deco&quot; style=&quot;font-size:small;&quot;&gt;（左：input.png、右：style.png）&lt;/span&gt;

![](http://f.st-hatena.com/images/fotolife/s/shu223/20160105/20160105091655.png)

&lt;span class=&quot;deco&quot; style=&quot;font-size:small;&quot;&gt;（結果画像）&lt;/span&gt;


##今後の展望

今回は環境構築と既に用意されているサンプルを実行してみただけなので、次のステップとしては、下記記事の例のように、OpenCVを活用して自前データセットつくって、Chainer なり TensorFlow なりで画像識別をやってみたいと思っています。

- http://bohemia.hatenablog.com/entry/2015/11/22/161858
- http://bohemia.hatenablog.com/entry/2015/11/22/174603

ただデータセット収集はそれなりに時間かかりそうなので、下記記事のように既存のデータセットを Chainer および TensorFlow に食わせるところから始めるのが現実的かも。

- http://rest-term.com/archives/3172/


また、iOSエンジニアとしては、モバイルデバイスでの利用についても模索したいと思っています。

- [iOSと機械学習 - Over&amp;Out その後](http://d.hatena.ne.jp/shu223/20141212/1418300463)

あらかじめ学習済みモデルを用意して識別専用として利用するだけなら可能なのか、学習機能自体をモバイル側でやってみたらどんだけ重いのか（そもそもできるのか）とか。TensorFlow は「モバイル端末にもデプロイ可能」と謳ってますし。


あと、画像以外にも、自然言語処理への利用等も試してみたいです。


おわり。


##関連記事

- [機械学習はじめの一歩に役立つ記事のまとめ](http://qiita.com/shu223/items/9cbde46c0690f1952750)
 
</textarea><input type="submit" name="commit" value="Save changes" data-disable-with="Save changes" /></form></div></section></div><div class="col-sm-3"><div class="socialButtons"><div class="socialButtons_twitter"><a class="twitter-share-button" data-text="ディープラーニングの有名ライブラリ5種を最短距離で試す半日コース（TensorFlow, Chainer, Caffe, DeepDream, 画風変換） by @shu223 on @Qiita" data-url="http://qiita.com/shu223/items/a4fc17eb3356a6068553" href="https://twitter.com/share">Tweet</a></div><div class="socialButtons_hatebu"><a class="hatena-bookmark-button" data-hatena-bookmark-layout="simple-balloon" data-hatena-bookmark-title="ディープラーニングの有名ライブラリ5種を最短距離で試す半日コース（TensorFlow, Chainer, Caffe, DeepDream, 画風変換）" href="http://b.hatena.ne.jp/entry/http://qiita.com/shu223/items/a4fc17eb3356a6068553" title="Add to Hatena Bookmark"><img alt="Add to Hatena Bookmark" height="20" src="https://b.st-hatena.com/images/entry-button/button-only@2x.png" style="border: none;" width="20" /></a><script async="async" charset="utf-8" src="https://b.st-hatena.com/js/bookmark_button.js" type="text/javascript"></script></div><div class="socialButtons_googlePlus"><div class="g-plusone" data-href="http://qiita.com/shu223/items/a4fc17eb3356a6068553" data-size="medium"></div></div><div class="socialButtons_facebook"><div class="fb-like" data-action="like" data-href="http://qiita.com/shu223/items/a4fc17eb3356a6068553" data-layout="button_count" data-share="false" data-show-faces="false"></div></div><div class="socialButtons_pocket"><a class="pocket-btn" data-lang="en" data-pocket-count="horizontal" data-pocket-label="pocket"></a></div></div><section class="itemsShowAuthorInfo" itemprop="author" itemscope="" itemtype="http://schema.org/Person"><a href="/shu223"><img alt="" class="itemsShowAuthorInfo_userIcon" itemprop="image" src="https://qiita-image-store.s3.amazonaws.com/0/3180/profile-images/1473682733" /></a><div class="itemsShowAuthorInfo_profileStats"><strong class="itemsShowAuthorInfo_userName" itemprop="name"><a itemprop="url" href="/shu223">shu223</a></strong><div class="itemsShowAuthorInfo_contribution"><span class="itemsShowAuthorInfo_count">18292</span><span class="itemsShowAuthorInfo_unit">Contribution</span></div><div id="js-react-on-rails-context" data-rails-context="{}"></div>
<div class="js-react-on-rails-component" data-component-name="UserFollowButton" data-props="{&quot;initial_followed_by&quot;:false,&quot;position&quot;:&quot;author-info&quot;,&quot;size&quot;:&quot;btn-xs&quot;,&quot;url_name&quot;:&quot;shu223&quot;}" data-trace="false" data-dom-id="UserFollowButton-react-component-82e185ab-1eb1-4f40-9f20-8c18fae25499"></div>
    <div id="UserFollowButton-react-component-82e185ab-1eb1-4f40-9f20-8c18fae25499"></div>
    
</div><section class="itemsShowAuthorPopularItems"><h5 class="itemsShowAuthorPopularItems_sectionTitle">人気の投稿</h5><ul class="itemsShowAuthorPopularItems_posts list-unstyled"><li itemscope="" itemtype="http://schema.org/Article"> <a itemprop="url" track="click" data-label="AuthorPopularItemsAtSidebar" href="/shu223/items/a4fc17eb3356a6068553">ディープラーニングの有名ライブラリ5種を最短距離で試す半日コース（TensorFlow, Chainer, Caffe, DeepDream, 画風変換）</a></li><li itemscope="" itemtype="http://schema.org/Article"> <a itemprop="url" track="click" data-label="AuthorPopularItemsAtSidebar" href="/shu223/items/a895a989e84219e5302e">iOSアプリ開発に役立つTips100連発！</a></li><li itemscope="" itemtype="http://schema.org/Article"> <a itemprop="url" track="click" data-label="AuthorPopularItemsAtSidebar" href="/shu223/items/9e3a50e092c2997fe6d2">例の機械学習コースが良いらしいと知りながらも2年間スルーし続けたがやはり良かったという話</a></li><li itemscope="" itemtype="http://schema.org/Article"> <a itemprop="url" track="click" data-label="AuthorPopularItemsAtSidebar" href="/shu223/items/9cbde46c0690f1952750">機械学習はじめの一歩に役立つ記事のまとめ</a></li><li itemscope="" itemtype="http://schema.org/Article"> <a itemprop="url" track="click" data-label="AuthorPopularItemsAtSidebar" href="/shu223/items/ffd2202eaf92d342f83d">「顔以外」のものを画像認識する</a></li></ul></section></section><div class="scroll-chaser"><div class="google-adsense"><style>.test-text-responsible { width: 200px; height: 200px; }@media(min-width: 1200px) {  .test-text-responsible { width: 250px; height: 250px; }}@media(max-width: 979px) and (min-width: 768px) {  .test-text-responsible { width: 120px; height: 240px; }}@media(max-width: 767px) {  .test-text-responsible { width: 320px; height: 50px; }}</style><script async="" src="http://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script><ins class="adsbygoogle test-text-responsible" data-ad-client="ca-pub-8127218772604357" data-ad-slot="3880091879" style="display:inline-block"></ins><script>(adsbygoogle = window.adsbygoogle || []).push({});</script></div></div><div class="js-react-on-rails-component" data-component-name="Toc" data-props="{&quot;body&quot;:&quot;\u003cul\u003e\n\u003cli\u003e\n\u003ca href=\&quot;#tensorflow\&quot;\u003eTensorFlow\u003c/a\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003ca href=\&quot;#%E3%82%AA%E3%83%BC%E3%83%97%E3%83%B3%E5%8C%96%E3%81%AE%E7%8B%99%E3%81%84\&quot;\u003eオープン化の狙い\u003c/a\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\&quot;#%E7%92%B0%E5%A2%83%E6%A7%8B%E7%AF%89%E6%89%8B%E9%A0%86%E6%89%80%E8%A6%81%E6%99%82%E9%96%9310%E5%88%86\&quot;\u003e環境構築手順（所要時間：10分）\u003c/a\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003ca href=\&quot;#1-pip-%E3%82%92%E3%82%A4%E3%83%B3%E3%82%B9%E3%83%88%E3%83%BC%E3%83%AB\&quot;\u003e1. pip をインストール\u003c/a\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\&quot;#2-virtualenv-%E3%82%92%E3%82%A4%E3%83%B3%E3%82%B9%E3%83%88%E3%83%BC%E3%83%AB\&quot;\u003e2. Virtualenv をインストール\u003c/a\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\&quot;#3-virtualenv-%E7%92%B0%E5%A2%83%E3%82%92%E4%BD%9C%E6%88%90\&quot;\u003e3. Virtualenv 環境を作成\u003c/a\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\&quot;#4-%E3%81%A4%E3%81%8F%E3%81%A3%E3%81%9F%E7%92%B0%E5%A2%83%E3%82%92%E3%82%A2%E3%82%AF%E3%83%86%E3%82%A3%E3%83%99%E3%83%BC%E3%83%88\&quot;\u003e4. つくった環境をアクティベート\u003c/a\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\&quot;#5-tensorflow-%E3%82%92%E3%82%A4%E3%83%B3%E3%82%B9%E3%83%88%E3%83%BC%E3%83%AB\&quot;\u003e5. TensorFlow をインストール\u003c/a\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\&quot;#%E5%8B%95%E4%BD%9C%E7%A2%BA%E8%AA%8Dhello-world-%E3%82%92%E5%AE%9F%E8%A1%8C%E3%81%97%E3%81%A6%E3%81%BF%E3%82%8B\&quot;\u003e動作確認：Hello World を実行してみる\u003c/a\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\&quot;#%E6%89%8B%E6%9B%B8%E3%81%8D%E6%95%B0%E5%AD%97%E3%82%92%E5%AD%A6%E7%BF%92%E3%81%97%E3%81%A6%E3%81%BF%E3%82%8B\&quot;\u003e手書き数字を学習してみる\u003c/a\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\&quot;#%E5%AD%A6%E7%BF%92%E7%B5%90%E6%9E%9C%E3%82%92%E5%8F%AF%E8%A6%96%E5%8C%96%E3%81%99%E3%82%8B-tensorboard-%E3%82%92%E8%A9%A6%E3%81%99\&quot;\u003e学習結果を可視化する TensorBoard を試す\u003c/a\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\&quot;#more\&quot;\u003eMore\u003c/a\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\&quot;#chainer\&quot;\u003eChainer\u003c/a\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003ca href=\&quot;#tensorflow-%E3%81%A8%E3%81%AE%E6%AF%94%E8%BC%83\&quot;\u003eTensorFlow との比較\u003c/a\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\&quot;#%E3%82%A4%E3%83%B3%E3%82%B9%E3%83%88%E3%83%BC%E3%83%AB%E6%89%8B%E9%A0%86%E6%89%80%E8%A6%81%E6%99%82%E9%96%935%E7%A7%92\&quot;\u003eインストール手順（所要時間：5秒）\u003c/a\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\&quot;#%E6%89%8B%E6%9B%B8%E3%81%8D%E6%95%B0%E5%AD%97%E3%82%92%E5%AD%A6%E7%BF%92%E3%81%97%E3%81%A6%E3%81%BF%E3%82%8B-1\&quot;\u003e手書き数字を学習してみる\u003c/a\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\&quot;#more-1\&quot;\u003eMore\u003c/a\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\&quot;#caffe\&quot;\u003eCaffe\u003c/a\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003ca href=\&quot;#%E7%92%B0%E5%A2%83%E6%A7%8B%E7%AF%89%E6%89%8B%E9%A0%86%E6%89%80%E8%A6%81%E6%99%82%E9%96%93%E7%B4%844%E6%99%82%E9%96%93\&quot;\u003e環境構築手順（所要時間：約4時間）\u003c/a\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003ca href=\&quot;#1-%E8%AB%B8%E3%80%85%E3%82%A4%E3%83%B3%E3%82%B9%E3%83%88%E3%83%BC%E3%83%AB\&quot;\u003e1. 諸々インストール\u003c/a\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\&quot;#2-caffe-%E3%82%92clone\&quot;\u003e2. caffe をclone\u003c/a\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\&quot;#3-makefileconfig-%E4%BD%9C%E6%88%90\&quot;\u003e3. Makefile.config 作成\u003c/a\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\&quot;#4-%E3%83%93%E3%83%AB%E3%83%89%E3%83%86%E3%82%B9%E3%83%88\&quot;\u003e4. ビルド＆テスト\u003c/a\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\&quot;#5-pycaffe-%E3%81%AB%E5%BF%85%E8%A6%81%E3%81%AA%E3%83%A9%E3%82%A4%E3%83%96%E3%83%A9%E3%83%AA%E3%82%92%E3%82%A4%E3%83%B3%E3%82%B9%E3%83%88%E3%83%BC%E3%83%AB\&quot;\u003e5. PyCaffe に必要なライブラリをインストール\u003c/a\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\&quot;#6-pycaffe-%E3%81%AE%E3%83%93%E3%83%AB%E3%83%89\&quot;\u003e6. PyCaffe のビルド\u003c/a\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\&quot;#7-%E7%92%B0%E5%A2%83%E5%A4%89%E6%95%B0%E3%82%92%E8%A8%AD%E5%AE%9A\&quot;\u003e7. 環境変数を設定\u003c/a\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\&quot;#8-%E5%8B%95%E4%BD%9C%E7%A2%BA%E8%AA%8D\&quot;\u003e8. 動作確認\u003c/a\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\&quot;#%E5%8F%82%E8%80%83%E3%83%9A%E3%83%BC%E3%82%B8\&quot;\u003e参考ページ：\u003c/a\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\&quot;#deepdream\&quot;\u003eDeepDream\u003c/a\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003ca href=\&quot;#%E7%92%B0%E5%A2%83%E6%A7%8B%E7%AF%89%E3%81%AE%E6%89%8B%E9%A0%86%E6%89%80%E8%A6%81%E6%99%82%E9%96%9310%E5%88%86\&quot;\u003e環境構築の手順（所要時間：10分）\u003c/a\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003ca href=\&quot;#1-ipython-notebook-%E3%82%92%E3%82%A4%E3%83%B3%E3%82%B9%E3%83%88%E3%83%BC%E3%83%AB-4\&quot;\u003e1. iPython notebook をインストール [^4]\u003c/a\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\&quot;#2-deepdream-%E3%82%92-clone\&quot;\u003e2. DeepDream を clone\u003c/a\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\&quot;#3-%E3%83%A2%E3%83%87%E3%83%AB%E3%82%92%E3%83%80%E3%82%A6%E3%83%B3%E3%83%AD%E3%83%BC%E3%83%89\&quot;\u003e3. モデルをダウンロード\u003c/a\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\&quot;#%E8%A9%A6%E3%81%99\&quot;\u003e試す\u003c/a\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\&quot;#%E7%94%BB%E9%A2%A8%E5%A4%89%E6%8F%9B%E3%82%A2%E3%83%AB%E3%82%B4%E3%83%AA%E3%82%BA%E3%83%A0-chainer-gogh\&quot;\u003e画風変換アルゴリズム chainer-gogh\u003c/a\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003ca href=\&quot;#%E7%92%B0%E5%A2%83%E6%A7%8B%E7%AF%89%E3%81%AE%E6%89%8B%E9%A0%86%E6%89%80%E8%A6%81%E6%99%82%E9%96%931%E5%88%86\&quot;\u003e環境構築の手順（所要時間：1分）\u003c/a\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003ca href=\&quot;#1-%E3%82%BD%E3%83%BC%E3%82%B9%E3%82%92-clone\&quot;\u003e1. ソースを clone\u003c/a\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\&quot;#2-%E3%83%A2%E3%83%87%E3%83%AB%E3%82%92%E3%83%80%E3%82%A6%E3%83%B3%E3%83%AD%E3%83%BC%E3%83%89\&quot;\u003e2. モデルをダウンロード\u003c/a\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\&quot;#%E5%AE%9F%E8%A1%8C%E3%81%99%E3%82%8B\&quot;\u003e実行する\u003c/a\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\&quot;#%E4%BB%8A%E5%BE%8C%E3%81%AE%E5%B1%95%E6%9C%9B\&quot;\u003e今後の展望\u003c/a\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\&quot;#%E9%96%A2%E9%80%A3%E8%A8%98%E4%BA%8B\&quot;\u003e関連記事\u003c/a\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n&quot;,&quot;wrapper&quot;:&quot;#article-body-wrapper&quot;}" data-trace="false" data-dom-id="Toc-react-component-996b58c3-f014-4afa-9a72-619dd4adac12"></div>
    <div id="Toc-react-component-996b58c3-f014-4afa-9a72-619dd4adac12"></div>
    
</div></div><div class="row"><div class="col-sm-9"><div class="ArticleFooter__menu"><div class="s-flex-align-center"><div class="js-likebutton" data-props="{&quot;like_status&quot;:false,&quot;like_count&quot;:1271,&quot;show_count&quot;:true,&quot;uuid&quot;:&quot;a4fc17eb3356a6068553&quot;,&quot;likable_type&quot;:&quot;Article&quot;,&quot;position&quot;:&quot;article-footer&quot;}"></div><div class="ArticleFooter__userList"><div class="ArticleFooter__user"><div class="js-hovercard" data-hovercard-target-name="makipe"><a itemprop="url" href="/makipe"><img alt="makipe" class="thumb thumb--xs" src="https://qiita-image-store.s3.amazonaws.com/0/69821/profile-images/1473698272" /></a></div></div><div class="ArticleFooter__user"><div class="js-hovercard" data-hovercard-target-name="lyuich"><a itemprop="url" href="/lyuich"><img alt="lyuich" class="thumb thumb--xs" src="https://qiita-image-store.s3.amazonaws.com/0/73617/profile-images/1473699563" /></a></div></div><div class="ArticleFooter__user"><div class="js-hovercard" data-hovercard-target-name="cb400sp2"><a itemprop="url" href="/cb400sp2"><img alt="cb400sp2" class="thumb thumb--xs" src="https://qiita-image-store.s3.amazonaws.com/0/7821/profile-images/1473680740" /></a></div></div><div class="ArticleFooter__user"><div class="js-hovercard" data-hovercard-target-name="sasaki77"><a itemprop="url" href="/sasaki77"><img alt="sasaki77" class="thumb thumb--xs" src="https://qiita-image-store.s3.amazonaws.com/0/99572/profile-images/1473707832" /></a></div></div><div class="ArticleFooter__user"><div class="js-hovercard" data-hovercard-target-name="sayamada"><a itemprop="url" href="/sayamada"><img alt="sayamada" class="thumb thumb--xs" src="https://qiita-image-store.s3.amazonaws.com/0/44722/profile-images/1473690004" /></a></div></div><div class="ArticleFooter__user"><div class="js-hovercard" data-hovercard-target-name="sadayuki-matsuno"><a itemprop="url" href="/sadayuki-matsuno"><img alt="sadayuki-matsuno" class="thumb thumb--xs" src="https://qiita-image-store.s3.amazonaws.com/0/55672/profile-images/1473693753" /></a></div></div><div class="ArticleFooter__user"><div class="js-hovercard" data-hovercard-target-name="mamo"><a itemprop="url" href="/mamo"><img alt="mamo" class="thumb thumb--xs" src="https://qiita-image-store.s3.amazonaws.com/0/32284/profile-images/1475060588" /></a></div></div><div class="ArticleFooter__user"><div class="js-hovercard" data-hovercard-target-name="syuhei"><a itemprop="url" href="/syuhei"><img alt="syuhei" class="thumb thumb--xs" src="https://qiita-image-store.s3.amazonaws.com/0/20848/profile-images/1473683137" /></a></div></div><div class="ArticleFooter__user"><div class="js-hovercard" data-hovercard-target-name="takuti"><a itemprop="url" href="/takuti"><img alt="takuti" class="thumb thumb--xs" src="https://qiita-image-store.s3.amazonaws.com/0/32315/profile-images/1479023405" /></a></div></div><div class="ArticleFooter__user"><div class="js-hovercard" data-hovercard-target-name="knao124"><a itemprop="url" href="/knao124"><img alt="knao124" class="thumb thumb--xs" src="https://qiita-image-store.s3.amazonaws.com/0/32783/profile-images/1473685978" /></a></div></div><div class="ArticleFooter__user"><a href="/shu223/items/a4fc17eb3356a6068553/likers"><span class="fa fa-ellipsis-h"></span></a></div></div></div><div class="u-flex u-align-center"><div class="ArticleFooter__stock"><div class="js-stockbutton" data-position="footer_menu" data-props="{&quot;stock_status&quot;:false}"></div></div><div class="ArticleFooter__editRequest"><a class="u-link-no-underline" data-toggle="tooltip" title="You can propose improvements about the article to the author 💪" href="/drafts/a4fc17eb3356a6068553/edit"><span class="fa fa-send-o fa-lg"></span> <span>Edit request</span></a></div><div class="dropdown ArticleFooter__dropdown"><a class="dropdown-toggle" data-toggle="dropdown" href="#"><span class="fa fa-ellipsis-h"></span></a><ul class="dropdown-menu dropdown-menu-right"><li><a href="/shu223/items/a4fc17eb3356a6068553.md"><span class="fa fa-fw fa-file-text-o"></span> Show article as Markdown</a></li><li><a data-target=".js-report-form" data-toggle="modal" href="#"><i class="fa fa-fw fa-flag"></i> Report article</a></li></ul></div></div></div><ul class="references js-referencesView"><li class="references_header"><i class="fa fa-fw fa-link"></i> Linked from these articles</li><li class="references_reference js-reference"><span>Linked from </span><a href="/yoppa/items/229507e6300ee18793ad#_reference-861f236db4fb57039a4d"><img alt="" width="18" height="18" src="https://qiita-image-store.s3.amazonaws.com/0/115058/profile-images/1473712798" />openFrameworks + ofxMSATensorFlow でディープラーニングを試してみる (OS X版)</a><time class="references_datetime js-dateTimeView" datetime="2016-02-26T23:21:06+00:00">about 1 year ago</time></li><li class="references_reference js-reference"><span>Linked from </span><a href="/eve_yk/items/e42431200a1616c7d045#_reference-bd35004eadf8ec3a6c63"><img alt="" width="18" height="18" src="https://qiita-image-store.s3.amazonaws.com/0/110468/profile-images/1473711224" />自分用TensorFlowメモ</a><time class="references_datetime js-dateTimeView" datetime="2016-04-30T08:05:53+00:00">11 months ago</time></li><li class="references_reference js-reference"><span>Linked from </span><a href="/shu223/items/ce190ea6669b2636a8a7#_reference-c3a228bdc4b3ce90c064"><img alt="" width="18" height="18" src="https://qiita-image-store.s3.amazonaws.com/0/3180/profile-images/1473682733" />TensorFlowにiOSサポートが追加されたそうなので試してみた</a><time class="references_datetime js-dateTimeView" datetime="2016-07-21T00:45:24+00:00">8 months ago</time></li><li class="references_reference js-reference"><span>Linked from </span><a href="/t_nakayama0714/items/776724410b2a119af088#_reference-4f0900cec0116e30718e"><img alt="" width="18" height="18" src="https://qiita-image-store.s3.amazonaws.com/0/45253/profile-images/1473690211" />Qiitaレジェンド達の偉大さをシェル芸で眺めて2016年を振り返る</a><time class="references_datetime js-dateTimeView" datetime="2016-12-28T14:21:49+00:00">3 months ago</time></li></ul><div class="itemsShowBody_articleColumnFooter"><div class="socialButtons"><div class="socialButtons_twitter"><a class="twitter-share-button" data-text="ディープラーニングの有名ライブラリ5種を最短距離で試す半日コース（TensorFlow, Chainer, Caffe, DeepDream, 画風変換） by @shu223 on @Qiita" data-url="http://qiita.com/shu223/items/a4fc17eb3356a6068553" href="https://twitter.com/share">Tweet</a></div><div class="socialButtons_hatebu"><a class="hatena-bookmark-button" data-hatena-bookmark-layout="simple-balloon" data-hatena-bookmark-title="ディープラーニングの有名ライブラリ5種を最短距離で試す半日コース（TensorFlow, Chainer, Caffe, DeepDream, 画風変換）" href="http://b.hatena.ne.jp/entry/http://qiita.com/shu223/items/a4fc17eb3356a6068553" title="Add to Hatena Bookmark"><img alt="Add to Hatena Bookmark" height="20" src="https://b.st-hatena.com/images/entry-button/button-only@2x.png" style="border: none;" width="20" /></a><script async="async" charset="utf-8" src="https://b.st-hatena.com/js/bookmark_button.js" type="text/javascript"></script></div><div class="socialButtons_googlePlus"><div class="g-plusone" data-href="http://qiita.com/shu223/items/a4fc17eb3356a6068553" data-size="medium"></div></div><div class="socialButtons_facebook"><div class="fb-like" data-action="like" data-href="http://qiita.com/shu223/items/a4fc17eb3356a6068553" data-layout="button_count" data-share="false" data-show-faces="false"></div></div><div class="socialButtons_pocket"><a class="pocket-btn" data-lang="en" data-pocket-count="horizontal" data-pocket-label="pocket"></a></div></div></div><div class="itemsShowComment_wrapper" id="comments"><div class="js-react-on-rails-component" data-component-name="CommentListContainer" data-props="{&quot;currentUser&quot;:null,&quot;initialComments&quot;:[],&quot;monthly_public_image_uploadable_size_limit&quot;:null,&quot;total_uploaded_public_image_size_in_current_month&quot;:null,&quot;item&quot;:{&quot;id&quot;:360766,&quot;uuid&quot;:&quot;a4fc17eb3356a6068553&quot;,&quot;suspended&quot;:false,&quot;secret&quot;:false},&quot;owner&quot;:{&quot;url_name&quot;:&quot;shu223&quot;},&quot;is_team&quot;:false,&quot;is_project&quot;:false,&quot;logged_in&quot;:false,&quot;polling&quot;:false,&quot;mention_candidates&quot;:[{&quot;id&quot;:3180,&quot;url_name&quot;:&quot;shu223&quot;,&quot;profile_image_url&quot;:&quot;https://qiita-image-store.s3.amazonaws.com/0/3180/profile-images/1473682733&quot;}]}" data-trace="false" data-dom-id="CommentListContainer-react-component-0624ef33-5f4c-4086-8673-416b80181f3e"></div>
    <div id="CommentListContainer-react-component-0624ef33-5f4c-4086-8673-416b80181f3e"></div>
    
</div></div></div></div></article><div class="js-report-form modal fade reportForm"><div class="modal-dialog"><div class="modal-content"><div class="modal-header"><button name="button" type="submit" class="close" data-dismiss="modal">&times;</button><h4 class="modal-title">Report article</h4></div><div class="modal-body"><form action="/reports" accept-charset="UTF-8" method="post"><input name="utf8" type="hidden" value="&#x2713;" /><input type="hidden" name="authenticity_token" value="ZhUq3GKEwiU5E8pNemXyXTp8VkPplzP7CngVCIdMQMlPV1nTsmc8vGQbddYrJElTddAajSWDoXAPdbNgfncV6w==" /><input type="hidden" name="redirect_path" id="redirect_path" value="/shu223/items/a4fc17eb3356a6068553" /><input type="hidden" name="item_uuid" id="item_uuid" value="a4fc17eb3356a6068553" /><p>Help us understand the problem. What is going on with this item?</p><br /><div class="form-group"><ul class="list-unstyled"><li><label><input type="radio" name="report_type" id="report_type_spam" value="spam" required="required" /> It&#39;s spam </label></li><li><label><input type="radio" name="report_type" id="report_type_harassment" value="harassment" required="required" /> It&#39;s abusive or harmful </label></li><li><label><input type="radio" name="report_type" id="report_type_inappropriate_content" value="inappropriate_content" required="required" /> It contains inappropriate content </label></li></ul></div><div class="reportForm_submitButtonContainer"><button name="button" type="submit" class="btn btn-primary reportForm_submitButton"><i class="fa fa-send"></i> Submit</button></div></form></div></div></div></div><script id="js-item" type="application/json">{ "url": "http://qiita.com/shu223/items/a4fc17eb3356a6068553", "id": 360766, "uuid": "a4fc17eb3356a6068553" }</script><script class="js-user" type="application/json">{&quot;id&quot;:3180,&quot;url_name&quot;:&quot;shu223&quot;,&quot;profile_image_url&quot;:&quot;https://qiita-image-store.s3.amazonaws.com/0/3180/profile-images/1473682733&quot;}</script><script language="JavaScript" src="//cdn.bigmining.com/private/js/qiita_bigmining.js" type="text/javascript"></script></div><footer class="footer"><div class="footer_inner"><div class="footer_container"><ul class="footer_links-left"><li class="footer_link"><a class="footer_copyright" href="http://increments.co.jp">© 2011-2017 Increments Inc.</a></li><li class="footer_link"><a href="http://qiita.com/terms">Terms</a></li><li class="footer_link"><a href="http://qiita.com/privacy">Privacy</a></li><li class="footer_link"><a href="http://help.qiita.com">Help</a></li><li class="footer_link"><a href="https://increments.zendesk.com/anonymous_requests/new">Contact</a></li></ul><ul class="footer_links-right"><li class="footer_link"><a href="http://qiita.com/about">About</a></li><li class="footer_link"><a href="/users">Users</a></li><li class="footer_link"><a href="/tags">Tags</a></li><li class="footer_link"><a href="http://blog.qiita.com">Blog</a></li><li class="footer_link"><a href="http://qiita.com/api/v2/docs">API</a></li><li class="footer_link"><a href="https://teams.qiita.com/">Team</a></li><li class="footer_link"><a href="http://kobito.qiita.com">Kobito</a></li><li class="footer_link"><a class="js-public-form-feedback-link" data-target=".js-feedback-form" data-toggle="modal" href=""><i class="fa fa-heart"></i> Feedback <i class="fa fa-caret-down"></i></a></li></ul></div></div></footer><div class="js-feedback-form modal fade feedbackForm"><div class="modal-dialog"><div class="modal-content"><div class="modal-header"><button name="button" type="submit" class="close" data-dismiss="modal">&times;</button><h4 class="modal-title">Feedback</h4></div><div class="modal-body"><form class="js-feedback-form-form" action="/feedbacks" accept-charset="UTF-8" method="post"><input name="utf8" type="hidden" value="&#x2713;" /><input type="hidden" name="authenticity_token" value="AGm8VZpZoLu3z4ilpNDN+iO/cn24yoRK+154UdDoquEpK89aSrpeIurHNz71kXb0bBM+s3TeFsH+U945KdP/ww==" /><input type="hidden" name="redirect_path" id="redirect_path" value="/shu223/items/a4fc17eb3356a6068553" /><div class="form-group"><textarea name="feedback[message]" id="feedback_message" class="form-control js-feedback-form-text-area" placeholder="Please give us any feedback about Qiita." required="required" rows="5">
</textarea></div><div class="feedbackForm_submitButtonContainer"><button name="button" type="submit" class="btn btn-primary feedbackForm_submitButton"><i class="fa fa-send"></i> Submit</button><p class="feedbackForm_note">We don&#39;t reply to any feedback.<br />If you need help with Qiita, please send a support request from <a href="https://increments.zendesk.com/anonymous_requests/new">here</a>.</p></div><div style="position:fixed;top:-99999px;opacity:0.0001;"><input name="feedback[name]" type="text" /></div></form></div></div></div></div><script>// if (window.mixpanel instanceof Element) {
//   window.mixpanel = [];
// }
// (function(f,b){if(!b.__SV){var a,e,i,g;window.mixpanel=b;b._i=[];b.init=function(a,e,d){function f(b,h){var a=h.split(".");2==a.length&&(b=b[a[0]],h=a[1]);b[h]=function(){b.push([h].concat(Array.prototype.slice.call(arguments,0)))}}var c=b;"undefined"!==typeof d?c=b[d]=[]:d="mixpanel";c.people=c.people||[];c.toString=function(b){var a="mixpanel";"mixpanel"!==d&&(a+="."+d);b||(a+=" (stub)");return a};c.people.toString=function(){return c.toString(1)+".people (stub)"};i="disable track track_pageview track_links track_forms register register_once alias unregister identify name_tag set_config people.set people.set_once people.increment people.append people.track_charge people.clear_charges people.delete_user".split(" ");
// for(g=0;g<i.length;g++)f(c,i[g]);b._i.push([a,e,d])};b.__SV=1.2;a=f.createElement("script");a.type="text/javascript";a.async=!0;a.src="//cdn.mxpnl.com/libs/mixpanel-2.2.min.js";e=f.getElementsByTagName("script")[0];e.parentNode.insertBefore(a,e)}})(document,window.mixpanel||[]);</script><script src="http://cdn.qiita.com/assets/public-3af9c1d29a49f3320bb796fb5e75304b.min.js"></script><script>
  (function () {
    var script = document.getElementsByTagName('script')[0];
    var load = function (src, id) {
      var el = document.createElement('script');
      el.async = true;
      el.src = src;
      el.id = id;
      script.parentNode.insertBefore(el, script);
    };
      // Optimizely
      load('//cdn.optimizely.com/js/52738645.js', 'optimizely-jssdk');
      // Google Analytics
      window._gaq = window._gaq || [];
      var isCareer = location.hostname.split('.')[0] == 'career';
      if (isCareer) {
        window._gaq.push(['_setAccount', 'UA-24675221-11']);
        window._gaq.push(['_setDomainName', 'qiita.com']);
      } else {
        window._gaq.push(['_setAccount', 'UA-24675221-1']);
      }
      window._gaq.push(['_setCustomVar', 1, 'logged_in', 'false', 2]);
      window._gaq.push(['_trackPageview']);
      var src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
      load(src, 'google-analytics-jssdk');
    // Google Analytics - Universal Analytics
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
    (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
    m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','//www.google-analytics.com/analytics.js','ga');
        ga('create', 'UA-24675221-12', {
          
        });
          ga('create', 'UA-3716439-6', { name: 'user' });
          ga('user.send', 'pageview');
        ga('set', 'dimension1', 'false');
        ga('set', 'dimension3', 'false');
      ga('require', 'displayfeatures');
      ga('set', 'forceSSL', true);
      ga('send', 'pageview');
    // Google Tag Manager
      (function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
      new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
      j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
      '//www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
      })(window,document,'script','dataLayer','GTM-TBQWPN');
  })();
</script>
</body></html>