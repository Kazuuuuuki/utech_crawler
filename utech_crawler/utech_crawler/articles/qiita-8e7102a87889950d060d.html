<!DOCTYPE html><html xmlns:og="http://ogp.me/ns#"><head><meta charset="UTF-8" /><title>Rubyでディープラーニング - Qiita</title><meta content="width=device-width,initial-scale=1" name="viewport" /><meta content="

背景

現在、TensorFlow、Chainer他多数のDeepLearning用ライブラリが公開されています。
本格的なアプリケーションで使うには実行スピード、クオリティ、拡張性、ドキュメント、コミュニティの充実等多くの面で、それらの中から選択して使用するのが鉄板な状況です。もちろん、私もメインではそれらを使わせてもらっています。これらのライブラリ、例えばtensorFlowではcomputatoin graphを構築、operationを追加してそれを実行とい..." name="description" /><meta content="summary" name="twitter:card" /><meta content="@Qiita" name="twitter:site" /><meta content="Rubyでディープラーニング - Qiita" property="og:title" /><meta content="article" property="og:type" /><meta content="http://qiita.com/elgoog/items/8e7102a87889950d060d" property="og:url" /><meta content="http://cdn.qiita.com/assets/qiita-fb-2887e7b4aad86fd8c25cea84846f2236.png" property="og:image" /><meta content="# 背景
現在、TensorFlow、Chainer他多数のDeepLearning用ライブラリが公開されています。
本格的なアプリケーションで使うには実行スピード、クオリティ、拡張性、ドキュメント、コミュニティの充実等多くの面で、そ..." property="og:description" /><meta content="Qiita" property="og:site_name" /><meta content="564524038" property="fb:admins" /><link rel="shortcut icon" type="image/x-icon" href="http://cdn.qiita.com/assets/favicons/public/production-4ff10c1e1e2b5fcb353ff9cafdd56c70.ico" /><link rel="apple-touch-icon" type="image/png" href="http://cdn.qiita.com/assets/favicons/public/apple-touch-icon-f9a6afad761ec2306e10db2736187c8b.png" /><link href="/opensearch.xml" rel="search" title="Qiita" type="application/opensearchdescription+xml" /><link rel="stylesheet" media="all" href="http://cdn.qiita.com/assets/public-81dd63f4385f99b52aeab91266068ebd.min.css" /><meta name="csrf-param" content="authenticity_token" />
<meta name="csrf-token" content="ZKA1X2rrA0VetbgeCRdyLWtPyl3jn5bNCniTMNt2OYybX2WE2yBnbj5pnqrmWeWZqL24gyWKL/VrU9+gBuVV7A==" /></head><body class="without-js" id=""><noscript><iframe height="0" src="//www.googletagmanager.com/ns.html?id=GTM-TBQWPN" style="display:none;visibility:hidden" width="0"></iframe></noscript><script>
  document.body.className = document.body.className.replace('without-js', '') + ' with-js';
  window.Qiita = {"asset_host":"cdn.qiita.com","TLD":"com","controller_path":"public/items","controller_action":"public/items#show","controller":"items","action":"show","action_path":"public/items#show","env":"production","flash":{},"is_landing_page":false,"is_team_page":false,"request_parameters":{"controller":"public/items","action":"show","user_id":"elgoog","type":"items","id":"8e7102a87889950d060d"},"root_domain":"qiita.com","variant":null,"config":{"mixpanel":{"career":"dd35af27e959781713d63fd7ca898a8d","per_team":"c0a2116368b33b44b5029ebd2cc9b094","public":"be87616606b0e26a87689099aab2c4e5","team":"b7c0342acba2dbc8742484d98788efb3"},"default_locale":"ja","locale":"en"},"team":null,"user":null,"GIT_BRANCH":null,"DEBUG":false};

</script>
<div class="headerContainer headerContainer-public" role="navigation"><div class="js-react-on-rails-component" data-component-name="HeaderContainer" data-props="{&quot;user&quot;:null,&quot;team&quot;:null,&quot;news&quot;:{&quot;type&quot;:&quot;募集&quot;,&quot;content&quot;:&quot;QiitaやQiita:Teamを良くしたいエンジニア&quot;,&quot;url&quot;:&quot;http://increments.co.jp/jobs/engineers?utm_source=qiita\u0026utm_medium=header_news&quot;},&quot;initial_unread_count&quot;:null,&quot;siteid_image&quot;:&quot;http://cdn.qiita.com/siteid-reverse.png&quot;,&quot;is_team_page&quot;:false,&quot;on_team_setting&quot;:false,&quot;show_post_menu&quot;:true,&quot;show_search_menu&quot;:true,&quot;is_fluid&quot;:false,&quot;locale&quot;:&quot;en&quot;}" data-trace="false" data-dom-id="HeaderContainer-react-component-12619db3-298b-430c-8958-c6530d6fff71"></div>
    <div id="HeaderContainer-react-component-12619db3-298b-430c-8958-c6530d6fff71"></div>
    
</div><div id="main"><script type="application/ld+json">{  "@context": "http://schema.org",  "@type": "BreadcrumbList",  "itemListElement": [    {      "@type": "ListItem",      "position": 1,      "item": {        "@id": "/",        "name": "Qiita"      }    },    {      "@type": "ListItem",      "position": 2,      "item": {        "@id": "/items",        "name": "Items"      }    },    {      "@type": "ListItem",      "position": 3,      "item": {        "@id": "/tags/DeepLearning",        "name": "DeepLearning"      }    }  ]}</script><article itemscope="" itemtype="http://schema.org/Article"><div class="ArticleMainHeader "><div class="container"></div><div class="container"><div class="row s-flex-align-center"><div class="col-sm-9"><h1 class="ArticleMainHeader__title" itemprop="headline">Rubyでディープラーニング</h1><ul class="TagList"><li class="TagList__item" data-count="1075"><a class="u-link-unstyled TagList__label" href="/tags/DeepLearning"><img alt="DeepLearning" class="TagList__icon" src="https://s3-ap-northeast-1.amazonaws.com/qiita-tag-image/eac844d1d880a38fc3be5ebf534cad5182b64ebf/medium.jpg?1453002020" /><span>DeepLearning</span></a></li><li class="TagList__item" data-count="1835"><a class="u-link-unstyled TagList__label" href="/tags/%E6%A9%9F%E6%A2%B0%E5%AD%A6%E7%BF%92"><img alt="機械学習" class="TagList__icon" src="https://s3-ap-northeast-1.amazonaws.com/qiita-tag-image/a94d4d239b3b0b83723d5b56c050ffc54b8593e7/medium.jpg?1394635775" /><span>機械学習</span></a></li><li class="TagList__item" data-count="229"><a class="u-link-unstyled TagList__label" href="/tags/%E6%B7%B1%E5%B1%A4%E5%AD%A6%E7%BF%92"><img alt="深層学習" class="TagList__icon" src="https://s3-ap-northeast-1.amazonaws.com/qiita-tag-image/9594cfcb56d9180f74c468e56c69ce9f69cbe6ee/medium.jpg?1480640899" /><span>深層学習</span></a></li><li class="TagList__item" data-count="92"><a class="u-link-unstyled TagList__label" href="/tags/%E3%83%8B%E3%83%A5%E3%83%BC%E3%83%A9%E3%83%AB%E3%83%8D%E3%83%83%E3%83%88%E3%83%AF%E3%83%BC%E3%82%AF"><img alt="ニューラルネットワーク" class="TagList__icon" src="https://s3-ap-northeast-1.amazonaws.com/qiita-tag-image/011823e464a9c800137e6074afd4ac7e1b55df45/medium.jpg?1480640830" /><span>ニューラルネットワーク</span></a></li><li class="TagList__item" data-count="13205"><a class="u-link-unstyled TagList__label" href="/tags/Ruby"><img alt="Ruby" class="TagList__icon" src="https://s3-ap-northeast-1.amazonaws.com/qiita-tag-image/0337fbcbff62fb8fa5d0b8be5c3b47d1115d91fc/medium.jpg?1418548649" /><span>Ruby</span></a></li></ul></div><div class="col-sm-3"><div class="itemsShowHeaderStock"><ul class="list-unstyled itemsShowHeaderStock_statusList"><li><div class="itemsShowHeaderStock_count stock"><span class="fa fa-thumbs-up"></span><span class="js-likecount">464</span></div><div class="itemsShowHeaderStock_countText">Like</div></li><li><div class="itemsShowHeaderStock_count" content="6 UserComments" itemprop="commentCount"><span class="fa fa-comment"></span>6</div><div class="itemsShowHeaderStock_countText">Comment</div></li></ul></div><div class="js-likebutton" data-props="{&quot;like_status&quot;:false,&quot;like_count&quot;:464,&quot;uuid&quot;:&quot;8e7102a87889950d060d&quot;,&quot;likable_type&quot;:&quot;Article&quot;,&quot;position&quot;:&quot;article-header&quot;}"></div><ul class="list-inline ArticleMainHeader__users"><li class="js-hovercard" data-hovercard-target-name="ytsukamoto"><a itemprop="url" href="/ytsukamoto"><img alt="ytsukamoto" class="thumb thumb--xs" src="https://2.gravatar.com/avatar/98bf066eac863d5b9a77ce43614b0cd2?d=https%3A%2F%2Fidenticons.github.com%2F95f86b01eb0a82a3d552499ba2a3b1de.png&amp;r=x" /></a></li><li class="js-hovercard" data-hovercard-target-name="snona"><a itemprop="url" href="/snona"><img alt="snona" class="thumb thumb--xs" src="https://qiita-image-store.s3.amazonaws.com/0/84376/profile-images/1473703078" /></a></li><li class="js-hovercard" data-hovercard-target-name="hakuaneko"><a itemprop="url" href="/hakuaneko"><img alt="hakuaneko" class="thumb thumb--xs" src="https://qiita-image-store.s3.amazonaws.com/0/31734/profile-images/1473685759" /></a></li><li class="js-hovercard" data-hovercard-target-name="hitomi_"><a itemprop="url" href="/hitomi_"><img alt="hitomi_" class="thumb thumb--xs" src="https://qiita-image-store.s3.amazonaws.com/0/6714/profile-images/1473683182" /></a></li><li class="js-hovercard" data-hovercard-target-name="takada-s"><a itemprop="url" href="/takada-s"><img alt="takada-s" class="thumb thumb--xs" src="https://qiita-image-store.s3.amazonaws.com/0/66222/profile-images/1473697138" /></a></li><li class="js-hovercard" data-hovercard-target-name="zuki_ebetsu"><a itemprop="url" href="/zuki_ebetsu"><img alt="zuki_ebetsu" class="thumb thumb--xs" src="https://qiita-image-store.s3.amazonaws.com/0/56485/profile-images/1473694012" /></a></li><li class="js-hovercard" data-hovercard-target-name="fumiyasac@github"><a itemprop="url" href="/fumiyasac@github"><img alt="fumiyasac@github" class="thumb thumb--xs" src="https://qiita-image-store.s3.amazonaws.com/0/17400/profile-images/1473682149" /></a></li><li class="js-hovercard" data-hovercard-target-name="uedatakumi"><a itemprop="url" href="/uedatakumi"><img alt="uedatakumi" class="thumb thumb--xs" src="https://qiita-image-store.s3.amazonaws.com/0/79169/profile-images/1473701352" /></a></li><li class="js-hovercard" data-hovercard-target-name="kazto"><a itemprop="url" href="/kazto"><img alt="kazto" class="thumb thumb--xs" src="https://qiita-image-store.s3.amazonaws.com/0/31413/profile-images/1473685689" /></a></li><li class="js-hovercard" data-hovercard-target-name="naari"><a itemprop="url" href="/naari"><img alt="naari" class="thumb thumb--xs" src="https://qiita-image-store.s3.amazonaws.com/0/92994/profile-images/1473705809" /></a></li><li><a href="/elgoog/items/8e7102a87889950d060d/likers"><span class="fa fa-ellipsis-h"></span></a></li></ul></div></div></div></div><div class="ArticleAsideHeader"><div class="container"><div class="u-flex u-space-between"><div class="u-flex u-flex-wrap"><div class="u-flex u-align-center s-pdv-5 u-flex-wrap"><div class="ArticleAsideHeader__author"><a href="/elgoog"><img class="thumb thumb--xs" src="https://qiita-image-store.s3.amazonaws.com/0/40955/profile-images/1473688611" alt="1473688611" /></a> <a class="u-link-unstyled" href="/elgoog">elgoog</a> </div><div class="ArticleAsideHeader__date"><meta content="2016-08-03T07:59:05+09:00" itemprop="datePublished" /><span data-toggle="tooltip" title="posted at 2016-08-03">Edited at <time datetime="2016-08-30T00:28:10+09:00" itemprop="dateModified">2016-08-30</time></span></div></div><div class="u-flex u-align-center s-pdv-5 mobile-hidden"><div class="ArticleAsideHeader__revision"> <a data-toggle="tooltip" title="Revisions" href="/elgoog/items/8e7102a87889950d060d/revisions"><span class="fa fa-history"></span></a><span class="ArticleAsideHeader__revisionCount">6</span></div></div><div class="u-flex u-align-center s-pdv-5 mobile-hidden"></div></div><div class="u-flex u-align-center s-flex-justiry-between s-pdv-5 u-shrink-0"><div class="ArticleAsideHeader__stock"><div class="js-stockbutton" data-position="top" data-props="{&quot;stock_status&quot;:false}"></div></div><div class="dropdown"><a class="dropdown-toggle" data-toggle="dropdown" href="#"><span class="fa fa-ellipsis-h fa-lg"></span></a><ul class="dropdown-menu dropdown-menu-right"><li class="dropdown__item--mobile"><a href="/elgoog/items/8e7102a87889950d060d/revisions"><span class="fa fa-fw fa-history"></span> Revisions<span>(6)</span></a></li><li><a href="/elgoog/items/8e7102a87889950d060d.md"><span class="fa fa-fw fa-file-text-o"></span> Show article as Markdown</a></li><li><a data-target=".js-report-form" data-toggle="modal" href="#"><span class="fa fa-fw fa-flag"></span> Report article</a></li></ul></div></div></div></div></div><div class="container"><div class="row" id="article-body-wrapper"><div class="col-sm-9"><section class="markdownContent markdownContent-headingEnabled js-task-list-container clearfix position-relative" id="item-8e7102a87889950d060d" itemprop="articleBody">
<h1>
<span id="背景" class="fragment"></span><a href="#%E8%83%8C%E6%99%AF"><i class="fa fa-link"></i></a>背景</h1>

<p>現在、TensorFlow、Chainer他多数のDeepLearning用ライブラリが公開されています。<br>
本格的なアプリケーションで使うには実行スピード、クオリティ、拡張性、ドキュメント、コミュニティの充実等多くの面で、それらの中から選択して使用するのが鉄板な状況です。もちろん、私もメインではそれらを使わせてもらっています。これらのライブラリ、例えばtensorFlowではcomputatoin graphを構築、operationを追加してそれを実行というイメージで（行列、数式で取り扱うイメージ）、根底にある古典的なニューロンの結合という考え方が隠されている気がします。むしろ、そのことは忘れて突き進んでしまっても良い気はしますが、自分の理解を深める意味でもニューロン指向でスクラッチからニューラルネットワークを書いてみました。<br>
使用言語は機械学習分野ではPythonに残念ながら遅れをとっているRubyを選択。<br>
DeepLearningに興味があるけどガッツリではなく少しさわってみたい方、公開ライブラリがpython用のためなんとなく手を出していなかった方などの入り口になればうれしいです。</p>

<h2>
<span id="rubybrain" class="fragment"></span><a href="#rubybrain"><i class="fa fa-link"></i></a>RubyBrain</h2>

<p>今回使用するライブラリの名前はRubyBrainです。<br>
背景でも書いたとおり現在主流のライブラリは使用者側からはニューロンを繋ぎあわせて人間の脳を模倣したネットワークを作って何かを学習させるという古典的なイメージは隠され、数式をつなぎ合わせてそのgraphを情報が流れて状態更新を行うイメージです。その点では、tensorFlow, Chainer共にネーミングセンスがとてもよいと感心します（特にChainer）。tensorFlowは次元が流れるイメージ、chainerは数式をつなぎ合わせていくイメージで、ライブラリの基本概念をうまく表現しています。<br>
で、RubyBrainですが、名前から少しは想像できるかもしれませんが、古典的なニューロンのつなぎ合わせをイメージして実装してあります。ニューロンを表すclass Neuronを用意して、ネットワーク内の各ニューロンはNeuron classのインスタンスで表現します。また、Rubyの組み込み＆標準ライブラリのみ使用して実装しており、入力、出力に使用するデータ構造もRuby標準のArrayです。ニューロン指向での実装の良い点は、各ニューロンを個別に操作して実験したい場合などそれほど難しくない（はず）。悪い点は、とにかく遅い。</p>

<h1>
<span id="使用環境ライブラリ" class="fragment"></span><a href="#%E4%BD%BF%E7%94%A8%E7%92%B0%E5%A2%83%E3%83%A9%E3%82%A4%E3%83%96%E3%83%A9%E3%83%AA"><i class="fa fa-link"></i></a>使用環境、ライブラリ</h1>

<p>今回作ったgemは、rubygems.orgにruby_brainとしてリリースしています。また、ソースコードはgithubに公開しています。<br>
<a href="https://rubygems.org/gems/ruby_brain" rel="nofollow noopener" target="_blank">rubygems.org/gems/ruby_brain</a><br>
<a href="https://github.com/elgoog/ruby_brain" rel="nofollow noopener" target="_blank">github.com/elgoog/ruby_brain</a></p>

<p>ruby_brain本体はRubyの組込＆標準ライブラリのみを使用して実装していますので環境準備に関しては大きな問題はないかと思います。以下の記事の内容はRuby 2.3.1で試していますが、他のバージョンでも問題なく動くはずです。<br>
irb/pry等で順次入力して試してみるとよいかも。</p>

<h2>
<span id="インストール" class="fragment"></span><a href="#%E3%82%A4%E3%83%B3%E3%82%B9%E3%83%88%E3%83%BC%E3%83%AB"><i class="fa fa-link"></i></a>インストール</h2>

<p><code>gem install ruby_brain</code></p>

<h2>
<span id="iruby-notebook" class="fragment"></span><a href="#iruby-notebook"><i class="fa fa-link"></i></a>iRuby notebook</h2>

<p>この記事では３つのexampleを取り扱いますが、後半２つのexampleについては、iRuby notebookでも用意しました。<br>
一部、本記事と違う部分もありますが、こちらのnotebookもご参照ください。<br>
<a href="http://nbviewer.jupyter.org/github/elgoog/ruby_brain/blob/master/examples/wave_form.ipynb" rel="nofollow noopener" target="_blank">examples/wave_form - iRuby</a><br>
<a href="http://nbviewer.jupyter.org/github/elgoog/ruby_brain/blob/master/examples/mnist.ipynb" rel="nofollow noopener" target="_blank">examples/mnist - iRuby</a><br>
本記事内の図はiRuby notebook上でnyaplotを使って描いたものを貼り付けています。</p>

<h1>
<span id="example-1---andネットワーク" class="fragment"></span><a href="#example-1---and%E3%83%8D%E3%83%83%E3%83%88%E3%83%AF%E3%83%BC%E3%82%AF"><i class="fa fa-link"></i></a>Example 1 - ANDネットワーク</h1>

<p>まず、簡単な例として２入力、１出力のANDの動作を行うANDネットワークを構築してみます。<br>
ANDの真理値表は以下のとおりです。<br>
入力が両方共１の時に出力が１、それ以外の時は出力が０となることを期待しています。</p>

<table>
<thead>
<tr>
<th style="text-align: center">in 1</th>
<th style="text-align: center">in 2</th>
<th style="text-align: center">out</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center">0</td>
<td style="text-align: center">0</td>
<td style="text-align: center">0</td>
</tr>
<tr>
<td style="text-align: center">0</td>
<td style="text-align: center">1</td>
<td style="text-align: center">0</td>
</tr>
<tr>
<td style="text-align: center">1</td>
<td style="text-align: center">0</td>
<td style="text-align: center">0</td>
</tr>
<tr>
<td style="text-align: center">1</td>
<td style="text-align: center">1</td>
<td style="text-align: center">1</td>
</tr>
</tbody>
</table>

<h2>
<span id="データセット" class="fragment"></span><a href="#%E3%83%87%E3%83%BC%E3%82%BF%E3%82%BB%E3%83%83%E3%83%88"><i class="fa fa-link"></i></a>データセット</h2>

<p>ネットワークの学習に使うデータセットを準備します。<br>
入力データ、出力データともに2次元Arrayになります。各次元はデータのサンプル、データのfeature（上記表の各カラム）に使用されます。</p>

<div class="code-frame" data-lang="ruby"><div class="highlight"><pre>
<span class="n">training_input_set</span> <span class="o">=</span> <span class="o">[</span>
  <span class="o">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="o">]</span><span class="p">,</span>
  <span class="o">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="o">]</span><span class="p">,</span>
  <span class="o">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="o">]</span><span class="p">,</span>
  <span class="o">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="o">]</span><span class="p">,</span>
<span class="o">]</span>

<span class="n">training_supervisor_set</span> <span class="o">=</span> <span class="o">[</span>
  <span class="o">[</span><span class="mi">0</span><span class="o">]</span><span class="p">,</span>
  <span class="o">[</span><span class="mi">0</span><span class="o">]</span><span class="p">,</span>
  <span class="o">[</span><span class="mi">0</span><span class="o">]</span><span class="p">,</span>
  <span class="o">[</span><span class="mi">1</span><span class="o">]</span><span class="p">,</span>
<span class="o">]</span>
</pre></div></div>

<p>training_input_setがネットワークへの入力データセット、それを入力した際に期待する出力データセットがtraining_supervisor_setです。</p>

<h1>
<span id="ネットワークの構築" class="fragment"></span><a href="#%E3%83%8D%E3%83%83%E3%83%88%E3%83%AF%E3%83%BC%E3%82%AF%E3%81%AE%E6%A7%8B%E7%AF%89"><i class="fa fa-link"></i></a>ネットワークの構築</h1>

<p>ネットワークの構造はArrayで表します。<br>
入力２、５つのニューロンをもつ隠れ層１、出力１のネットワーク構造は下記の通り表現できます。</p>

<div class="code-frame" data-lang="ruby"><div class="highlight"><pre>
<span class="c1"># 2 inputs</span>
<span class="c1"># 5 units in a hidden layer</span>
<span class="c1"># 1 output</span>
<span class="o">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">1</span><span class="o">]</span>
</pre></div></div>

<p>隠れ層が２層以上の場合も下記のように簡単に記述できます。</p>

<div class="code-frame" data-lang="ruby"><div class="highlight"><pre>
<span class="c1"># 2 inputs</span>
<span class="c1"># 4 units in 1st hidden layer</span>
<span class="c1"># 3 units in 2nd hidden layer</span>
<span class="c1"># 1 output</span>
<span class="o">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="o">]</span>
</pre></div></div>

<p>次に、実際にネットワークを作ってみます。<br>
ここでは、ANDの入力が２つ、出力が１つなので、<code>[2, 5, 1]</code>の構成にします。<br>
隠れ層は１つでニューロン５つを持つことにしました。</p>

<div class="code-frame" data-lang="ruby"><div class="highlight"><pre>
<span class="nb">require</span> <span class="s1">'ruby_brain'</span>

<span class="c1"># Netwworkクラスのコンストラクタにネットワーク構造Arrayを渡すことによりネットワークを作る</span>
<span class="n">a_network</span> <span class="o">=</span> <span class="no">RubyBrain</span><span class="o">::</span><span class="no">Network</span><span class="o">.</span><span class="n">new</span><span class="p">(</span><span class="o">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">1</span><span class="o">]</span><span class="p">)</span>

<span class="c1"># learning_rateをセットします。（私の設計ミスでこんなところで学習率を設定することになってます。。時間取れたら修正するかもしれません。）</span>
<span class="n">a_network</span><span class="o">.</span><span class="n">learning_rate</span> <span class="o">=</span> <span class="mi">0</span><span class="o">.</span><span class="mi">5</span>

<span class="c1"># ネットワークを使用する前に初期化する必要があります。ここで実際に内部で重み用Arrayを確保し、初期値を設定します</span>
<span class="n">a_network</span><span class="o">.</span><span class="n">init_network</span>
</pre></div></div>

<h2>
<span id="トレーニング" class="fragment"></span><a href="#%E3%83%88%E3%83%AC%E3%83%BC%E3%83%8B%E3%83%B3%E3%82%B0"><i class="fa fa-link"></i></a>トレーニング</h2>

<p>ネットワークのトレーニングはlearnメソッドに、入力データ、期待する出力データ（教師データ）を与えることにより、行います。</p>

<div class="code-frame" data-lang="ruby"><div class="highlight"><pre>
<span class="c1"># max_training_cout : 最大で何回まで学習を行うかを設定</span>
<span class="c1"># tolerance : RMSエラーの許容値を設定。エラーがこの値より小さくなると学習会数がmax_training_countに達していなくても学習を終了する</span>
<span class="c1"># monitoring_channels : 学習中に何をログとして出力するかを設定。今のところ下記の設定をしておいてください。</span>
<span class="n">a_network</span><span class="o">.</span><span class="n">learn</span><span class="p">(</span><span class="n">training_input_set</span><span class="p">,</span> <span class="n">training_supervisor_set</span><span class="p">,</span> <span class="n">max_training_count</span><span class="o">=</span><span class="mi">3000</span><span class="p">,</span> <span class="n">tolerance</span><span class="o">=</span><span class="mi">0</span><span class="o">.</span><span class="mo">0004</span><span class="p">,</span> <span class="n">monitoring_channels</span><span class="o">=[</span><span class="ss">:best_params_training</span><span class="o">]</span><span class="p">)</span>
</pre></div></div>

<p>メソッドの実行が終了したら、a_networkがAND動作を行うように最適化されているはずです。</p>

<h2>
<span id="ネットワークの動作確認" class="fragment"></span><a href="#%E3%83%8D%E3%83%83%E3%83%88%E3%83%AF%E3%83%BC%E3%82%AF%E3%81%AE%E5%8B%95%E4%BD%9C%E7%A2%BA%E8%AA%8D"><i class="fa fa-link"></i></a>ネットワークの動作確認</h2>

<p>get_forward_outputsメソッドを使用することにより、ネットワークに入力を与えた場合の出力を得ることができます。<br>
ANDのin1, in2に各入力を与えて確かめてみます。</p>

<div class="code-frame" data-lang="ruby"><div class="highlight"><pre>
<span class="n">a_network</span><span class="o">.</span><span class="n">get_forward_outputs</span><span class="p">(</span><span class="o">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="o">]</span><span class="p">)</span> <span class="c1"># =&gt; [0.00023268152328014436]</span>
<span class="n">a_network</span><span class="o">.</span><span class="n">get_forward_outputs</span><span class="p">(</span><span class="o">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="o">]</span><span class="p">)</span> <span class="c1"># =&gt; [0.01829368167074594]</span>
<span class="n">a_network</span><span class="o">.</span><span class="n">get_forward_outputs</span><span class="p">(</span><span class="o">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="o">]</span><span class="p">)</span> <span class="c1"># =&gt; [0.01900452216228691]</span>
<span class="n">a_network</span><span class="o">.</span><span class="n">get_forward_outputs</span><span class="p">(</span><span class="o">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="o">]</span><span class="p">)</span> <span class="c1"># =&gt; [0.9727050287128143]</span>
</pre></div></div>

<p>ネットワークが正しくANDの動作を行っていることが確認できます。<br>
ここでの出力値は、上記とピッタリ同じになることはありません。ネットワーク内の重みの初期値がランダムに設定されているため、学習が終わった時点でネットワーク内の重みが私の環境と同じになる可能性は非常に低いためです。<br>
しかし、[1, 1]を入力した場合に1に近い値、それ以外の入力の場合0に近い値になっているはずです。<br>
以上でANDネットワークの構築完了です。</p>

<h2>
<span id="ネットワークの重みの保存復元" class="fragment"></span><a href="#%E3%83%8D%E3%83%83%E3%83%88%E3%83%AF%E3%83%BC%E3%82%AF%E3%81%AE%E9%87%8D%E3%81%BF%E3%81%AE%E4%BF%9D%E5%AD%98%E5%BE%A9%E5%85%83"><i class="fa fa-link"></i></a>ネットワークの重みの保存＆復元</h2>

<p>上記の例のネットワークは非常に単純なものなので、トレーニングにも時間がかかりませんでしたが、<br>
もっと大きな構造＆大きなデータでトレーニングしてネットワークを作った場合、出来上がったネットワークの重みを再利用したい場合があるかと思います。<br>
以下のメソッドで、保存＆復元が可能です。フォーマットはYAMLで保存されます。</p>

<div class="code-frame" data-lang="ruby"><div class="highlight"><pre>
<span class="c1"># 保存</span>
<span class="n">a_network</span><span class="o">.</span><span class="n">dump_weights_to_yaml</span><span class="p">(</span><span class="s1">'/path/to/saved/weights/file.yml'</span><span class="p">)</span>

<span class="c1"># 復元</span>
<span class="n">a_network</span> <span class="o">=</span> <span class="no">RubyBrain</span><span class="o">::</span><span class="no">Network</span><span class="o">.</span><span class="n">new</span><span class="p">(</span><span class="o">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">1</span><span class="o">]</span><span class="p">)</span>
<span class="n">a_network</span><span class="o">.</span><span class="n">init_network</span>
<span class="n">a_network</span><span class="o">.</span><span class="n">load_weights_from_yaml_file</span><span class="p">(</span><span class="s1">'/path/to/saved/weights/file.yml'</span><span class="p">)</span>
</pre></div></div>

<h1>
<span id="example-2---波形の近似" class="fragment"></span><a href="#example-2---%E6%B3%A2%E5%BD%A2%E3%81%AE%E8%BF%91%E4%BC%BC"><i class="fa fa-link"></i></a>Example 2 - 波形の近似</h1>

<p>次に少しデータ量を増やした例を見るため、適当な波形を作ってトレーニングデータとして使用してみます。<br>
iRuby notebook版はこちら＝＞　<a href="http://nbviewer.jupyter.org/github/elgoog/ruby_brain/blob/master/examples/wave_form.ipynb" rel="nofollow noopener" target="_blank">examples/wave_form - iRuby</a></p>

<p>ここで、しれっと書きますが、、<br>
現在activation関数としてsigmoid関数を持つニューロンしか用意してません。。（完全な手抜きです。。）<br>
なので最終層もsigmoidの出力0~1しか出力できないため、学習データセットも0~1の間で表現するように注意します。(入力側は0~1の範囲外でも大丈夫です。)</p>

<p>Xの値を0~1の範囲、0.01ステップで用意します。</p>

<div class="code-frame" data-lang="ruby"><div class="highlight"><pre>
<span class="n">X</span> <span class="o">=</span> <span class="p">(</span><span class="mi">0</span><span class="o">.</span><span class="n">.</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="mi">0</span><span class="o">.</span><span class="mo">01</span><span class="p">)</span><span class="o">.</span><span class="n">to_a</span>
</pre></div></div>

<p>$(0.75 * sin(x*2*\pi) + 0.15 * cos(5*\pi – 0.023) + 1) / 2$をY_IDEALとして、<br>
それにランダムでノイズ(-0.05..0.005)をのせたものをYとします。</p>

<div class="code-frame" data-lang="ruby"><div class="highlight"><pre>
<span class="no">Y_IDEAL</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">map</span> <span class="p">{</span><span class="o">|</span><span class="n">x</span><span class="o">|</span> <span class="p">(</span><span class="mi">0</span><span class="o">.</span><span class="mi">75</span> <span class="o">*</span> <span class="no">Math</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">x</span><span class="o">*</span><span class="mi">2</span><span class="o">*</span><span class="no">Math</span><span class="o">::</span><span class="no">PI</span><span class="p">)</span> <span class="o">-</span> <span class="mi">0</span><span class="o">.</span><span class="mi">2</span> <span class="o">*</span> <span class="no">Math</span><span class="o">.</span><span class="n">cos</span><span class="p">(</span><span class="mi">5</span><span class="o">*</span><span class="n">x</span><span class="o">*</span><span class="mi">2</span><span class="o">*</span><span class="no">Math</span><span class="o">::</span><span class="no">PI</span> <span class="o">-</span> <span class="mi">0</span><span class="o">.</span><span class="mo">023</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">/</span> <span class="mi">2</span><span class="p">}</span> 
<span class="n">Y</span> <span class="o">=</span> <span class="o">[</span><span class="no">Y_IDEAL</span><span class="p">,</span> <span class="nb">Array</span><span class="o">.</span><span class="n">new</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">size</span><span class="p">)</span> <span class="p">{</span><span class="nb">rand</span><span class="p">(</span><span class="o">-</span><span class="mi">0</span><span class="o">.</span><span class="mo">05</span><span class="o">.</span><span class="n">.</span><span class="mi">0</span><span class="o">.</span><span class="mo">05</span><span class="p">)}</span><span class="o">].</span><span class="n">transpose</span><span class="o">.</span><span class="n">map</span> <span class="p">{</span><span class="o">|</span><span class="n">e</span><span class="o">|</span> <span class="n">e</span><span class="o">.</span><span class="n">inject</span><span class="p">(</span><span class="ss">:+</span><span class="p">)}</span>
</pre></div></div>

<p>私の環境で生成したX, Y, Y_IDEALをプロットしてみると以下のようになりました。<br>
<a href="https://qiita-image-store.s3.amazonaws.com/0/40955/93682713-95b2-b03e-33dc-efdeca0c4bf8.png" target="_blank" rel="nofollow noopener"><img src="https://qiita-image-store.s3.amazonaws.com/0/40955/93682713-95b2-b03e-33dc-efdeca0c4bf8.png" alt="example2_1.png"></a></p>

<p>このXをinput、Yをoutputとしてネットワークに学習させます。<br>
ネットワークは構成は<code>[1, 13, 6, 1]</code>にしてみました。</p>

<div class="code-frame" data-lang="ruby"><div class="highlight"><pre>
<span class="n">a_network</span> <span class="o">=</span> <span class="no">RubyBrain</span><span class="o">::</span><span class="no">Network</span><span class="o">.</span><span class="n">new</span><span class="p">(</span><span class="o">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">13</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">1</span><span class="o">]</span><span class="p">)</span>
<span class="n">a_network</span><span class="o">.</span><span class="n">init_network</span>
<span class="n">a_network</span><span class="o">.</span><span class="n">learning_rate</span> <span class="o">=</span> <span class="mi">0</span><span class="o">.</span><span class="mi">5</span>
<span class="n">a_network</span><span class="o">.</span><span class="n">learn</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">map</span><span class="p">{</span><span class="o">|</span><span class="n">e</span><span class="o">|</span> <span class="o">[</span><span class="n">e</span><span class="o">]</span><span class="p">},</span> <span class="n">Y</span><span class="o">.</span><span class="n">map</span><span class="p">{</span><span class="o">|</span><span class="n">e</span><span class="o">|</span> <span class="o">[</span><span class="n">e</span><span class="o">]</span><span class="p">},</span> <span class="n">max_tra2ining_count</span><span class="o">=</span><span class="mi">40000</span><span class="p">,</span> <span class="n">tolerance</span><span class="o">=</span><span class="mi">0</span><span class="o">.</span><span class="mo">0004</span><span class="p">,</span> <span class="n">monitoring_channels</span><span class="o">=[</span><span class="ss">:best_params_training</span><span class="o">]</span><span class="p">)</span>
</pre></div></div>

<p>トレーニングした<code>a_networ</code>は下記のコードで確認できます。Y_PREDICATEDが<code>a_network</code>にXを入れた時のoutputになります。</p>

<div class="code-frame" data-lang="rb"><div class="highlight"><pre>
<span class="no">Y_PREDICATED</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">map</span><span class="p">{</span><span class="o">|</span><span class="n">e</span><span class="o">|</span> <span class="o">[</span><span class="n">e</span><span class="o">]</span><span class="p">}</span><span class="o">.</span><span class="n">map</span> <span class="p">{</span><span class="o">|</span><span class="n">a</span><span class="o">|</span> <span class="n">a_network</span><span class="o">.</span><span class="n">get_forward_outputs</span><span class="p">(</span><span class="n">a</span><span class="p">)</span><span class="o">.</span><span class="n">first</span><span class="p">}</span>
</pre></div></div>

<p>私の環境での結果をプロットすると下図のようになりました。<br>
良い感じで模倣しています。<br>
<a href="https://qiita-image-store.s3.amazonaws.com/0/40955/e14500f4-d0cb-0db9-f93f-be0d45920a30.png" target="_blank" rel="nofollow noopener"><img src="https://qiita-image-store.s3.amazonaws.com/0/40955/e14500f4-d0cb-0db9-f93f-be0d45920a30.png" alt="fig(1).png"></a></p>

<h1>
<span id="example-3---mnist" class="fragment"></span><a href="#example-3---mnist"><i class="fa fa-link"></i></a>Example 3 - MNIST</h1>

<p>Exampleの最後としてMNISTを試してみます。28*28ピクセルの手書き数字画像を0~9にクラス分けする機械学習のHelloWorld的なチュートリアルです。<br>
iRuby notebook版はこちら　＝＞　<a href="http://nbviewer.jupyter.org/github/elgoog/ruby_brain/blob/master/examples/mnist.ipynb" rel="nofollow noopener" target="_blank">examples/mnist - iRuby</a></p>

<h2>
<span id="mnistデータの取得" class="fragment"></span><a href="#mnist%E3%83%87%E3%83%BC%E3%82%BF%E3%81%AE%E5%8F%96%E5%BE%97"><i class="fa fa-link"></i></a>MNISTデータの取得</h2>

<p>付属の便利メソッドを使用するとMNISTのデータを簡単にRubyのArrayに入れることができます。<br>
データは <a href="http://yann.lecun.com/exdb/mnist/" rel="nofollow noopener" target="_blank">THE MNIST DATABASE of handwritten digits</a> より、取得しています。<br>
また、データの読み込みにはmrknさんのgem <a href="https://rubygems.org/gems/mnist" rel="nofollow noopener" target="_blank">mnist</a>を使用させていただきました。</p>

<div class="code-frame" data-lang="ruby"><div class="highlight"><pre>
<span class="nb">require</span> <span class="s1">'ruby_brain'</span>

<span class="c1"># MNISTのデータセットを取り扱う便利メソッドをロード</span>
<span class="nb">require</span> <span class="s1">'ruby_brain/dataset/mnist/data'</span>
</pre></div></div>

<p>下記のように、<code>DataSet::Mnist::data</code>メソッドを実行するとMNISTのデータをArrayとして取得できます。<br>
datasetはArrayで、training用データセットとtest用データセットを持っています。</p>

<div class="code-frame" data-lang="ruby"><div class="highlight"><pre>
<span class="n">dataset</span> <span class="o">=</span> <span class="no">RubyBrain</span><span class="o">::</span><span class="no">DataSet</span><span class="o">::</span><span class="no">Mnist</span><span class="o">::</span><span class="n">data</span>
<span class="n">training_dataset</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">first</span>
<span class="n">test_dataset</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">last</span>
</pre></div></div>

<p>各データセットは、以下のようになっています</p>

<div class="code-frame" data-lang="rb"><div class="highlight"><pre>
<span class="c1"># :input, :outputをkeyとするHashになっています。</span>
<span class="n">training_dataset</span><span class="o">.</span><span class="n">keys</span> <span class="c1"># =&gt; [:input, :output]</span>
<span class="n">test_dataset</span><span class="o">.</span><span class="n">keys</span>     <span class="c1"># =&gt; [:input, :output]</span>

<span class="c1"># トレーニングデータセットの :input は 60000(samples) x 784(28 * 28 input pixcels)</span>
<span class="n">training_dataset</span><span class="o">[</span><span class="ss">:input</span><span class="o">].</span><span class="n">size</span>       <span class="c1"># =&gt; 60000</span>
<span class="n">training_dataset</span><span class="o">[</span><span class="ss">:input</span><span class="o">].</span><span class="n">first</span><span class="o">.</span><span class="n">size</span> <span class="c1"># =&gt; 784</span>

<span class="c1"># トレーニングデータセットの :output は 60000(samples) x 10(0~9の10クラス)</span>
<span class="n">training_dataset</span><span class="o">[</span><span class="ss">:output</span><span class="o">].</span><span class="n">size</span>       <span class="c1"># =&gt; 60000</span>
<span class="n">training_dataset</span><span class="o">[</span><span class="ss">:output</span><span class="o">].</span><span class="n">first</span><span class="o">.</span><span class="n">size</span> <span class="c1"># =&gt; 10</span>

<span class="c1"># テストデータセットの:input は 10000(samples) x 784(28 * 28 input pixcels)</span>
<span class="n">test_dataset</span><span class="o">[</span><span class="ss">:input</span><span class="o">].</span><span class="n">size</span>       <span class="c1"># =&gt; 10000</span>
<span class="n">test_dataset</span><span class="o">[</span><span class="ss">:input</span><span class="o">].</span><span class="n">first</span><span class="o">.</span><span class="n">size</span> <span class="c1"># =&gt; 784</span>

<span class="c1"># テストデータセットの :output は 10000(samples) x 10(0~9の10クラス)</span>
<span class="n">test_dataset</span><span class="o">[</span><span class="ss">:output</span><span class="o">].</span><span class="n">size</span>       <span class="c1"># =&gt; 10000</span>
<span class="n">test_dataset</span><span class="o">[</span><span class="ss">:output</span><span class="o">].</span><span class="n">first</span><span class="o">.</span><span class="n">size</span> <span class="c1"># =&gt; 10</span>
</pre></div></div>

<p>この例ではtraining_datasetの最初の5000サンプルのみ実際のトレーニングに使用します。RubyBrainが遅く、全70000枚の画像を使用すると学習に時間がかかりすぎるためです。</p>

<div class="code-frame" data-lang="rb"><div class="highlight"><pre>
<span class="c1"># 最初の5000枚のみトレーニングに使用</span>
<span class="no">NUM_TRAIN_DATA</span> <span class="o">=</span> <span class="mi">5000</span>
<span class="n">training_input</span> <span class="o">=</span> <span class="n">training_dataset</span><span class="o">[</span><span class="ss">:input</span><span class="o">][</span><span class="mi">0</span><span class="o">.</span><span class="n">.</span><span class="p">(</span><span class="no">NUM_TRAIN_DATA</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">]</span>
<span class="n">training_supervisor</span> <span class="o">=</span> <span class="n">training_dataset</span><span class="o">[</span><span class="ss">:output</span><span class="o">][</span><span class="mi">0</span><span class="o">.</span><span class="n">.</span><span class="p">(</span><span class="no">NUM_TRAIN_DATA</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">]</span>
<span class="c1"># test_datasetはすべて使用</span>
<span class="n">test_input</span> <span class="o">=</span> <span class="n">test_dataset</span><span class="o">[</span><span class="ss">:input</span><span class="o">]</span>
<span class="n">test_supervisor</span> <span class="o">=</span> <span class="n">test_dataset</span><span class="o">[</span><span class="ss">:output</span><span class="o">]</span>
</pre></div></div>

<h2>
<span id="ネットワークの構築トレーニング実行" class="fragment"></span><a href="#%E3%83%8D%E3%83%83%E3%83%88%E3%83%AF%E3%83%BC%E3%82%AF%E3%81%AE%E6%A7%8B%E7%AF%89%E3%83%88%E3%83%AC%E3%83%BC%E3%83%8B%E3%83%B3%E3%82%B0%E5%AE%9F%E8%A1%8C"><i class="fa fa-link"></i></a>ネットワークの構築＆トレーニング実行</h2>

<p>ここでは画像が784(28x28)ピクセルで10クラス(0..9)分類です。<br>
隠れ層は１層で50個のニューロンを持つとして、<code>[784, 50, 10]</code>として構成しました。</p>

<div class="code-frame" data-lang="rb"><div class="highlight"><pre>
<span class="c1"># ネットワーク構成 [784, 50, 10]</span>
<span class="n">network</span> <span class="o">=</span> <span class="no">RubyBrain</span><span class="o">::</span><span class="no">Network</span><span class="o">.</span><span class="n">new</span><span class="p">(</span><span class="o">[</span><span class="n">training_input</span><span class="o">.</span><span class="n">first</span><span class="o">.</span><span class="n">size</span><span class="p">,</span> <span class="mi">50</span><span class="p">,</span> <span class="n">training_supervisor</span><span class="o">.</span><span class="n">first</span><span class="o">.</span><span class="n">size</span><span class="o">]</span><span class="p">)</span>
<span class="c1"># learning rate is 0.7</span>
<span class="n">network</span><span class="o">.</span><span class="n">learning_rate</span> <span class="o">=</span> <span class="mi">0</span><span class="o">.</span><span class="mi">7</span>
<span class="c1"># initialize network</span>
<span class="n">network</span><span class="o">.</span><span class="n">init_network</span>
</pre></div></div>

<p>トレーニングの実行</p>

<div class="code-frame" data-lang="rb"><div class="highlight"><pre>
<span class="n">network</span><span class="o">.</span><span class="n">learn</span><span class="p">(</span><span class="n">training_input</span><span class="p">,</span> <span class="n">training_supervisor</span><span class="p">,</span> <span class="n">max_training_count</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">tolerance</span><span class="o">=</span><span class="mi">0</span><span class="o">.</span><span class="mo">0004</span><span class="p">,</span> <span class="n">monitoring_channels</span><span class="o">=[</span><span class="ss">:best_params_training</span><span class="o">]</span><span class="p">)</span>
</pre></div></div>

<h2>
<span id="結果の確認" class="fragment"></span><a href="#%E7%B5%90%E6%9E%9C%E3%81%AE%E7%A2%BA%E8%AA%8D"><i class="fa fa-link"></i></a>結果の確認</h2>

<p>下記のコードで、トレーニングしたnetworkをtest_datasetを使って評価できます。<br>
画像１枚分のデータ（input）をnetworkに入力した際の出力がpredicated_outputです。<br>
このpredicated_outputはサイズ10のArrayで、そのindex 0~9がラベル0~9に対応します。<br>
そして、最も大きい要素を持つindexがnetworkの予想したラベル（数字）となります。<br>
下記のコードでは、手書き画像を簡易的にasciiで表示しています。<br>
フルで走らすと10000枚分がstdoutに出力され、非常に時間がかかるので気をつけてください。<br>
最後のaccuracyが認識率です。</p>

<div class="code-frame" data-lang="rb"><div class="highlight"><pre>
<span class="n">test_input</span><span class="o">.</span><span class="n">each_with_index</span> <span class="k">do</span> <span class="o">|</span><span class="n">input</span><span class="p">,</span> <span class="n">i</span><span class="o">|</span>
  <span class="n">input</span><span class="o">.</span><span class="n">each_with_index</span> <span class="k">do</span> <span class="o">|</span><span class="n">e</span><span class="p">,</span> <span class="n">j</span><span class="o">|</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">e</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="o">.</span><span class="mi">3</span> <span class="o">?</span> <span class="s1">'x'</span> <span class="p">:</span> <span class="s1">' '</span><span class="p">)</span>
    <span class="nb">puts</span> <span class="k">if</span> <span class="p">(</span><span class="n">j</span> <span class="o">%</span> <span class="mi">28</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span>
  <span class="k">end</span>
  <span class="nb">puts</span>
  <span class="n">supervisor_label</span> <span class="o">=</span> <span class="n">test_supervisor</span><span class="o">[</span><span class="n">i</span><span class="o">].</span><span class="n">index</span><span class="p">(</span><span class="n">test_supervisor</span><span class="o">[</span><span class="n">i</span><span class="o">].</span><span class="n">max</span><span class="p">)</span>
  <span class="n">predicated_output</span> <span class="o">=</span> <span class="n">network</span><span class="o">.</span><span class="n">get_forward_outputs</span><span class="p">(</span><span class="n">input</span><span class="p">)</span>
  <span class="n">predicated_label</span> <span class="o">=</span> <span class="n">predicated_output</span><span class="o">.</span><span class="n">index</span><span class="p">(</span><span class="n">predicated_output</span><span class="o">.</span><span class="n">max</span><span class="p">)</span>
  <span class="nb">puts</span> <span class="s2">"test_supervisor: </span><span class="si">#{</span><span class="n">supervisor_label</span><span class="si">}</span><span class="s2">"</span>
  <span class="nb">puts</span> <span class="s2">"predicate: </span><span class="si">#{</span><span class="n">predicated_label</span><span class="si">}</span><span class="s2">"</span>
  <span class="n">results</span> <span class="o">&lt;&lt;</span> <span class="p">(</span><span class="n">supervisor_label</span> <span class="o">==</span> <span class="n">predicated_label</span><span class="p">)</span>
  <span class="nb">puts</span> <span class="s2">"------------------------------------------------------------"</span>
<span class="k">end</span>

<span class="nb">puts</span> <span class="s2">"accuracy: </span><span class="si">#{</span><span class="n">results</span><span class="o">.</span><span class="n">count</span><span class="p">(</span><span class="kp">true</span><span class="p">)</span><span class="o">.</span><span class="n">to_f</span><span class="o">/</span><span class="n">results</span><span class="o">.</span><span class="n">size</span><span class="si">}</span><span class="s2">"</span>
</pre></div></div>

<p>実際にどんな画像で誤判定をしたかみてみると、なぜこれを間違うのかってのもいくつか見られましたが、多くが確かに間違える可能性ありそうな画像でした。以下、判定を間違ったケースの一部です。</p>

<p><a href="https://qiita-image-store.s3.amazonaws.com/0/40955/504cc547-7f43-aef3-661d-4c4b55f7262e.png" target="_blank" rel="nofollow noopener"><img src="https://qiita-image-store.s3.amazonaws.com/0/40955/504cc547-7f43-aef3-661d-4c4b55f7262e.png" alt="mnist_1_5_2.png"></a><br>
test_supervisor[8] : 5<br>
predicated_class : 2<br>
　-------------------------------------------------------------------------------------</p>

<p><a href="https://qiita-image-store.s3.amazonaws.com/0/40955/ff89c2bb-9290-e69c-1871-8e526cd6c856.png" target="_blank" rel="nofollow noopener"><img src="https://qiita-image-store.s3.amazonaws.com/0/40955/ff89c2bb-9290-e69c-1871-8e526cd6c856.png" alt="mnist_2_4_6.png"></a><br>
test_supervisor[33] : 4<br>
predicated_class : 6<br>
　-------------------------------------------------------------------------------------</p>

<p><a href="https://qiita-image-store.s3.amazonaws.com/0/40955/73f9742a-4596-1724-cfdd-0a07537560d7.png" target="_blank" rel="nofollow noopener"><img src="https://qiita-image-store.s3.amazonaws.com/0/40955/73f9742a-4596-1724-cfdd-0a07537560d7.png" alt="mnist_3_6_2.png"></a><br>
test_supervisor[66] : 6<br>
predicated_class : 2<br>
　-------------------------------------------------------------------------------------</p>

<p><a href="https://qiita-image-store.s3.amazonaws.com/0/40955/a5e3a848-c818-c85e-a24d-fb04e01e2fab.png" target="_blank" rel="nofollow noopener"><img src="https://qiita-image-store.s3.amazonaws.com/0/40955/a5e3a848-c818-c85e-a24d-fb04e01e2fab.png" alt="mnist_4_9_7.png"></a><br>
test_supervisor[73] : 9<br>
predicated_class : 7<br>
　-------------------------------------------------------------------------------------</p>

<p><a href="https://qiita-image-store.s3.amazonaws.com/0/40955/a1c0d197-1c7d-87f2-1e4d-e4f939bf79b7.png" target="_blank" rel="nofollow noopener"><img src="https://qiita-image-store.s3.amazonaws.com/0/40955/a1c0d197-1c7d-87f2-1e4d-e4f939bf79b7.png" alt="mnist_5_9_4.png"></a><br>
test_supervisor[92] : 9<br>
predicated_class : 4<br>
　-------------------------------------------------------------------------------------</p>

<p><a href="https://qiita-image-store.s3.amazonaws.com/0/40955/add03f61-f58f-8693-93e9-a25c9f012ed8.png" target="_blank" rel="nofollow noopener"><img src="https://qiita-image-store.s3.amazonaws.com/0/40955/add03f61-f58f-8693-93e9-a25c9f012ed8.png" alt="mnist_6_9_5.png"></a><br>
test_supervisor[104] : 9<br>
predicated_class : 5<br>
　-------------------------------------------------------------------------------------</p>

<p><a href="https://qiita-image-store.s3.amazonaws.com/0/40955/5bc1b286-8203-22ff-b30d-b711053fe687.png" target="_blank" rel="nofollow noopener"><img src="https://qiita-image-store.s3.amazonaws.com/0/40955/5bc1b286-8203-22ff-b30d-b711053fe687.png" alt="mnist_7_2_9.png"></a><br>
test_supervisor[149] : 2<br>
predicated_class : 9<br>
　-------------------------------------------------------------------------------------</p>

<p><a href="https://qiita-image-store.s3.amazonaws.com/0/40955/c9c60812-f7ee-1d47-6592-dd41a9949eef.png" target="_blank" rel="nofollow noopener"><img src="https://qiita-image-store.s3.amazonaws.com/0/40955/c9c60812-f7ee-1d47-6592-dd41a9949eef.png" alt="mnist_8_9_5.png"></a><br>
test_supervisor[151] : 9<br>
predicated_class : 5<br>
　-------------------------------------------------------------------------------------</p>

<p>私の環境では上記の条件で、何回かためしてみて0.9312(93.12%)の認識率になりました。<br>
出来上がった重みは <a href="https://github.com/elgoog/weights_ruby_brain/blob/master/weights_782_50_10_1.yml" rel="nofollow noopener" target="_blank">こちら</a></p>

<h1>
<span id="最後に" class="fragment"></span><a href="#%E6%9C%80%E5%BE%8C%E3%81%AB"><i class="fa fa-link"></i></a>最後に</h1>

<p>本記事のタイトルにディープラーニングとついていますが、ReLUすら実装していないのでかなりつりっぽいタイトルになっていてすみませんm(_ _)m<br>
MNISTの認識率が予想外に簡単に90%を超えることができました。やはりここから更に上げていくのが難しいんでしょうね。</p>

<h3>
<span id="やりたかったけどやらなかったこと" class="fragment"></span><a href="#%E3%82%84%E3%82%8A%E3%81%9F%E3%81%8B%E3%81%A3%E3%81%9F%E3%81%91%E3%81%A9%E3%82%84%E3%82%89%E3%81%AA%E3%81%8B%E3%81%A3%E3%81%9F%E3%81%93%E3%81%A8"><i class="fa fa-link"></i></a>やりたかったけどやらなかったこと</h3>

<ul>
<li>ランダムノイズをのせるときに、<a href="https://github.com/SciRuby/distribution" rel="nofollow noopener" target="_blank">SciRuby/distribution</a>を使って、ガウス分布でのせる
=&gt; 今回、図の生成に初めてnyaplotを使ってみたところ非常に使いやすかったので、他のSciRubyプロジェクトにも興味がでてきました。見てみたところ面白いプロジェクトが結構あったので今後機会があれば使ってみたい。</li>
</ul>

<h3>
<span id="疑問" class="fragment"></span><a href="#%E7%96%91%E5%95%8F"><i class="fa fa-link"></i></a>疑問</h3>

<p>この記事を書いてて、いくつか不明な点があったのでご存知の方がいましたら教えていただけると助かります。<br>
この記事の趣旨とは関係ない内容ですが。。</p>

<ul>
<li>iruby notebookの各cellのoutputを表示させないようにする方法
=&gt; バックエンドがipythonの場合、<code>%%capture</code>を使えるらしいですが、irubyの場合どうするのかわからなかったので、とりあえず<code>nil</code>を最後に付加して対処。</li>
<li>nyaplotのheatmapのgridが長方形になってしまうのを正方形にする方法</li>
</ul>
<div class="hidden"><form class="js-task-list-update" action="/elgoog/items/8e7102a87889950d060d" accept-charset="UTF-8" method="post"><input name="utf8" type="hidden" value="&#x2713;" /><input type="hidden" name="_method" value="patch" /><input type="hidden" name="authenticity_token" value="5aPf3XBdWlxCePESepOE87Ke7IxwHBNvDWrOJaymO1IaXI8GwZY+dyKk16aV3RNHcWyeUrYJqldsQYK1cTVXMg==" /><input type="hidden" name="updated_at_confirmation_in_unixtime" id="updated_at_confirmation_in_unixtime" value="1472484490" class="js-task-list-updated-at" /><textarea name="raw_body" id="raw_body" class="js-task-list-field">
# 背景
現在、TensorFlow、Chainer他多数のDeepLearning用ライブラリが公開されています。
本格的なアプリケーションで使うには実行スピード、クオリティ、拡張性、ドキュメント、コミュニティの充実等多くの面で、それらの中から選択して使用するのが鉄板な状況です。もちろん、私もメインではそれらを使わせてもらっています。これらのライブラリ、例えばtensorFlowではcomputatoin graphを構築、operationを追加してそれを実行というイメージで（行列、数式で取り扱うイメージ）、根底にある古典的なニューロンの結合という考え方が隠されている気がします。むしろ、そのことは忘れて突き進んでしまっても良い気はしますが、自分の理解を深める意味でもニューロン指向でスクラッチからニューラルネットワークを書いてみました。
使用言語は機械学習分野ではPythonに残念ながら遅れをとっているRubyを選択。
DeepLearningに興味があるけどガッツリではなく少しさわってみたい方、公開ライブラリがpython用のためなんとなく手を出していなかった方などの入り口になればうれしいです。

## RubyBrain
今回使用するライブラリの名前はRubyBrainです。
背景でも書いたとおり現在主流のライブラリは使用者側からはニューロンを繋ぎあわせて人間の脳を模倣したネットワークを作って何かを学習させるという古典的なイメージは隠され、数式をつなぎ合わせてそのgraphを情報が流れて状態更新を行うイメージです。その点では、tensorFlow, Chainer共にネーミングセンスがとてもよいと感心します（特にChainer）。tensorFlowは次元が流れるイメージ、chainerは数式をつなぎ合わせていくイメージで、ライブラリの基本概念をうまく表現しています。
で、RubyBrainですが、名前から少しは想像できるかもしれませんが、古典的なニューロンのつなぎ合わせをイメージして実装してあります。ニューロンを表すclass Neuronを用意して、ネットワーク内の各ニューロンはNeuron classのインスタンスで表現します。また、Rubyの組み込み＆標準ライブラリのみ使用して実装しており、入力、出力に使用するデータ構造もRuby標準のArrayです。ニューロン指向での実装の良い点は、各ニューロンを個別に操作して実験したい場合などそれほど難しくない（はず）。悪い点は、とにかく遅い。

# 使用環境、ライブラリ

今回作ったgemは、rubygems.orgにruby_brainとしてリリースしています。また、ソースコードはgithubに公開しています。
[rubygems.org/gems/ruby_brain](https://rubygems.org/gems/ruby_brain)
[github.com/elgoog/ruby_brain](https://github.com/elgoog/ruby_brain)

ruby_brain本体はRubyの組込＆標準ライブラリのみを使用して実装していますので環境準備に関しては大きな問題はないかと思います。以下の記事の内容はRuby 2.3.1で試していますが、他のバージョンでも問題なく動くはずです。
irb/pry等で順次入力して試してみるとよいかも。

## インストール
`gem install ruby_brain`

## iRuby notebook

この記事では３つのexampleを取り扱いますが、後半２つのexampleについては、iRuby notebookでも用意しました。
一部、本記事と違う部分もありますが、こちらのnotebookもご参照ください。
[examples/wave_form - iRuby](http://nbviewer.jupyter.org/github/elgoog/ruby_brain/blob/master/examples/wave_form.ipynb)
[examples/mnist - iRuby](http://nbviewer.jupyter.org/github/elgoog/ruby_brain/blob/master/examples/mnist.ipynb)
本記事内の図はiRuby notebook上でnyaplotを使って描いたものを貼り付けています。

# Example 1 - ANDネットワーク
まず、簡単な例として２入力、１出力のANDの動作を行うANDネットワークを構築してみます。
ANDの真理値表は以下のとおりです。
入力が両方共１の時に出力が１、それ以外の時は出力が０となることを期待しています。

| in 1 | in 2 | out |
|:----:|:----:|:---:|
| 0    | 0    | 0   |
| 0    | 1    | 0   |
| 1    | 0    | 0   |
| 1    | 1    | 1   |

## データセット
ネットワークの学習に使うデータセットを準備します。
入力データ、出力データともに2次元Arrayになります。各次元はデータのサンプル、データのfeature（上記表の各カラム）に使用されます。

```ruby
training_input_set = [
  [0, 0],
  [0, 1],
  [1, 0],
  [1, 1],
]

training_supervisor_set = [
  [0],
  [0],
  [0],
  [1],
]
```
training_input_setがネットワークへの入力データセット、それを入力した際に期待する出力データセットがtraining_supervisor_setです。

# ネットワークの構築
ネットワークの構造はArrayで表します。
入力２、５つのニューロンをもつ隠れ層１、出力１のネットワーク構造は下記の通り表現できます。

```ruby
# 2 inputs
# 5 units in a hidden layer
# 1 output
[2, 5, 1]
```
隠れ層が２層以上の場合も下記のように簡単に記述できます。

```ruby
# 2 inputs
# 4 units in 1st hidden layer
# 3 units in 2nd hidden layer
# 1 output
[2, 4, 2, 1]
```

次に、実際にネットワークを作ってみます。
ここでは、ANDの入力が２つ、出力が１つなので、`[2, 5, 1]`の構成にします。
隠れ層は１つでニューロン５つを持つことにしました。

```ruby
require &#39;ruby_brain&#39;

# Netwworkクラスのコンストラクタにネットワーク構造Arrayを渡すことによりネットワークを作る
a_network = RubyBrain::Network.new([2, 5, 1])

# learning_rateをセットします。（私の設計ミスでこんなところで学習率を設定することになってます。。時間取れたら修正するかもしれません。）
a_network.learning_rate = 0.5

# ネットワークを使用する前に初期化する必要があります。ここで実際に内部で重み用Arrayを確保し、初期値を設定します
a_network.init_network
```
## トレーニング
ネットワークのトレーニングはlearnメソッドに、入力データ、期待する出力データ（教師データ）を与えることにより、行います。

```ruby
# max_training_cout : 最大で何回まで学習を行うかを設定
# tolerance : RMSエラーの許容値を設定。エラーがこの値より小さくなると学習会数がmax_training_countに達していなくても学習を終了する
# monitoring_channels : 学習中に何をログとして出力するかを設定。今のところ下記の設定をしておいてください。
a_network.learn(training_input_set, training_supervisor_set, max_training_count=3000, tolerance=0.0004, monitoring_channels=[:best_params_training])
```
メソッドの実行が終了したら、a_networkがAND動作を行うように最適化されているはずです。

## ネットワークの動作確認
get_forward_outputsメソッドを使用することにより、ネットワークに入力を与えた場合の出力を得ることができます。
ANDのin1, in2に各入力を与えて確かめてみます。

```ruby
a_network.get_forward_outputs([0, 0]) # =&gt; [0.00023268152328014436]
a_network.get_forward_outputs([0, 1]) # =&gt; [0.01829368167074594]
a_network.get_forward_outputs([1, 0]) # =&gt; [0.01900452216228691]
a_network.get_forward_outputs([1, 1]) # =&gt; [0.9727050287128143]
```
ネットワークが正しくANDの動作を行っていることが確認できます。
ここでの出力値は、上記とピッタリ同じになることはありません。ネットワーク内の重みの初期値がランダムに設定されているため、学習が終わった時点でネットワーク内の重みが私の環境と同じになる可能性は非常に低いためです。
しかし、[1, 1]を入力した場合に1に近い値、それ以外の入力の場合0に近い値になっているはずです。
以上でANDネットワークの構築完了です。

## ネットワークの重みの保存＆復元
上記の例のネットワークは非常に単純なものなので、トレーニングにも時間がかかりませんでしたが、
もっと大きな構造＆大きなデータでトレーニングしてネットワークを作った場合、出来上がったネットワークの重みを再利用したい場合があるかと思います。
以下のメソッドで、保存＆復元が可能です。フォーマットはYAMLで保存されます。

```ruby
# 保存
a_network.dump_weights_to_yaml(&#39;/path/to/saved/weights/file.yml&#39;)

# 復元
a_network = RubyBrain::Network.new([2, 5, 1])
a_network.init_network
a_network.load_weights_from_yaml_file(&#39;/path/to/saved/weights/file.yml&#39;)
```

# Example 2 - 波形の近似
次に少しデータ量を増やした例を見るため、適当な波形を作ってトレーニングデータとして使用してみます。
iRuby notebook版はこちら＝＞　[examples/wave_form - iRuby](http://nbviewer.jupyter.org/github/elgoog/ruby_brain/blob/master/examples/wave_form.ipynb)

ここで、しれっと書きますが、、
現在activation関数としてsigmoid関数を持つニューロンしか用意してません。。（完全な手抜きです。。）
なので最終層もsigmoidの出力0~1しか出力できないため、学習データセットも0~1の間で表現するように注意します。(入力側は0~1の範囲外でも大丈夫です。)

Xの値を0~1の範囲、0.01ステップで用意します。

```ruby
X = (0..1).step(0.01).to_a
```
$(0.75 * sin(x*2*\pi) + 0.15 * cos(5*\pi – 0.023) + 1) / 2$をY_IDEALとして、
それにランダムでノイズ(-0.05..0.005)をのせたものをYとします。

```ruby
Y_IDEAL = X.map {|x| (0.75 * Math.sin(x*2*Math::PI) - 0.2 * Math.cos(5*x*2*Math::PI - 0.023) + 1) / 2} 
Y = [Y_IDEAL, Array.new(X.size) {rand(-0.05..0.05)}].transpose.map {|e| e.inject(:+)}
```
私の環境で生成したX, Y, Y_IDEALをプロットしてみると以下のようになりました。
![example2_1.png](https://qiita-image-store.s3.amazonaws.com/0/40955/93682713-95b2-b03e-33dc-efdeca0c4bf8.png)

このXをinput、Yをoutputとしてネットワークに学習させます。
ネットワークは構成は`[1, 13, 6, 1]`にしてみました。

```ruby
a_network = RubyBrain::Network.new([1, 13, 6, 1])
a_network.init_network
a_network.learning_rate = 0.5
a_network.learn(X.map{|e| [e]}, Y.map{|e| [e]}, max_tra2ining_count=40000, tolerance=0.0004, monitoring_channels=[:best_params_training])
```
トレーニングした`a_networ`は下記のコードで確認できます。Y_PREDICATEDが`a_network`にXを入れた時のoutputになります。

```rb
Y_PREDICATED = X.map{|e| [e]}.map {|a| a_network.get_forward_outputs(a).first}
```
私の環境での結果をプロットすると下図のようになりました。
良い感じで模倣しています。
![fig(1).png](https://qiita-image-store.s3.amazonaws.com/0/40955/e14500f4-d0cb-0db9-f93f-be0d45920a30.png)

# Example 3 - MNIST
Exampleの最後としてMNISTを試してみます。28*28ピクセルの手書き数字画像を0~9にクラス分けする機械学習のHelloWorld的なチュートリアルです。
iRuby notebook版はこちら　＝＞　[examples/mnist - iRuby](http://nbviewer.jupyter.org/github/elgoog/ruby_brain/blob/master/examples/mnist.ipynb)

## MNISTデータの取得
付属の便利メソッドを使用するとMNISTのデータを簡単にRubyのArrayに入れることができます。
データは [THE MNIST DATABASE of handwritten digits](http://yann.lecun.com/exdb/mnist/) より、取得しています。
また、データの読み込みにはmrknさんのgem [mnist](https://rubygems.org/gems/mnist)を使用させていただきました。

```ruby
require &#39;ruby_brain&#39;

# MNISTのデータセットを取り扱う便利メソッドをロード
require &#39;ruby_brain/dataset/mnist/data&#39;
```
下記のように、`DataSet::Mnist::data`メソッドを実行するとMNISTのデータをArrayとして取得できます。
datasetはArrayで、training用データセットとtest用データセットを持っています。

```ruby
dataset = RubyBrain::DataSet::Mnist::data
training_dataset = dataset.first
test_dataset = dataset.last
```

各データセットは、以下のようになっています

```rb
# :input, :outputをkeyとするHashになっています。
training_dataset.keys # =&gt; [:input, :output]
test_dataset.keys     # =&gt; [:input, :output]

# トレーニングデータセットの :input は 60000(samples) x 784(28 * 28 input pixcels)
training_dataset[:input].size       # =&gt; 60000
training_dataset[:input].first.size # =&gt; 784

# トレーニングデータセットの :output は 60000(samples) x 10(0~9の10クラス)
training_dataset[:output].size       # =&gt; 60000
training_dataset[:output].first.size # =&gt; 10

# テストデータセットの:input は 10000(samples) x 784(28 * 28 input pixcels)
test_dataset[:input].size       # =&gt; 10000
test_dataset[:input].first.size # =&gt; 784

# テストデータセットの :output は 10000(samples) x 10(0~9の10クラス)
test_dataset[:output].size       # =&gt; 10000
test_dataset[:output].first.size # =&gt; 10
```
この例ではtraining_datasetの最初の5000サンプルのみ実際のトレーニングに使用します。RubyBrainが遅く、全70000枚の画像を使用すると学習に時間がかかりすぎるためです。

```rb
# 最初の5000枚のみトレーニングに使用
NUM_TRAIN_DATA = 5000
training_input = training_dataset[:input][0..(NUM_TRAIN_DATA-1)]
training_supervisor = training_dataset[:output][0..(NUM_TRAIN_DATA-1)]
# test_datasetはすべて使用
test_input = test_dataset[:input]
test_supervisor = test_dataset[:output]
```
## ネットワークの構築＆トレーニング実行
ここでは画像が784(28x28)ピクセルで10クラス(0..9)分類です。
隠れ層は１層で50個のニューロンを持つとして、`[784, 50, 10]`として構成しました。

```rb
# ネットワーク構成 [784, 50, 10]
network = RubyBrain::Network.new([training_input.first.size, 50, training_supervisor.first.size])
# learning rate is 0.7
network.learning_rate = 0.7
# initialize network
network.init_network
```
トレーニングの実行

```rb
network.learn(training_input, training_supervisor, max_training_count=100, tolerance=0.0004, monitoring_channels=[:best_params_training])
```

## 結果の確認

下記のコードで、トレーニングしたnetworkをtest_datasetを使って評価できます。
画像１枚分のデータ（input）をnetworkに入力した際の出力がpredicated_outputです。
このpredicated_outputはサイズ10のArrayで、そのindex 0~9がラベル0~9に対応します。
そして、最も大きい要素を持つindexがnetworkの予想したラベル（数字）となります。
下記のコードでは、手書き画像を簡易的にasciiで表示しています。
フルで走らすと10000枚分がstdoutに出力され、非常に時間がかかるので気をつけてください。
最後のaccuracyが認識率です。

```rb
test_input.each_with_index do |input, i|
  input.each_with_index do |e, j|
    print(e &gt; 0.3 ? &#39;x&#39; : &#39; &#39;)
    puts if (j % 28) == 0
  end
  puts
  supervisor_label = test_supervisor[i].index(test_supervisor[i].max)
  predicated_output = network.get_forward_outputs(input)
  predicated_label = predicated_output.index(predicated_output.max)
  puts &quot;test_supervisor: #{supervisor_label}&quot;
  puts &quot;predicate: #{predicated_label}&quot;
  results &lt;&lt; (supervisor_label == predicated_label)
  puts &quot;------------------------------------------------------------&quot;
end

puts &quot;accuracy: #{results.count(true).to_f/results.size}&quot;
```
実際にどんな画像で誤判定をしたかみてみると、なぜこれを間違うのかってのもいくつか見られましたが、多くが確かに間違える可能性ありそうな画像でした。以下、判定を間違ったケースの一部です。

![mnist_1_5_2.png](https://qiita-image-store.s3.amazonaws.com/0/40955/504cc547-7f43-aef3-661d-4c4b55f7262e.png)
test_supervisor[8] : 5
predicated_class : 2
　-------------------------------------------------------------------------------------

![mnist_2_4_6.png](https://qiita-image-store.s3.amazonaws.com/0/40955/ff89c2bb-9290-e69c-1871-8e526cd6c856.png)
test_supervisor[33] : 4
predicated_class : 6
　-------------------------------------------------------------------------------------

![mnist_3_6_2.png](https://qiita-image-store.s3.amazonaws.com/0/40955/73f9742a-4596-1724-cfdd-0a07537560d7.png)
test_supervisor[66] : 6
predicated_class : 2
　-------------------------------------------------------------------------------------

![mnist_4_9_7.png](https://qiita-image-store.s3.amazonaws.com/0/40955/a5e3a848-c818-c85e-a24d-fb04e01e2fab.png)
test_supervisor[73] : 9
predicated_class : 7
　-------------------------------------------------------------------------------------

![mnist_5_9_4.png](https://qiita-image-store.s3.amazonaws.com/0/40955/a1c0d197-1c7d-87f2-1e4d-e4f939bf79b7.png)
test_supervisor[92] : 9
predicated_class : 4
　-------------------------------------------------------------------------------------

![mnist_6_9_5.png](https://qiita-image-store.s3.amazonaws.com/0/40955/add03f61-f58f-8693-93e9-a25c9f012ed8.png)
test_supervisor[104] : 9
predicated_class : 5
　-------------------------------------------------------------------------------------

![mnist_7_2_9.png](https://qiita-image-store.s3.amazonaws.com/0/40955/5bc1b286-8203-22ff-b30d-b711053fe687.png)
test_supervisor[149] : 2
predicated_class : 9
　-------------------------------------------------------------------------------------

![mnist_8_9_5.png](https://qiita-image-store.s3.amazonaws.com/0/40955/c9c60812-f7ee-1d47-6592-dd41a9949eef.png)
test_supervisor[151] : 9
predicated_class : 5
　-------------------------------------------------------------------------------------

私の環境では上記の条件で、何回かためしてみて0.9312(93.12%)の認識率になりました。
出来上がった重みは [こちら](https://github.com/elgoog/weights_ruby_brain/blob/master/weights_782_50_10_1.yml)

# 最後に

本記事のタイトルにディープラーニングとついていますが、ReLUすら実装していないのでかなりつりっぽいタイトルになっていてすみませんm(_ _)m
MNISTの認識率が予想外に簡単に90%を超えることができました。やはりここから更に上げていくのが難しいんでしょうね。

### やりたかったけどやらなかったこと
- ランダムノイズをのせるときに、[SciRuby/distribution](https://github.com/SciRuby/distribution)を使って、ガウス分布でのせる
  =&gt; 今回、図の生成に初めてnyaplotを使ってみたところ非常に使いやすかったので、他のSciRubyプロジェクトにも興味がでてきました。見てみたところ面白いプロジェクトが結構あったので今後機会があれば使ってみたい。

### 疑問
この記事を書いてて、いくつか不明な点があったのでご存知の方がいましたら教えていただけると助かります。
この記事の趣旨とは関係ない内容ですが。。

- iruby notebookの各cellのoutputを表示させないようにする方法
  =&gt; バックエンドがipythonの場合、`%%capture`を使えるらしいですが、irubyの場合どうするのかわからなかったので、とりあえず`nil`を最後に付加して対処。
- nyaplotのheatmapのgridが長方形になってしまうのを正方形にする方法

</textarea><input type="submit" name="commit" value="Save changes" data-disable-with="Save changes" /></form></div></section></div><div class="col-sm-3"><div class="socialButtons"><div class="socialButtons_twitter"><a class="twitter-share-button" data-text="Rubyでディープラーニング on @Qiita" data-url="http://qiita.com/elgoog/items/8e7102a87889950d060d" href="https://twitter.com/share">Tweet</a></div><div class="socialButtons_hatebu"><a class="hatena-bookmark-button" data-hatena-bookmark-layout="simple-balloon" data-hatena-bookmark-title="Rubyでディープラーニング" href="http://b.hatena.ne.jp/entry/http://qiita.com/elgoog/items/8e7102a87889950d060d" title="Add to Hatena Bookmark"><img alt="Add to Hatena Bookmark" height="20" src="https://b.st-hatena.com/images/entry-button/button-only@2x.png" style="border: none;" width="20" /></a><script async="async" charset="utf-8" src="https://b.st-hatena.com/js/bookmark_button.js" type="text/javascript"></script></div><div class="socialButtons_googlePlus"><div class="g-plusone" data-href="http://qiita.com/elgoog/items/8e7102a87889950d060d" data-size="medium"></div></div><div class="socialButtons_facebook"><div class="fb-like" data-action="like" data-href="http://qiita.com/elgoog/items/8e7102a87889950d060d" data-layout="button_count" data-share="false" data-show-faces="false"></div></div><div class="socialButtons_pocket"><a class="pocket-btn" data-lang="en" data-pocket-count="horizontal" data-pocket-label="pocket"></a></div></div><section class="itemsShowAuthorInfo" itemprop="author" itemscope="" itemtype="http://schema.org/Person"><a href="/elgoog"><img alt="" class="itemsShowAuthorInfo_userIcon" itemprop="image" src="https://qiita-image-store.s3.amazonaws.com/0/40955/profile-images/1473688611" /></a><div class="itemsShowAuthorInfo_profileStats"><strong class="itemsShowAuthorInfo_userName" itemprop="name"><a itemprop="url" href="/elgoog">elgoog</a></strong><div class="itemsShowAuthorInfo_contribution"><span class="itemsShowAuthorInfo_count">464</span><span class="itemsShowAuthorInfo_unit">Contribution</span></div><div id="js-react-on-rails-context" data-rails-context="{}"></div>
<div class="js-react-on-rails-component" data-component-name="UserFollowButton" data-props="{&quot;initial_followed_by&quot;:false,&quot;position&quot;:&quot;author-info&quot;,&quot;size&quot;:&quot;btn-xs&quot;,&quot;url_name&quot;:&quot;elgoog&quot;}" data-trace="false" data-dom-id="UserFollowButton-react-component-23152d4f-1da0-4b58-9cae-a96d634bf1e9"></div>
    <div id="UserFollowButton-react-component-23152d4f-1da0-4b58-9cae-a96d634bf1e9"></div>
    
</div><section class="itemsShowAuthorPopularItems"><h5 class="itemsShowAuthorPopularItems_sectionTitle">Popular Posts</h5><ul class="itemsShowAuthorPopularItems_posts list-unstyled"><li itemscope="" itemtype="http://schema.org/Article"> <a itemprop="url" track="click" data-label="AuthorPopularItemsAtSidebar" href="/elgoog/items/8e7102a87889950d060d">Rubyでディープラーニング</a></li></ul></section></section><div class="scroll-chaser"><div class="google-adsense"><style>.test-text-responsible { width: 200px; height: 200px; }@media(min-width: 1200px) {  .test-text-responsible { width: 250px; height: 250px; }}@media(max-width: 979px) and (min-width: 768px) {  .test-text-responsible { width: 120px; height: 240px; }}@media(max-width: 767px) {  .test-text-responsible { width: 320px; height: 50px; }}</style><script async="" src="http://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script><ins class="adsbygoogle test-text-responsible" data-ad-client="ca-pub-8127218772604357" data-ad-slot="3880091879" style="display:inline-block"></ins><script>(adsbygoogle = window.adsbygoogle || []).push({});</script></div></div><div class="js-react-on-rails-component" data-component-name="Toc" data-props="{&quot;body&quot;:&quot;\u003cul\u003e\n\u003cli\u003e\n\u003ca href=\&quot;#%E8%83%8C%E6%99%AF\&quot;\u003e背景\u003c/a\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003ca href=\&quot;#rubybrain\&quot;\u003eRubyBrain\u003c/a\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\&quot;#%E4%BD%BF%E7%94%A8%E7%92%B0%E5%A2%83%E3%83%A9%E3%82%A4%E3%83%96%E3%83%A9%E3%83%AA\&quot;\u003e使用環境、ライブラリ\u003c/a\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003ca href=\&quot;#%E3%82%A4%E3%83%B3%E3%82%B9%E3%83%88%E3%83%BC%E3%83%AB\&quot;\u003eインストール\u003c/a\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\&quot;#iruby-notebook\&quot;\u003eiRuby notebook\u003c/a\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\&quot;#example-1---and%E3%83%8D%E3%83%83%E3%83%88%E3%83%AF%E3%83%BC%E3%82%AF\&quot;\u003eExample 1 - ANDネットワーク\u003c/a\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003ca href=\&quot;#%E3%83%87%E3%83%BC%E3%82%BF%E3%82%BB%E3%83%83%E3%83%88\&quot;\u003eデータセット\u003c/a\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\&quot;#%E3%83%8D%E3%83%83%E3%83%88%E3%83%AF%E3%83%BC%E3%82%AF%E3%81%AE%E6%A7%8B%E7%AF%89\&quot;\u003eネットワークの構築\u003c/a\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003ca href=\&quot;#%E3%83%88%E3%83%AC%E3%83%BC%E3%83%8B%E3%83%B3%E3%82%B0\&quot;\u003eトレーニング\u003c/a\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\&quot;#%E3%83%8D%E3%83%83%E3%83%88%E3%83%AF%E3%83%BC%E3%82%AF%E3%81%AE%E5%8B%95%E4%BD%9C%E7%A2%BA%E8%AA%8D\&quot;\u003eネットワークの動作確認\u003c/a\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\&quot;#%E3%83%8D%E3%83%83%E3%83%88%E3%83%AF%E3%83%BC%E3%82%AF%E3%81%AE%E9%87%8D%E3%81%BF%E3%81%AE%E4%BF%9D%E5%AD%98%E5%BE%A9%E5%85%83\&quot;\u003eネットワークの重みの保存＆復元\u003c/a\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\&quot;#example-2---%E6%B3%A2%E5%BD%A2%E3%81%AE%E8%BF%91%E4%BC%BC\&quot;\u003eExample 2 - 波形の近似\u003c/a\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\&quot;#example-3---mnist\&quot;\u003eExample 3 - MNIST\u003c/a\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003ca href=\&quot;#mnist%E3%83%87%E3%83%BC%E3%82%BF%E3%81%AE%E5%8F%96%E5%BE%97\&quot;\u003eMNISTデータの取得\u003c/a\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\&quot;#%E3%83%8D%E3%83%83%E3%83%88%E3%83%AF%E3%83%BC%E3%82%AF%E3%81%AE%E6%A7%8B%E7%AF%89%E3%83%88%E3%83%AC%E3%83%BC%E3%83%8B%E3%83%B3%E3%82%B0%E5%AE%9F%E8%A1%8C\&quot;\u003eネットワークの構築＆トレーニング実行\u003c/a\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\&quot;#%E7%B5%90%E6%9E%9C%E3%81%AE%E7%A2%BA%E8%AA%8D\&quot;\u003e結果の確認\u003c/a\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\&quot;#%E6%9C%80%E5%BE%8C%E3%81%AB\&quot;\u003e最後に\u003c/a\u003e\n\u003cul\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003ca href=\&quot;#%E3%82%84%E3%82%8A%E3%81%9F%E3%81%8B%E3%81%A3%E3%81%9F%E3%81%91%E3%81%A9%E3%82%84%E3%82%89%E3%81%AA%E3%81%8B%E3%81%A3%E3%81%9F%E3%81%93%E3%81%A8\&quot;\u003eやりたかったけどやらなかったこと\u003c/a\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\&quot;#%E7%96%91%E5%95%8F\&quot;\u003e疑問\u003c/a\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\n\n&quot;,&quot;wrapper&quot;:&quot;#article-body-wrapper&quot;}" data-trace="false" data-dom-id="Toc-react-component-42050727-4d55-45e6-a20e-6c0d0d580de0"></div>
    <div id="Toc-react-component-42050727-4d55-45e6-a20e-6c0d0d580de0"></div>
    
</div></div><div class="row"><div class="col-sm-9"><div class="ArticleFooter__menu"><div class="s-flex-align-center"><div class="js-likebutton" data-props="{&quot;like_status&quot;:false,&quot;like_count&quot;:464,&quot;show_count&quot;:true,&quot;uuid&quot;:&quot;8e7102a87889950d060d&quot;,&quot;likable_type&quot;:&quot;Article&quot;,&quot;position&quot;:&quot;article-footer&quot;}"></div><div class="ArticleFooter__userList"><div class="ArticleFooter__user"><div class="js-hovercard" data-hovercard-target-name="ytsukamoto"><a itemprop="url" href="/ytsukamoto"><img alt="ytsukamoto" class="thumb thumb--xs" src="https://2.gravatar.com/avatar/98bf066eac863d5b9a77ce43614b0cd2?d=https%3A%2F%2Fidenticons.github.com%2F95f86b01eb0a82a3d552499ba2a3b1de.png&amp;r=x" /></a></div></div><div class="ArticleFooter__user"><div class="js-hovercard" data-hovercard-target-name="snona"><a itemprop="url" href="/snona"><img alt="snona" class="thumb thumb--xs" src="https://qiita-image-store.s3.amazonaws.com/0/84376/profile-images/1473703078" /></a></div></div><div class="ArticleFooter__user"><div class="js-hovercard" data-hovercard-target-name="hakuaneko"><a itemprop="url" href="/hakuaneko"><img alt="hakuaneko" class="thumb thumb--xs" src="https://qiita-image-store.s3.amazonaws.com/0/31734/profile-images/1473685759" /></a></div></div><div class="ArticleFooter__user"><div class="js-hovercard" data-hovercard-target-name="hitomi_"><a itemprop="url" href="/hitomi_"><img alt="hitomi_" class="thumb thumb--xs" src="https://qiita-image-store.s3.amazonaws.com/0/6714/profile-images/1473683182" /></a></div></div><div class="ArticleFooter__user"><div class="js-hovercard" data-hovercard-target-name="takada-s"><a itemprop="url" href="/takada-s"><img alt="takada-s" class="thumb thumb--xs" src="https://qiita-image-store.s3.amazonaws.com/0/66222/profile-images/1473697138" /></a></div></div><div class="ArticleFooter__user"><div class="js-hovercard" data-hovercard-target-name="zuki_ebetsu"><a itemprop="url" href="/zuki_ebetsu"><img alt="zuki_ebetsu" class="thumb thumb--xs" src="https://qiita-image-store.s3.amazonaws.com/0/56485/profile-images/1473694012" /></a></div></div><div class="ArticleFooter__user"><div class="js-hovercard" data-hovercard-target-name="fumiyasac@github"><a itemprop="url" href="/fumiyasac@github"><img alt="fumiyasac@github" class="thumb thumb--xs" src="https://qiita-image-store.s3.amazonaws.com/0/17400/profile-images/1473682149" /></a></div></div><div class="ArticleFooter__user"><div class="js-hovercard" data-hovercard-target-name="uedatakumi"><a itemprop="url" href="/uedatakumi"><img alt="uedatakumi" class="thumb thumb--xs" src="https://qiita-image-store.s3.amazonaws.com/0/79169/profile-images/1473701352" /></a></div></div><div class="ArticleFooter__user"><div class="js-hovercard" data-hovercard-target-name="kazto"><a itemprop="url" href="/kazto"><img alt="kazto" class="thumb thumb--xs" src="https://qiita-image-store.s3.amazonaws.com/0/31413/profile-images/1473685689" /></a></div></div><div class="ArticleFooter__user"><div class="js-hovercard" data-hovercard-target-name="naari"><a itemprop="url" href="/naari"><img alt="naari" class="thumb thumb--xs" src="https://qiita-image-store.s3.amazonaws.com/0/92994/profile-images/1473705809" /></a></div></div><div class="ArticleFooter__user"><a href="/elgoog/items/8e7102a87889950d060d/likers"><span class="fa fa-ellipsis-h"></span></a></div></div></div><div class="u-flex u-align-center"><div class="ArticleFooter__stock"><div class="js-stockbutton" data-position="footer_menu" data-props="{&quot;stock_status&quot;:false}"></div></div><div class="ArticleFooter__editRequest"><a class="u-link-no-underline" data-toggle="tooltip" title="You can propose improvements about the article to the author 💪" href="/drafts/8e7102a87889950d060d/edit"><span class="fa fa-send-o fa-lg"></span> <span>Edit request</span></a></div><div class="dropdown ArticleFooter__dropdown"><a class="dropdown-toggle" data-toggle="dropdown" href="#"><span class="fa fa-ellipsis-h"></span></a><ul class="dropdown-menu dropdown-menu-right"><li><a href="/elgoog/items/8e7102a87889950d060d.md"><span class="fa fa-fw fa-file-text-o"></span> Show article as Markdown</a></li><li><a data-target=".js-report-form" data-toggle="modal" href="#"><i class="fa fa-fw fa-flag"></i> Report article</a></li></ul></div></div></div><ul class="references js-referencesView"><li class="references_header"><i class="fa fa-fw fa-link"></i> Linked from these articles</li><li class="references_reference js-reference"><span>Linked from </span><a href="/seinosuke/items/c16198c218bfc64a134a#_reference-20f0c4359f700f345d42"><img alt="" width="18" height="18" src="https://qiita-image-store.s3.amazonaws.com/0/54587/profile-images/1473693422" />人はRubyだけで手書き数字認識できるか?</a><time class="references_datetime js-dateTimeView" datetime="2016-10-13T09:58:29+00:00">5 months ago</time></li></ul><div class="itemsShowBody_articleColumnFooter"><div class="socialButtons"><div class="socialButtons_twitter"><a class="twitter-share-button" data-text="Rubyでディープラーニング on @Qiita" data-url="http://qiita.com/elgoog/items/8e7102a87889950d060d" href="https://twitter.com/share">Tweet</a></div><div class="socialButtons_hatebu"><a class="hatena-bookmark-button" data-hatena-bookmark-layout="simple-balloon" data-hatena-bookmark-title="Rubyでディープラーニング" href="http://b.hatena.ne.jp/entry/http://qiita.com/elgoog/items/8e7102a87889950d060d" title="Add to Hatena Bookmark"><img alt="Add to Hatena Bookmark" height="20" src="https://b.st-hatena.com/images/entry-button/button-only@2x.png" style="border: none;" width="20" /></a><script async="async" charset="utf-8" src="https://b.st-hatena.com/js/bookmark_button.js" type="text/javascript"></script></div><div class="socialButtons_googlePlus"><div class="g-plusone" data-href="http://qiita.com/elgoog/items/8e7102a87889950d060d" data-size="medium"></div></div><div class="socialButtons_facebook"><div class="fb-like" data-action="like" data-href="http://qiita.com/elgoog/items/8e7102a87889950d060d" data-layout="button_count" data-share="false" data-show-faces="false"></div></div><div class="socialButtons_pocket"><a class="pocket-btn" data-lang="en" data-pocket-count="horizontal" data-pocket-label="pocket"></a></div></div></div><div class="itemsShowComment_wrapper" id="comments"><div class="js-react-on-rails-component" data-component-name="CommentListContainer" data-props="{&quot;currentUser&quot;:null,&quot;initialComments&quot;:[{&quot;banned&quot;:false,&quot;body&quot;:&quot;\u003cblockquote\u003e\n\u003cp\u003eiruby notebookの各cellのoutputを表示させないようにする方法\u003c/p\u003e\n\u003c/blockquote\u003e\n\n\u003cp\u003eJuputer (IPython) の各outputは、そのセルの最後に実行した式（文）の結果を表示しますが、例えばPythonの場合、代入文は値を返さない（基本的に文は式ではない）ので、最後が代入で終わっていればoutputが表示されません。一方Rubyは全てが式（代入もその値を返す式）なので、基本的にはoutputに最後の値が表示されてしまいます（最後に評価した結果が\u003ccode\u003enil\u003c/code\u003eの場合を除く）。\u003c/p\u003e\n\n\u003cp\u003eIRuby 最近触ってないのですが、そこに \u003ccode\u003e%%capture\u003c/code\u003e に替わる機能が用意されていない限り、最後に \u003ccode\u003enil\u003c/code\u003e を書くくらいしか私も思いつきません（私もよくやりました）。\u003c/p\u003e\n&quot;,&quot;created_at&quot;:&quot;2016-08-03T08:58:16+09:00&quot;,&quot;expanded_references&quot;:&quot;&quot;,&quot;id&quot;:605521,&quot;is_team&quot;:false,&quot;item_id&quot;:412598,&quot;item_type&quot;:&quot;PublicDomainArticle&quot;,&quot;item_uuid&quot;:&quot;8e7102a87889950d060d&quot;,&quot;likable&quot;:false,&quot;liked&quot;:false,&quot;public_likes_count&quot;:1,&quot;raw_body&quot;:&quot;\u003e iruby notebookの各cellのoutputを表示させないようにする方法\n\nJuputer (IPython) の各outputは、そのセルの最後に実行した式（文）の結果を表示しますが、例えばPythonの場合、代入文は値を返さない（基本的に文は式ではない）ので、最後が代入で終わっていればoutputが表示されません。一方Rubyは全てが式（代入もその値を返す式）なので、基本的にはoutputに最後の値が表示されてしまいます（最後に評価した結果が`nil`の場合を除く）。\n\nIRuby 最近触ってないのですが、そこに `%%capture` に替わる機能が用意されていない限り、最後に `nil` を書くくらいしか私も思いつきません（私もよくやりました）。\n&quot;,&quot;reaction_types&quot;:[{&quot;image_url&quot;:&quot;https://cdn.qiita.com/emoji/twemoji/unicode/1f44d.png&quot;,&quot;name&quot;:&quot;+1&quot;},{&quot;image_url&quot;:&quot;https://cdn.qiita.com/emoji/twemoji/unicode/1f64f.png&quot;,&quot;name&quot;:&quot;pray&quot;},{&quot;image_url&quot;:&quot;https://cdn.qiita.com/emoji/twemoji/unicode/1f389.png&quot;,&quot;name&quot;:&quot;tada&quot;},{&quot;image_url&quot;:&quot;https://cdn.qiita.com/emoji/twemoji/unicode/1f647.png&quot;,&quot;name&quot;:&quot;bow&quot;},{&quot;image_url&quot;:&quot;https://cdn.qiita.com/emoji/twemoji/unicode/1f631.png&quot;,&quot;name&quot;:&quot;scream&quot;},{&quot;image_url&quot;:&quot;https://cdn.qiita.com/emoji/twemoji/unicode/1f440.png&quot;,&quot;name&quot;:&quot;eyes&quot;}],&quot;reactions&quot;:[],&quot;team&quot;:null,&quot;team_membership&quot;:null,&quot;updatable&quot;:false,&quot;url&quot;:&quot;http://qiita.com/elgoog/items/8e7102a87889950d060d#comment-fa9f3df573ab4da7b3d8&quot;,&quot;user&quot;:{&quot;contribution&quot;:411,&quot;created_at&quot;:&quot;2013-10-07T12:16:05+09:00&quot;,&quot;id&quot;:30400,&quot;is_admin&quot;:false,&quot;profile_image_url&quot;:&quot;https://qiita-image-store.s3.amazonaws.com/0/30400/profile-images/1473685489&quot;,&quot;suspended&quot;:false,&quot;url_name&quot;:&quot;antimon2&quot;},&quot;uuid&quot;:&quot;fa9f3df573ab4da7b3d8&quot;,&quot;via_email&quot;:false},{&quot;banned&quot;:false,&quot;body&quot;:&quot;\u003cp\u003e\u003ca href=\&quot;/antimon2\&quot; class=\&quot;user-mention js-hovercard\&quot; title=\&quot;antimon2\&quot; data-hovercard-target-type=\&quot;user\&quot; data-hovercard-target-name=\&quot;antimon2\&quot;\u003e@antimon2\u003c/a\u003e 詳細な情報ありがとうございます。やはり、今のところ\u003ccode\u003enil\u003c/code\u003eを追加しておくしかなさそうですね。解決策が見つかったら修正していきたいと思います。\u003c/p\u003e\n&quot;,&quot;created_at&quot;:&quot;2016-08-03T20:52:54+09:00&quot;,&quot;expanded_references&quot;:&quot;&quot;,&quot;id&quot;:606370,&quot;is_team&quot;:false,&quot;item_id&quot;:412598,&quot;item_type&quot;:&quot;PublicDomainArticle&quot;,&quot;item_uuid&quot;:&quot;8e7102a87889950d060d&quot;,&quot;likable&quot;:false,&quot;liked&quot;:false,&quot;public_likes_count&quot;:0,&quot;raw_body&quot;:&quot;@antimon2 詳細な情報ありがとうございます。やはり、今のところ`nil`を追加しておくしかなさそうですね。解決策が見つかったら修正していきたいと思います。\n&quot;,&quot;reaction_types&quot;:[{&quot;image_url&quot;:&quot;https://cdn.qiita.com/emoji/twemoji/unicode/1f44d.png&quot;,&quot;name&quot;:&quot;+1&quot;},{&quot;image_url&quot;:&quot;https://cdn.qiita.com/emoji/twemoji/unicode/1f64f.png&quot;,&quot;name&quot;:&quot;pray&quot;},{&quot;image_url&quot;:&quot;https://cdn.qiita.com/emoji/twemoji/unicode/1f389.png&quot;,&quot;name&quot;:&quot;tada&quot;},{&quot;image_url&quot;:&quot;https://cdn.qiita.com/emoji/twemoji/unicode/1f647.png&quot;,&quot;name&quot;:&quot;bow&quot;},{&quot;image_url&quot;:&quot;https://cdn.qiita.com/emoji/twemoji/unicode/1f631.png&quot;,&quot;name&quot;:&quot;scream&quot;},{&quot;image_url&quot;:&quot;https://cdn.qiita.com/emoji/twemoji/unicode/1f440.png&quot;,&quot;name&quot;:&quot;eyes&quot;}],&quot;reactions&quot;:[],&quot;team&quot;:null,&quot;team_membership&quot;:null,&quot;updatable&quot;:false,&quot;url&quot;:&quot;http://qiita.com/elgoog/items/8e7102a87889950d060d#comment-63429540d83622666d33&quot;,&quot;user&quot;:{&quot;contribution&quot;:464,&quot;created_at&quot;:&quot;2014-04-02T22:45:53+09:00&quot;,&quot;id&quot;:40955,&quot;is_admin&quot;:false,&quot;profile_image_url&quot;:&quot;https://qiita-image-store.s3.amazonaws.com/0/40955/profile-images/1473688611&quot;,&quot;suspended&quot;:false,&quot;url_name&quot;:&quot;elgoog&quot;},&quot;uuid&quot;:&quot;63429540d83622666d33&quot;,&quot;via_email&quot;:false},{&quot;banned&quot;:false,&quot;body&quot;:&quot;\u003cblockquote\u003e\n\u003cp\u003e悪い点は、とにかく遅い。\u003c/p\u003e\n\u003c/blockquote\u003e\n\n\u003cp\u003eたぶん，高速化の余地が十分にあると思います。\u003c/p\u003e\n\n\u003cp\u003eどのメソッドで時間を食っているかは，たとえば標準添付ライブラリーの \u003ca href=\&quot;http://docs.ruby-lang.org/ja/2.3.0/library/profiler.html\&quot; rel=\&quot;nofollow noopener\&quot; target=\&quot;_blank\&quot;\u003eprofiler\u003c/a\u003e を使って調べることができます。\u003c/p\u003e\n\n\u003cp\u003e使い方は簡単で，\u003c/p\u003e\n\n\u003cdiv class=\&quot;code-frame\&quot; data-lang=\&quot;rb\&quot;\u003e\u003cdiv class=\&quot;highlight\&quot;\u003e\u003cpre\u003e\n\u003cspan class=\&quot;nb\&quot;\u003erequire\u003c/span\u003e \u003cspan class=\&quot;s1\&quot;\u003e&#39;profiler&#39;\u003c/span\u003e\n\u003c/pre\u003e\u003c/div\u003e\u003c/div\u003e\n\n\u003cp\u003eとしておいて，計測したい箇所を\u003c/p\u003e\n\n\u003cdiv class=\&quot;code-frame\&quot; data-lang=\&quot;rb\&quot;\u003e\u003cdiv class=\&quot;highlight\&quot;\u003e\u003cpre\u003e\n\u003cspan class=\&quot;no\&quot;\u003eProfiler__\u003c/span\u003e\u003cspan class=\&quot;o\&quot;\u003e.\u003c/span\u003e\u003cspan class=\&quot;n\&quot;\u003estart_profile\u003c/span\u003e\n\u003c/pre\u003e\u003c/div\u003e\u003c/div\u003e\n\n\u003cp\u003eと\u003c/p\u003e\n\n\u003cdiv class=\&quot;code-frame\&quot; data-lang=\&quot;rb\&quot;\u003e\u003cdiv class=\&quot;highlight\&quot;\u003e\u003cpre\u003e\n\u003cspan class=\&quot;no\&quot;\u003eProfiler__\u003c/span\u003e\u003cspan class=\&quot;o\&quot;\u003e.\u003c/span\u003e\u003cspan class=\&quot;n\&quot;\u003eprint_profile\u003c/span\u003e\u003cspan class=\&quot;p\&quot;\u003e(\u003c/span\u003e\u003cspan class=\&quot;no\&quot;\u003eSTDOUT\u003c/span\u003e\u003cspan class=\&quot;p\&quot;\u003e)\u003c/span\u003e\n\u003c/pre\u003e\u003c/div\u003e\u003c/div\u003e\n\n\u003cp\u003eで挟むだけです。（挟んだところの実行は非常に遅くなります）\u003c/p\u003e\n\n\u003cp\u003e表示されるリストは「self seconds」の値の大きいもの順なので，上から順に高速化できないか検討します。\u003cbr\u003e\nその際，呼び出し回数（call）と1回当たりの時間（self ms/call）が出るので，それぞれ減らせないかを考えます。\u003c/p\u003e\n\n\u003cp\u003e例えば \u003ccode\u003eNeuron#output_of_forward_calc\u003c/code\u003e が\u003c/p\u003e\n\n\u003cdiv class=\&quot;code-frame\&quot; data-lang=\&quot;rb\&quot;\u003e\u003cdiv class=\&quot;highlight\&quot;\u003e\u003cpre\u003e\n\u003cspan class=\&quot;k\&quot;\u003edef\u003c/span\u003e \u003cspan class=\&quot;nf\&quot;\u003eoutput_of_forward_calc\u003c/span\u003e\u003cspan class=\&quot;p\&quot;\u003e(\u003c/span\u003e\u003cspan class=\&quot;n\&quot;\u003einputs\u003c/span\u003e\u003cspan class=\&quot;p\&quot;\u003e)\u003c/span\u003e\n  \u003cspan class=\&quot;n\&quot;\u003esigmoid_input\u003c/span\u003e \u003cspan class=\&quot;o\&quot;\u003e=\u003c/span\u003e \u003cspan class=\&quot;mi\&quot;\u003e0\u003c/span\u003e\u003cspan class=\&quot;o\&quot;\u003e.\u003c/span\u003e\u003cspan class=\&quot;mi\&quot;\u003e0\u003c/span\u003e\n  \u003cspan class=\&quot;vi\&quot;\u003e@left_side_weights\u003c/span\u003e\u003cspan class=\&quot;o\&quot;\u003e.\u003c/span\u003e\u003cspan class=\&quot;n\&quot;\u003etranspose\u003c/span\u003e\u003cspan class=\&quot;o\&quot;\u003e[\u003c/span\u003e\u003cspan class=\&quot;vi\&quot;\u003e@order_index\u003c/span\u003e\u003cspan class=\&quot;o\&quot;\u003e].\u003c/span\u003e\u003cspan class=\&quot;n\&quot;\u003ezip\u003c/span\u003e\u003cspan class=\&quot;p\&quot;\u003e(\u003c/span\u003e\u003cspan class=\&quot;n\&quot;\u003einputs\u003c/span\u003e\u003cspan class=\&quot;p\&quot;\u003e)\u003c/span\u003e\u003cspan class=\&quot;o\&quot;\u003e.\u003c/span\u003e\u003cspan class=\&quot;n\&quot;\u003eeach\u003c/span\u003e \u003cspan class=\&quot;k\&quot;\u003edo\u003c/span\u003e \u003cspan class=\&quot;o\&quot;\u003e|\u003c/span\u003e\u003cspan class=\&quot;n\&quot;\u003eweight\u003c/span\u003e\u003cspan class=\&quot;p\&quot;\u003e,\u003c/span\u003e \u003cspan class=\&quot;n\&quot;\u003einput\u003c/span\u003e\u003cspan class=\&quot;o\&quot;\u003e|\u003c/span\u003e\n    \u003cspan class=\&quot;n\&quot;\u003esigmoid_input\u003c/span\u003e \u003cspan class=\&quot;o\&quot;\u003e+=\u003c/span\u003e \u003cspan class=\&quot;n\&quot;\u003einput\u003c/span\u003e \u003cspan class=\&quot;o\&quot;\u003e*\u003c/span\u003e \u003cspan class=\&quot;n\&quot;\u003eweight\u003c/span\u003e\n \u003cspan class=\&quot;k\&quot;\u003eend\u003c/span\u003e\n  \u003cspan class=\&quot;vi\&quot;\u003e@this_output\u003c/span\u003e \u003cspan class=\&quot;o\&quot;\u003e=\u003c/span\u003e \u003cspan class=\&quot;n\&quot;\u003eget_sigmoid_output\u003c/span\u003e\u003cspan class=\&quot;p\&quot;\u003e(\u003c/span\u003e\u003cspan class=\&quot;n\&quot;\u003esigmoid_input\u003c/span\u003e\u003cspan class=\&quot;p\&quot;\u003e)\u003c/span\u003e\n\u003cspan class=\&quot;k\&quot;\u003eend\u003c/span\u003e\n\u003c/pre\u003e\u003c/div\u003e\u003c/div\u003e\n\n\u003cp\u003eとあるのですが，たぶん大きな行列を \u003ccode\u003etranspose\u003c/code\u003e したり，\u003ccode\u003ezip\u003c/code\u003e したりするコストが馬鹿にならないのではないかと思います。（計測せずに当てずっぽうで書いてます，すいません）\u003c/p\u003e\n\n\u003cp\u003eこのループのところは，おそらく\u003c/p\u003e\n\n\u003cdiv class=\&quot;code-frame\&quot; data-lang=\&quot;rb\&quot;\u003e\u003cdiv class=\&quot;highlight\&quot;\u003e\u003cpre\u003e\n\u003cspan class=\&quot;n\&quot;\u003einputs\u003c/span\u003e\u003cspan class=\&quot;o\&quot;\u003e.\u003c/span\u003e\u003cspan class=\&quot;n\&quot;\u003etimes\u003c/span\u003e \u003cspan class=\&quot;k\&quot;\u003edo\u003c/span\u003e \u003cspan class=\&quot;o\&quot;\u003e|\u003c/span\u003e\u003cspan class=\&quot;n\&quot;\u003ei\u003c/span\u003e\u003cspan class=\&quot;o\&quot;\u003e|\u003c/span\u003e\n  \u003cspan class=\&quot;n\&quot;\u003esigmoid_input\u003c/span\u003e \u003cspan class=\&quot;o\&quot;\u003e+=\u003c/span\u003e \u003cspan class=\&quot;vi\&quot;\u003e@left_side_weights\u003c/span\u003e\u003cspan class=\&quot;o\&quot;\u003e[\u003c/span\u003e\u003cspan class=\&quot;n\&quot;\u003ei\u003c/span\u003e\u003cspan class=\&quot;o\&quot;\u003e][\u003c/span\u003e\u003cspan class=\&quot;vi\&quot;\u003e@order_index\u003c/span\u003e\u003cspan class=\&quot;o\&quot;\u003e]\u003c/span\u003e \u003cspan class=\&quot;o\&quot;\u003e*\u003c/span\u003e \u003cspan class=\&quot;n\&quot;\u003einputs\u003c/span\u003e\u003cspan class=\&quot;o\&quot;\u003e[\u003c/span\u003e\u003cspan class=\&quot;n\&quot;\u003ei\u003c/span\u003e\u003cspan class=\&quot;o\&quot;\u003e]\u003c/span\u003e\n\u003cspan class=\&quot;k\&quot;\u003eend\u003c/span\u003e\n\u003c/pre\u003e\u003c/div\u003e\u003c/div\u003e\n\n\u003cp\u003eとかのほうが速いのではないかと思います。\u003cbr\u003e\n（コードを実行してみていないので，本当に速くなるか，そもそもこのコードで正しいのかどうかも分かりません；いい加減な話ですみません）\u003c/p\u003e\n&quot;,&quot;created_at&quot;:&quot;2016-08-04T01:32:46+09:00&quot;,&quot;expanded_references&quot;:&quot;&quot;,&quot;id&quot;:606554,&quot;is_team&quot;:false,&quot;item_id&quot;:412598,&quot;item_type&quot;:&quot;PublicDomainArticle&quot;,&quot;item_uuid&quot;:&quot;8e7102a87889950d060d&quot;,&quot;likable&quot;:false,&quot;liked&quot;:false,&quot;public_likes_count&quot;:2,&quot;raw_body&quot;:&quot;\u003e 悪い点は、とにかく遅い。\n\nたぶん，高速化の余地が十分にあると思います。\n\nどのメソッドで時間を食っているかは，たとえば標準添付ライブラリーの [profiler](http://docs.ruby-lang.org/ja/2.3.0/library/profiler.html) を使って調べることができます。\n\n使い方は簡単で，\n\n```rb\nrequire &#39;profiler&#39;\n```\n\nとしておいて，計測したい箇所を\n\n```rb\nProfiler__.start_profile\n```\n\nと\n\n```rb\nProfiler__.print_profile(STDOUT)\n```\n\nで挟むだけです。（挟んだところの実行は非常に遅くなります）\n\n表示されるリストは「self seconds」の値の大きいもの順なので，上から順に高速化できないか検討します。\nその際，呼び出し回数（call）と1回当たりの時間（self ms/call）が出るので，それぞれ減らせないかを考えます。\n\n例えば `Neuron#output_of_forward_calc` が\n\n```rb\ndef output_of_forward_calc(inputs)\n  sigmoid_input = 0.0\n  @left_side_weights.transpose[@order_index].zip(inputs).each do |weight, input|\n    sigmoid_input += input * weight\n end\n  @this_output = get_sigmoid_output(sigmoid_input)\nend\n```\n\nとあるのですが，たぶん大きな行列を `transpose` したり，`zip` したりするコストが馬鹿にならないのではないかと思います。（計測せずに当てずっぽうで書いてます，すいません）\n\nこのループのところは，おそらく\n\n```rb\ninputs.times do |i|\n  sigmoid_input += @left_side_weights[i][@order_index] * inputs[i]\nend\n```\n\nとかのほうが速いのではないかと思います。\n（コードを実行してみていないので，本当に速くなるか，そもそもこのコードで正しいのかどうかも分かりません；いい加減な話ですみません）\n&quot;,&quot;reaction_types&quot;:[{&quot;image_url&quot;:&quot;https://cdn.qiita.com/emoji/twemoji/unicode/1f44d.png&quot;,&quot;name&quot;:&quot;+1&quot;},{&quot;image_url&quot;:&quot;https://cdn.qiita.com/emoji/twemoji/unicode/1f64f.png&quot;,&quot;name&quot;:&quot;pray&quot;},{&quot;image_url&quot;:&quot;https://cdn.qiita.com/emoji/twemoji/unicode/1f389.png&quot;,&quot;name&quot;:&quot;tada&quot;},{&quot;image_url&quot;:&quot;https://cdn.qiita.com/emoji/twemoji/unicode/1f647.png&quot;,&quot;name&quot;:&quot;bow&quot;},{&quot;image_url&quot;:&quot;https://cdn.qiita.com/emoji/twemoji/unicode/1f631.png&quot;,&quot;name&quot;:&quot;scream&quot;},{&quot;image_url&quot;:&quot;https://cdn.qiita.com/emoji/twemoji/unicode/1f440.png&quot;,&quot;name&quot;:&quot;eyes&quot;}],&quot;reactions&quot;:[],&quot;team&quot;:null,&quot;team_membership&quot;:null,&quot;updatable&quot;:false,&quot;url&quot;:&quot;http://qiita.com/elgoog/items/8e7102a87889950d060d#comment-929e9459b24ae265e29b&quot;,&quot;user&quot;:{&quot;contribution&quot;:2193,&quot;created_at&quot;:&quot;2014-07-05T01:04:15+09:00&quot;,&quot;id&quot;:48101,&quot;is_admin&quot;:false,&quot;profile_image_url&quot;:&quot;https://qiita-image-store.s3.amazonaws.com/0/48101/profile-images/1473691230&quot;,&quot;suspended&quot;:false,&quot;url_name&quot;:&quot;scivola&quot;},&quot;uuid&quot;:&quot;929e9459b24ae265e29b&quot;,&quot;via_email&quot;:false},{&quot;banned&quot;:false,&quot;body&quot;:&quot;\u003cp\u003e\u003ca href=\&quot;/scivola\&quot; class=\&quot;user-mention js-hovercard\&quot; title=\&quot;scivola\&quot; data-hovercard-target-type=\&quot;user\&quot; data-hovercard-target-name=\&quot;scivola\&quot;\u003e@scivola\u003c/a\u003e ありがとうございます。コードを引用しての例示でわかりやすく助かります。\u003cbr\u003e\nご指摘の通り、今回のgemはニューロン指向での実装の中でもかなり遅いほうで高速化の余地が十分あると思います。\u003cbr\u003e\n高速化を追求するとSciRubyのNMatrixに全部押しこんで計算することになってきそうです。しかし、それだともはやニューロン指向での実装ではなくなってしまうので、ご指摘の通りprofilerで適度なところまで最適化するのが良さそうですね。\u003cbr\u003e\nprofilerは今まで実際に使ったことがないので、これを機会に試してみます。\u003c/p\u003e\n&quot;,&quot;created_at&quot;:&quot;2016-08-04T07:54:32+09:00&quot;,&quot;expanded_references&quot;:&quot;&quot;,&quot;id&quot;:606613,&quot;is_team&quot;:false,&quot;item_id&quot;:412598,&quot;item_type&quot;:&quot;PublicDomainArticle&quot;,&quot;item_uuid&quot;:&quot;8e7102a87889950d060d&quot;,&quot;likable&quot;:false,&quot;liked&quot;:false,&quot;public_likes_count&quot;:0,&quot;raw_body&quot;:&quot;@scivola ありがとうございます。コードを引用しての例示でわかりやすく助かります。\nご指摘の通り、今回のgemはニューロン指向での実装の中でもかなり遅いほうで高速化の余地が十分あると思います。\n高速化を追求するとSciRubyのNMatrixに全部押しこんで計算することになってきそうです。しかし、それだともはやニューロン指向での実装ではなくなってしまうので、ご指摘の通りprofilerで適度なところまで最適化するのが良さそうですね。\nprofilerは今まで実際に使ったことがないので、これを機会に試してみます。\n&quot;,&quot;reaction_types&quot;:[{&quot;image_url&quot;:&quot;https://cdn.qiita.com/emoji/twemoji/unicode/1f44d.png&quot;,&quot;name&quot;:&quot;+1&quot;},{&quot;image_url&quot;:&quot;https://cdn.qiita.com/emoji/twemoji/unicode/1f64f.png&quot;,&quot;name&quot;:&quot;pray&quot;},{&quot;image_url&quot;:&quot;https://cdn.qiita.com/emoji/twemoji/unicode/1f389.png&quot;,&quot;name&quot;:&quot;tada&quot;},{&quot;image_url&quot;:&quot;https://cdn.qiita.com/emoji/twemoji/unicode/1f647.png&quot;,&quot;name&quot;:&quot;bow&quot;},{&quot;image_url&quot;:&quot;https://cdn.qiita.com/emoji/twemoji/unicode/1f631.png&quot;,&quot;name&quot;:&quot;scream&quot;},{&quot;image_url&quot;:&quot;https://cdn.qiita.com/emoji/twemoji/unicode/1f440.png&quot;,&quot;name&quot;:&quot;eyes&quot;}],&quot;reactions&quot;:[],&quot;team&quot;:null,&quot;team_membership&quot;:null,&quot;updatable&quot;:false,&quot;url&quot;:&quot;http://qiita.com/elgoog/items/8e7102a87889950d060d#comment-1edb2d1274ea5827380a&quot;,&quot;user&quot;:{&quot;contribution&quot;:464,&quot;created_at&quot;:&quot;2014-04-02T22:45:53+09:00&quot;,&quot;id&quot;:40955,&quot;is_admin&quot;:false,&quot;profile_image_url&quot;:&quot;https://qiita-image-store.s3.amazonaws.com/0/40955/profile-images/1473688611&quot;,&quot;suspended&quot;:false,&quot;url_name&quot;:&quot;elgoog&quot;},&quot;uuid&quot;:&quot;1edb2d1274ea5827380a&quot;,&quot;via_email&quot;:false},{&quot;banned&quot;:false,&quot;body&quot;:&quot;\u003cp\u003e非常に参考になりました。\u003cbr\u003e\nRubyで簡単にディープラーニングを体験できてとても楽しかったです。\u003c/p\u003e\n\n\u003cp\u003e追伸\u003c/p\u003e\n\n\u003cp\u003eargmaxの定義だけ本論から離れているように見えるので、下記のように Pure Ruby で簡素に表現しても良いかなと思いました^^。\u003cbr\u003e\n\u003ccode\u003esupervisor_label = test_supervisor[i].index(test_supervisor[i].max)\u003c/code\u003e\u003c/p\u003e\n\n\u003cp\u003e今後とも楽しい記事を期待しています。\u003c/p\u003e\n&quot;,&quot;created_at&quot;:&quot;2016-08-18T18:51:34+09:00&quot;,&quot;expanded_references&quot;:&quot;&quot;,&quot;id&quot;:615854,&quot;is_team&quot;:false,&quot;item_id&quot;:412598,&quot;item_type&quot;:&quot;PublicDomainArticle&quot;,&quot;item_uuid&quot;:&quot;8e7102a87889950d060d&quot;,&quot;likable&quot;:false,&quot;liked&quot;:false,&quot;public_likes_count&quot;:1,&quot;raw_body&quot;:&quot;非常に参考になりました。\nRubyで簡単にディープラーニングを体験できてとても楽しかったです。\n\n追伸\n\nargmaxの定義だけ本論から離れているように見えるので、下記のように Pure Ruby で簡素に表現しても良いかなと思いました^^。\n```supervisor_label = test_supervisor[i].index(test_supervisor[i].max)```\n\n今後とも楽しい記事を期待しています。\n&quot;,&quot;reaction_types&quot;:[{&quot;image_url&quot;:&quot;https://cdn.qiita.com/emoji/twemoji/unicode/1f44d.png&quot;,&quot;name&quot;:&quot;+1&quot;},{&quot;image_url&quot;:&quot;https://cdn.qiita.com/emoji/twemoji/unicode/1f64f.png&quot;,&quot;name&quot;:&quot;pray&quot;},{&quot;image_url&quot;:&quot;https://cdn.qiita.com/emoji/twemoji/unicode/1f389.png&quot;,&quot;name&quot;:&quot;tada&quot;},{&quot;image_url&quot;:&quot;https://cdn.qiita.com/emoji/twemoji/unicode/1f647.png&quot;,&quot;name&quot;:&quot;bow&quot;},{&quot;image_url&quot;:&quot;https://cdn.qiita.com/emoji/twemoji/unicode/1f631.png&quot;,&quot;name&quot;:&quot;scream&quot;},{&quot;image_url&quot;:&quot;https://cdn.qiita.com/emoji/twemoji/unicode/1f440.png&quot;,&quot;name&quot;:&quot;eyes&quot;}],&quot;reactions&quot;:[],&quot;team&quot;:null,&quot;team_membership&quot;:null,&quot;updatable&quot;:false,&quot;url&quot;:&quot;http://qiita.com/elgoog/items/8e7102a87889950d060d#comment-11209bd27336a0b6d740&quot;,&quot;user&quot;:{&quot;contribution&quot;:28,&quot;created_at&quot;:&quot;2015-10-10T15:03:30+09:00&quot;,&quot;id&quot;:96254,&quot;is_admin&quot;:false,&quot;profile_image_url&quot;:&quot;https://qiita-image-store.s3.amazonaws.com/0/96254/profile-images/1473706828&quot;,&quot;suspended&quot;:false,&quot;url_name&quot;:&quot;yamamuteki&quot;},&quot;uuid&quot;:&quot;11209bd27336a0b6d740&quot;,&quot;via_email&quot;:false},{&quot;banned&quot;:false,&quot;body&quot;:&quot;\u003cp\u003e\u003ca href=\&quot;/yamamuteki\&quot; class=\&quot;user-mention js-hovercard\&quot; title=\&quot;yamamuteki\&quot; data-hovercard-target-type=\&quot;user\&quot; data-hovercard-target-name=\&quot;yamamuteki\&quot;\u003e@yamamuteki\u003c/a\u003e ありがとうございます、そう言っていただけると嬉しいです。\u003c/p\u003e\n\n\u003cp\u003eargmaxの件ですが、pythonのndarryには標準で準備されておりtensorFlowのチュートリアル等でも使われていたので、追加してしまえって感じで短絡的におこなってしまいました。。\u003cbr\u003e\nご指摘のとおり本文の流れ＆趣旨（ディープラーニング・ニューラルネットを簡単に体験）を考えると、本論から離れてしまうので無理に入れないほうが良かったですね；；\u003cbr\u003e\n後日、ご提案いただいた方法で記事を修正したいと思います！\u003c/p\u003e\n&quot;,&quot;created_at&quot;:&quot;2016-08-19T22:50:49+09:00&quot;,&quot;expanded_references&quot;:&quot;&quot;,&quot;id&quot;:616956,&quot;is_team&quot;:false,&quot;item_id&quot;:412598,&quot;item_type&quot;:&quot;PublicDomainArticle&quot;,&quot;item_uuid&quot;:&quot;8e7102a87889950d060d&quot;,&quot;likable&quot;:false,&quot;liked&quot;:false,&quot;public_likes_count&quot;:0,&quot;raw_body&quot;:&quot;@yamamuteki ありがとうございます、そう言っていただけると嬉しいです。\n\nargmaxの件ですが、pythonのndarryには標準で準備されておりtensorFlowのチュートリアル等でも使われていたので、追加してしまえって感じで短絡的におこなってしまいました。。\nご指摘のとおり本文の流れ＆趣旨（ディープラーニング・ニューラルネットを簡単に体験）を考えると、本論から離れてしまうので無理に入れないほうが良かったですね；；\n後日、ご提案いただいた方法で記事を修正したいと思います！\n&quot;,&quot;reaction_types&quot;:[{&quot;image_url&quot;:&quot;https://cdn.qiita.com/emoji/twemoji/unicode/1f44d.png&quot;,&quot;name&quot;:&quot;+1&quot;},{&quot;image_url&quot;:&quot;https://cdn.qiita.com/emoji/twemoji/unicode/1f64f.png&quot;,&quot;name&quot;:&quot;pray&quot;},{&quot;image_url&quot;:&quot;https://cdn.qiita.com/emoji/twemoji/unicode/1f389.png&quot;,&quot;name&quot;:&quot;tada&quot;},{&quot;image_url&quot;:&quot;https://cdn.qiita.com/emoji/twemoji/unicode/1f647.png&quot;,&quot;name&quot;:&quot;bow&quot;},{&quot;image_url&quot;:&quot;https://cdn.qiita.com/emoji/twemoji/unicode/1f631.png&quot;,&quot;name&quot;:&quot;scream&quot;},{&quot;image_url&quot;:&quot;https://cdn.qiita.com/emoji/twemoji/unicode/1f440.png&quot;,&quot;name&quot;:&quot;eyes&quot;}],&quot;reactions&quot;:[],&quot;team&quot;:null,&quot;team_membership&quot;:null,&quot;updatable&quot;:false,&quot;url&quot;:&quot;http://qiita.com/elgoog/items/8e7102a87889950d060d#comment-1dc409301b5c1c35ae53&quot;,&quot;user&quot;:{&quot;contribution&quot;:464,&quot;created_at&quot;:&quot;2014-04-02T22:45:53+09:00&quot;,&quot;id&quot;:40955,&quot;is_admin&quot;:false,&quot;profile_image_url&quot;:&quot;https://qiita-image-store.s3.amazonaws.com/0/40955/profile-images/1473688611&quot;,&quot;suspended&quot;:false,&quot;url_name&quot;:&quot;elgoog&quot;},&quot;uuid&quot;:&quot;1dc409301b5c1c35ae53&quot;,&quot;via_email&quot;:false}],&quot;monthly_public_image_uploadable_size_limit&quot;:null,&quot;total_uploaded_public_image_size_in_current_month&quot;:null,&quot;item&quot;:{&quot;id&quot;:412598,&quot;uuid&quot;:&quot;8e7102a87889950d060d&quot;,&quot;suspended&quot;:false,&quot;secret&quot;:false},&quot;owner&quot;:{&quot;url_name&quot;:&quot;elgoog&quot;},&quot;is_team&quot;:false,&quot;is_project&quot;:false,&quot;logged_in&quot;:false,&quot;polling&quot;:false,&quot;mention_candidates&quot;:[{&quot;id&quot;:40955,&quot;url_name&quot;:&quot;elgoog&quot;,&quot;profile_image_url&quot;:&quot;https://qiita-image-store.s3.amazonaws.com/0/40955/profile-images/1473688611&quot;},{&quot;id&quot;:30400,&quot;url_name&quot;:&quot;antimon2&quot;,&quot;profile_image_url&quot;:&quot;https://qiita-image-store.s3.amazonaws.com/0/30400/profile-images/1473685489&quot;},{&quot;id&quot;:48101,&quot;url_name&quot;:&quot;scivola&quot;,&quot;profile_image_url&quot;:&quot;https://qiita-image-store.s3.amazonaws.com/0/48101/profile-images/1473691230&quot;},{&quot;id&quot;:96254,&quot;url_name&quot;:&quot;yamamuteki&quot;,&quot;profile_image_url&quot;:&quot;https://qiita-image-store.s3.amazonaws.com/0/96254/profile-images/1473706828&quot;}]}" data-trace="false" data-dom-id="CommentListContainer-react-component-41ef5e52-1e05-4293-a22c-dfc0e943ad52"></div>
    <div id="CommentListContainer-react-component-41ef5e52-1e05-4293-a22c-dfc0e943ad52"></div>
    
</div></div></div></div></article><div class="js-report-form modal fade reportForm"><div class="modal-dialog"><div class="modal-content"><div class="modal-header"><button name="button" type="submit" class="close" data-dismiss="modal">&times;</button><h4 class="modal-title">Report article</h4></div><div class="modal-body"><form action="/reports" accept-charset="UTF-8" method="post"><input name="utf8" type="hidden" value="&#x2713;" /><input type="hidden" name="authenticity_token" value="jCRAnnsz1luSa7aE9AEcgFEwOIlkREWKUEAKOl6bIeVz2xBFyviycPK3kDAbT4s0ksJKV6JR/LIxa0aqgwhNhQ==" /><input type="hidden" name="redirect_path" id="redirect_path" value="/elgoog/items/8e7102a87889950d060d" /><input type="hidden" name="item_uuid" id="item_uuid" value="8e7102a87889950d060d" /><p>Help us understand the problem. What is going on with this item?</p><br /><div class="form-group"><ul class="list-unstyled"><li><label><input type="radio" name="report_type" id="report_type_spam" value="spam" required="required" /> It&#39;s spam </label></li><li><label><input type="radio" name="report_type" id="report_type_harassment" value="harassment" required="required" /> It&#39;s abusive or harmful </label></li><li><label><input type="radio" name="report_type" id="report_type_inappropriate_content" value="inappropriate_content" required="required" /> It contains inappropriate content </label></li></ul></div><div class="reportForm_submitButtonContainer"><button name="button" type="submit" class="btn btn-primary reportForm_submitButton"><i class="fa fa-send"></i> Submit</button></div></form></div></div></div></div><script id="js-item" type="application/json">{ "url": "http://qiita.com/elgoog/items/8e7102a87889950d060d", "id": 412598, "uuid": "8e7102a87889950d060d" }</script><script class="js-user" type="application/json">{&quot;id&quot;:40955,&quot;url_name&quot;:&quot;elgoog&quot;,&quot;profile_image_url&quot;:&quot;https://qiita-image-store.s3.amazonaws.com/0/40955/profile-images/1473688611&quot;}</script><script language="JavaScript" src="//cdn.bigmining.com/private/js/qiita_bigmining.js" type="text/javascript"></script></div><footer class="footer"><div class="footer_inner"><div class="footer_container"><ul class="footer_links-left"><li class="footer_link"><a class="footer_copyright" href="http://increments.co.jp">© 2011-2017 Increments Inc.</a></li><li class="footer_link"><a href="http://qiita.com/terms">Terms</a></li><li class="footer_link"><a href="http://qiita.com/privacy">Privacy</a></li><li class="footer_link"><a href="http://help.qiita.com">Help</a></li><li class="footer_link"><a href="https://increments.zendesk.com/anonymous_requests/new">Contact</a></li></ul><ul class="footer_links-right"><li class="footer_link"><a href="http://qiita.com/about">About</a></li><li class="footer_link"><a href="/users">Users</a></li><li class="footer_link"><a href="/tags">Tags</a></li><li class="footer_link"><a href="http://blog.qiita.com">Blog</a></li><li class="footer_link"><a href="http://qiita.com/api/v2/docs">API</a></li><li class="footer_link"><a href="https://teams.qiita.com/">Team</a></li><li class="footer_link"><a href="http://kobito.qiita.com">Kobito</a></li><li class="footer_link"><a class="js-public-form-feedback-link" data-target=".js-feedback-form" data-toggle="modal" href=""><i class="fa fa-heart"></i> Feedback <i class="fa fa-caret-down"></i></a></li></ul></div></div></footer><div class="js-feedback-form modal fade feedbackForm"><div class="modal-dialog"><div class="modal-content"><div class="modal-header"><button name="button" type="submit" class="close" data-dismiss="modal">&times;</button><h4 class="modal-title">Feedback</h4></div><div class="modal-body"><form class="js-feedback-form-form" action="/feedbacks" accept-charset="UTF-8" method="post"><input name="utf8" type="hidden" value="&#x2713;" /><input type="hidden" name="authenticity_token" value="RXFdIwWauS2t8gPlBq506DPYnVAgOsxKVJeSV4IlkX26jg34tFHdBs0uJVHp4ONc8CrvjuYvdXI1vN7HX7b9HQ==" /><input type="hidden" name="redirect_path" id="redirect_path" value="/elgoog/items/8e7102a87889950d060d" /><div class="form-group"><textarea name="feedback[message]" id="feedback_message" class="form-control js-feedback-form-text-area" placeholder="Please give us any feedback about Qiita." required="required" rows="5">
</textarea></div><div class="feedbackForm_submitButtonContainer"><button name="button" type="submit" class="btn btn-primary feedbackForm_submitButton"><i class="fa fa-send"></i> Submit</button><p class="feedbackForm_note">We don&#39;t reply to any feedback.<br />If you need help with Qiita, please send a support request from <a href="https://increments.zendesk.com/anonymous_requests/new">here</a>.</p></div><div style="position:fixed;top:-99999px;opacity:0.0001;"><input name="feedback[name]" type="text" /></div></form></div></div></div></div><script>// if (window.mixpanel instanceof Element) {
//   window.mixpanel = [];
// }
// (function(f,b){if(!b.__SV){var a,e,i,g;window.mixpanel=b;b._i=[];b.init=function(a,e,d){function f(b,h){var a=h.split(".");2==a.length&&(b=b[a[0]],h=a[1]);b[h]=function(){b.push([h].concat(Array.prototype.slice.call(arguments,0)))}}var c=b;"undefined"!==typeof d?c=b[d]=[]:d="mixpanel";c.people=c.people||[];c.toString=function(b){var a="mixpanel";"mixpanel"!==d&&(a+="."+d);b||(a+=" (stub)");return a};c.people.toString=function(){return c.toString(1)+".people (stub)"};i="disable track track_pageview track_links track_forms register register_once alias unregister identify name_tag set_config people.set people.set_once people.increment people.append people.track_charge people.clear_charges people.delete_user".split(" ");
// for(g=0;g<i.length;g++)f(c,i[g]);b._i.push([a,e,d])};b.__SV=1.2;a=f.createElement("script");a.type="text/javascript";a.async=!0;a.src="//cdn.mxpnl.com/libs/mixpanel-2.2.min.js";e=f.getElementsByTagName("script")[0];e.parentNode.insertBefore(a,e)}})(document,window.mixpanel||[]);</script><script src="http://cdn.qiita.com/assets/public-3af9c1d29a49f3320bb796fb5e75304b.min.js"></script><script>
  (function () {
    var script = document.getElementsByTagName('script')[0];
    var load = function (src, id) {
      var el = document.createElement('script');
      el.async = true;
      el.src = src;
      el.id = id;
      script.parentNode.insertBefore(el, script);
    };
      // Optimizely
      load('//cdn.optimizely.com/js/52738645.js', 'optimizely-jssdk');
      // Google Analytics
      window._gaq = window._gaq || [];
      var isCareer = location.hostname.split('.')[0] == 'career';
      if (isCareer) {
        window._gaq.push(['_setAccount', 'UA-24675221-11']);
        window._gaq.push(['_setDomainName', 'qiita.com']);
      } else {
        window._gaq.push(['_setAccount', 'UA-24675221-1']);
      }
      window._gaq.push(['_setCustomVar', 1, 'logged_in', 'false', 2]);
      window._gaq.push(['_trackPageview']);
      var src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
      load(src, 'google-analytics-jssdk');
    // Google Analytics - Universal Analytics
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
    (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
    m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','//www.google-analytics.com/analytics.js','ga');
        ga('create', 'UA-24675221-12', {
          
        });
          ga('create', 'UA-81822075-1', { name: 'user' });
          ga('user.send', 'pageview');
        ga('set', 'dimension1', 'false');
        ga('set', 'dimension3', 'false');
      ga('require', 'displayfeatures');
      ga('set', 'forceSSL', true);
      ga('send', 'pageview');
    // Google Tag Manager
      (function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
      new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
      j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
      '//www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
      })(window,document,'script','dataLayer','GTM-TBQWPN');
  })();
</script>
</body></html>