<!DOCTYPE html><html xmlns:og="http://ogp.me/ns#"><head><meta charset="UTF-8" /><title>深層学習でニュース記事を分類する - Qiita</title><meta content="width=device-width,initial-scale=1" name="viewport" /><meta content="

はじめに

ニュース記事のBag-of-Words(BoW)から，カテゴリを予測するみたいなことをStacked Denoising Autoencodersでやってみました．


データセット

データセットはlivedoor ニュースコーパスを使います．


本コーパスは、NHN Japan株式会社が運営する「livedoor ニュース」のうち、下記のクリエイティブ・コモンズライセンスが適用されるニュース記事を収集し、可能な限りHTMLタグを取り除いて作成したも..." name="description" /><meta content="summary" name="twitter:card" /><meta content="@Qiita" name="twitter:site" /><meta content="hogefugabar" name="twitter:creator" /><meta content="深層学習でニュース記事を分類する - Qiita" property="og:title" /><meta content="article" property="og:type" /><meta content="http://qiita.com/hogefugabar/items/c27ed578717c5e7288c0" property="og:url" /><meta content="http://cdn.qiita.com/assets/qiita-fb-2887e7b4aad86fd8c25cea84846f2236.png" property="og:image" /><meta content="
#はじめに
ニュース記事のBag-of-Words(BoW)から，カテゴリを予測するみたいなことをStacked Denoising Autoencodersでやってみました．

#データセット
データセットは[livedoor ニ..." property="og:description" /><meta content="Qiita" property="og:site_name" /><meta content="564524038" property="fb:admins" /><link rel="shortcut icon" type="image/x-icon" href="http://cdn.qiita.com/assets/favicons/public/production-4ff10c1e1e2b5fcb353ff9cafdd56c70.ico" /><link rel="apple-touch-icon" type="image/png" href="http://cdn.qiita.com/assets/favicons/public/apple-touch-icon-f9a6afad761ec2306e10db2736187c8b.png" /><link href="/opensearch.xml" rel="search" title="Qiita" type="application/opensearchdescription+xml" /><link rel="stylesheet" media="all" href="http://cdn.qiita.com/assets/public-81dd63f4385f99b52aeab91266068ebd.min.css" /><meta name="csrf-param" content="authenticity_token" />
<meta name="csrf-token" content="A5J1FIMabXYl2zqVVReNe0nuP610OuOrVlW0qEuOcZ4dozKILcXhCLF9c/7Utghaew7YpM7FzJFQ0tcv6OEnsA==" /></head><body class="without-js" id=""><noscript><iframe height="0" src="//www.googletagmanager.com/ns.html?id=GTM-TBQWPN" style="display:none;visibility:hidden" width="0"></iframe></noscript><script>
  document.body.className = document.body.className.replace('without-js', '') + ' with-js';
  window.Qiita = {"asset_host":"cdn.qiita.com","TLD":"com","controller_path":"public/items","controller_action":"public/items#show","controller":"items","action":"show","action_path":"public/items#show","env":"production","flash":{},"is_landing_page":false,"is_team_page":false,"request_parameters":{"controller":"public/items","action":"show","user_id":"hogefugabar","type":"items","id":"c27ed578717c5e7288c0"},"root_domain":"qiita.com","variant":null,"config":{"mixpanel":{"career":"dd35af27e959781713d63fd7ca898a8d","per_team":"c0a2116368b33b44b5029ebd2cc9b094","public":"be87616606b0e26a87689099aab2c4e5","team":"b7c0342acba2dbc8742484d98788efb3"},"default_locale":"ja","locale":"en"},"team":null,"user":null,"GIT_BRANCH":null,"DEBUG":false};

</script>
<div class="headerContainer headerContainer-public" role="navigation"><div class="js-react-on-rails-component" data-component-name="HeaderContainer" data-props="{&quot;user&quot;:null,&quot;team&quot;:null,&quot;news&quot;:{&quot;type&quot;:&quot;募集&quot;,&quot;content&quot;:&quot;QiitaやQiita:Teamを良くしたいエンジニア&quot;,&quot;url&quot;:&quot;http://increments.co.jp/jobs/engineers?utm_source=qiita\u0026utm_medium=header_news&quot;},&quot;initial_unread_count&quot;:null,&quot;siteid_image&quot;:&quot;http://cdn.qiita.com/siteid-reverse.png&quot;,&quot;is_team_page&quot;:false,&quot;on_team_setting&quot;:false,&quot;show_post_menu&quot;:true,&quot;show_search_menu&quot;:true,&quot;is_fluid&quot;:false,&quot;locale&quot;:&quot;en&quot;}" data-trace="false" data-dom-id="HeaderContainer-react-component-ab6ab06a-92f9-4b72-9693-4e7578613fa9"></div>
    <div id="HeaderContainer-react-component-ab6ab06a-92f9-4b72-9693-4e7578613fa9"></div>
    
</div><div id="main"><script type="application/ld+json">{  "@context": "http://schema.org",  "@type": "BreadcrumbList",  "itemListElement": [    {      "@type": "ListItem",      "position": 1,      "item": {        "@id": "/",        "name": "Qiita"      }    },    {      "@type": "ListItem",      "position": 2,      "item": {        "@id": "/items",        "name": "Items"      }    },    {      "@type": "ListItem",      "position": 3,      "item": {        "@id": "/tags/%E6%A9%9F%E6%A2%B0%E5%AD%A6%E7%BF%92",        "name": "機械学習"      }    }  ]}</script><article itemscope="" itemtype="http://schema.org/Article"><div class="ArticleMainHeader "><div class="container"></div><div class="container"><div class="row s-flex-align-center"><div class="col-sm-9"><h1 class="ArticleMainHeader__title" itemprop="headline">深層学習でニュース記事を分類する</h1><ul class="TagList"><li class="TagList__item" data-count="1835"><a class="u-link-unstyled TagList__label" href="/tags/%E6%A9%9F%E6%A2%B0%E5%AD%A6%E7%BF%92"><img alt="機械学習" class="TagList__icon" src="https://s3-ap-northeast-1.amazonaws.com/qiita-tag-image/a94d4d239b3b0b83723d5b56c050ffc54b8593e7/medium.jpg?1394635775" /><span>機械学習</span></a></li><li class="TagList__item" data-count="9910"><a class="u-link-unstyled TagList__label" href="/tags/Python"><img alt="Python" class="TagList__icon" src="https://s3-ap-northeast-1.amazonaws.com/qiita-tag-image/28fd3d6b220c89e6197fd82c02fd2fcd2bb66d81/medium.jpg?1383884245" /><span>Python</span></a></li><li class="TagList__item" data-count="1075"><a class="u-link-unstyled TagList__label" href="/tags/DeepLearning"><img alt="DeepLearning" class="TagList__icon" src="https://s3-ap-northeast-1.amazonaws.com/qiita-tag-image/eac844d1d880a38fc3be5ebf534cad5182b64ebf/medium.jpg?1453002020" /><span>DeepLearning</span></a></li><li class="TagList__item" data-count="229"><a class="u-link-unstyled TagList__label" href="/tags/%E6%B7%B1%E5%B1%A4%E5%AD%A6%E7%BF%92"><img alt="深層学習" class="TagList__icon" src="https://s3-ap-northeast-1.amazonaws.com/qiita-tag-image/9594cfcb56d9180f74c468e56c69ce9f69cbe6ee/medium.jpg?1480640899" /><span>深層学習</span></a></li><li class="TagList__item" data-count="358"><a class="u-link-unstyled TagList__label" href="/tags/Chainer"><img alt="Chainer" class="TagList__icon" src="https://s3-ap-northeast-1.amazonaws.com/qiita-tag-image/755fdcf477b1d3db5946dad4f779ba11a5954c18/medium.jpg?1434432587" /><span>Chainer</span></a></li></ul></div><div class="col-sm-3"><div class="itemsShowHeaderStock"><ul class="list-unstyled itemsShowHeaderStock_statusList"><li><div class="itemsShowHeaderStock_count stock"><span class="fa fa-thumbs-up"></span><span class="js-likecount">175</span></div><div class="itemsShowHeaderStock_countText">Like</div></li><li><div class="itemsShowHeaderStock_count" content="0 UserComments" itemprop="commentCount"><span class="fa fa-comment"></span>0</div><div class="itemsShowHeaderStock_countText">Comment</div></li></ul></div><div class="js-likebutton" data-props="{&quot;like_status&quot;:false,&quot;like_count&quot;:175,&quot;uuid&quot;:&quot;c27ed578717c5e7288c0&quot;,&quot;likable_type&quot;:&quot;Article&quot;,&quot;position&quot;:&quot;article-header&quot;}"></div><ul class="list-inline ArticleMainHeader__users"><li class="js-hovercard" data-hovercard-target-name="okappy"><a itemprop="url" href="/okappy"><img alt="okappy" class="thumb thumb--xs" src="https://qiita-image-store.s3.amazonaws.com/0/1418/profile-images/1480224071" /></a></li><li class="js-hovercard" data-hovercard-target-name="HirofumiYashima"><a itemprop="url" href="/HirofumiYashima"><img alt="HirofumiYashima" class="thumb thumb--xs" src="https://qiita-image-store.s3.amazonaws.com/0/43487/profile-images/1473689546" /></a></li><li class="js-hovercard" data-hovercard-target-name="t-hanya"><a itemprop="url" href="/t-hanya"><img alt="t-hanya" class="thumb thumb--xs" src="https://qiita-image-store.s3.amazonaws.com/0/38729/profile-images/1473687868" /></a></li><li class="js-hovercard" data-hovercard-target-name="zaoriku0"><a itemprop="url" href="/zaoriku0"><img alt="zaoriku0" class="thumb thumb--xs" src="https://qiita-image-store.s3.amazonaws.com/0/7438/profile-images/1473684178" /></a></li><li class="js-hovercard" data-hovercard-target-name="kumazo"><a itemprop="url" href="/kumazo"><img alt="kumazo" class="thumb thumb--xs" src="https://secure.gravatar.com/avatar/f1028eac1359f4c5b6d87584d0b99d2e?d=https://a248.e.akamai.net/assets.github.com%2Fimages%2Fgravatars%2Fgravatar-user-420.png" /></a></li><li class="js-hovercard" data-hovercard-target-name="mitrad"><a itemprop="url" href="/mitrad"><img alt="mitrad" class="thumb thumb--xs" src="https://qiita-image-store.s3.amazonaws.com/0/86562/profile-images/1473703788" /></a></li><li class="js-hovercard" data-hovercard-target-name="Reds"><a itemprop="url" href="/Reds"><img alt="Reds" class="thumb thumb--xs" src="https://0.gravatar.com/avatar/e751888e30cdc35253c1a3b241977adf?d=https%3A%2F%2Fidenticons.github.com%2F0e2f15414d97b8b642022be91ff105e0.png" /></a></li><li class="js-hovercard" data-hovercard-target-name="snoopython"><a itemprop="url" href="/snoopython"><img alt="snoopython" class="thumb thumb--xs" src="https://qiita-image-store.s3.amazonaws.com/0/44000/profile-images/1473898779" /></a></li><li class="js-hovercard" data-hovercard-target-name="minewebstaff"><a itemprop="url" href="/minewebstaff"><img alt="minewebstaff" class="thumb thumb--xs" src="https://qiita-image-store.s3.amazonaws.com/0/46049/profile-images/1473690517" /></a></li><li class="js-hovercard" data-hovercard-target-name="mero"><a itemprop="url" href="/mero"><img alt="mero" class="thumb thumb--xs" src="https://qiita-image-store.s3.amazonaws.com/0/63104/profile-images/1473696161" /></a></li><li><a href="/hogefugabar/items/c27ed578717c5e7288c0/likers"><span class="fa fa-ellipsis-h"></span></a></li></ul></div></div></div></div><div class="ArticleAsideHeader"><div class="container"><div class="u-flex u-space-between"><div class="u-flex u-flex-wrap"><div class="u-flex u-align-center s-pdv-5 u-flex-wrap"><div class="ArticleAsideHeader__author"><a href="/hogefugabar"><img class="thumb thumb--xs" src="https://qiita-image-store.s3.amazonaws.com/0/31899/profile-images/1473685791" alt="1473685791" /></a> <a class="u-link-unstyled" href="/hogefugabar">hogefugabar</a> </div><div class="ArticleAsideHeader__date"><meta content="2015-07-23T20:55:43+09:00" itemprop="datePublished" /><span data-toggle="tooltip" title="posted at 2015-07-23">Edited at <time datetime="2015-08-20T17:08:54+09:00" itemprop="dateModified">2015-08-20</time></span></div></div><div class="u-flex u-align-center s-pdv-5 mobile-hidden"><div class="ArticleAsideHeader__revision"> <a data-toggle="tooltip" title="Revisions" href="/hogefugabar/items/c27ed578717c5e7288c0/revisions"><span class="fa fa-history"></span></a><span class="ArticleAsideHeader__revisionCount">2</span></div></div><div class="u-flex u-align-center s-pdv-5 mobile-hidden"></div></div><div class="u-flex u-align-center s-flex-justiry-between s-pdv-5 u-shrink-0"><div class="ArticleAsideHeader__stock"><div class="js-stockbutton" data-position="top" data-props="{&quot;stock_status&quot;:false}"></div></div><div class="dropdown"><a class="dropdown-toggle" data-toggle="dropdown" href="#"><span class="fa fa-ellipsis-h fa-lg"></span></a><ul class="dropdown-menu dropdown-menu-right"><li class="dropdown__item--mobile"><a href="/hogefugabar/items/c27ed578717c5e7288c0/revisions"><span class="fa fa-fw fa-history"></span> Revisions<span>(2)</span></a></li><li><a href="/hogefugabar/items/c27ed578717c5e7288c0.md"><span class="fa fa-fw fa-file-text-o"></span> Show article as Markdown</a></li><li><a data-target=".js-report-form" data-toggle="modal" href="#"><span class="fa fa-fw fa-flag"></span> Report article</a></li></ul></div></div></div></div></div><div class="container"><div class="row" id="article-body-wrapper"><div class="col-sm-9"><section class="markdownContent markdownContent-headingEnabled js-task-list-container clearfix position-relative" id="item-c27ed578717c5e7288c0" itemprop="articleBody"><div class="alert alert-warning"><i class="fa fa-clock-o"></i> More than 1 year has passed since last update.</div>
<h1>
<span id="はじめに" class="fragment"></span><a href="#%E3%81%AF%E3%81%98%E3%82%81%E3%81%AB"><i class="fa fa-link"></i></a>はじめに</h1>

<p>ニュース記事のBag-of-Words(BoW)から，カテゴリを予測するみたいなことをStacked Denoising Autoencodersでやってみました．</p>

<h1>
<span id="データセット" class="fragment"></span><a href="#%E3%83%87%E3%83%BC%E3%82%BF%E3%82%BB%E3%83%83%E3%83%88"><i class="fa fa-link"></i></a>データセット</h1>

<p>データセットは<a href="http://www.rondhuit.com/download.html#ldcc" rel="nofollow noopener" target="_blank">livedoor ニュースコーパス</a>を使います．</p>

<blockquote>
<p>本コーパスは、NHN Japan株式会社が運営する「livedoor ニュース」のうち、下記のクリエイティブ・コモンズライセンスが適用されるニュース記事を収集し、可能な限りHTMLタグを取り除いて作成したものです。</p>
</blockquote>

<p>らしいです．</p>

<ul>
<li>トピックニュース</li>
<li>Sports Watch</li>
<li>ITライフハック</li>
<li>家電チャンネル</li>
<li>MOVIE ENTER</li>
<li>独女通信</li>
<li>エスマックス</li>
<li>livedoor HOMME</li>
<li>Peachy</li>
</ul>

<p>の計9つのカテゴリがあるので，9クラス分類問題になります．</p>

<h1>
<span id="データ前処理" class="fragment"></span><a href="#%E3%83%87%E3%83%BC%E3%82%BF%E5%89%8D%E5%87%A6%E7%90%86"><i class="fa fa-link"></i></a>データ前処理</h1>

<p>まず記事をBoWにする必要がありますが，これには<a href="https://github.com/yasunori/" rel="nofollow noopener" target="_blank">yasunori</a>さんの<a href="https://github.com/yasunori/Random-Forest-Example" rel="nofollow noopener" target="_blank">Random-Forest-Example</a>のcorpus.pyを利用させていただきました．</p>

<div class="code-frame" data-lang="text"><div class="highlight"><pre>
python corpus.py
</pre></div></div>

<p>を実行すると辞書(livedoordic.txt)を作ってくれます．初回だけ実行します．<br>
次に入力として与えるデータを作成します．corpus.pyについてget_class_idというメソッドについてのみ↓のように書き換えたんだけどかなり昔にやったからどうしてそうなったのか思い出せない．．．</p>

<div class="code-frame" data-lang="python">
<div class="code-lang"><span class="bold">corpus.py</span></div>
<div class="highlight"><pre>
<span class="k">def</span> <span class="nf">get_class_id</span><span class="p">(</span><span class="n">file_name</span><span class="p">):</span>
    <span class="sd">'''</span>
<span class="sd">    ファイル名から、クラスIDを決定する。</span>
<span class="sd">    学習データを作るときに使っています。</span>
<span class="sd">    '''</span>
    <span class="n">dir_list</span> <span class="o">=</span> <span class="n">get_dir_list</span><span class="p">()</span>
    <span class="n">dir_name</span> <span class="o">=</span> <span class="nb">filter</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">file_name</span><span class="p">,</span> <span class="n">dir_list</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">dir_list</span><span class="o">.</span><span class="n">index</span><span class="p">(</span><span class="n">dir_name</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
</pre></div>
</div>

<div class="code-frame" data-lang="python"><div class="highlight"><pre>
<span class="kn">import</span> <span class="nn">corpus</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>

<span class="n">dictionary</span> <span class="o">=</span> <span class="n">corpus</span><span class="o">.</span><span class="n">get_dictionary</span><span class="p">(</span><span class="n">create_flg</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
<span class="n">contents</span> <span class="o">=</span> <span class="n">corpus</span><span class="o">.</span><span class="n">get_contents</span><span class="p">()</span>

<span class="n">data</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">target</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">file_name</span><span class="p">,</span> <span class="n">content</span> <span class="ow">in</span> <span class="n">contents</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
    <span class="n">data</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">corpus</span><span class="o">.</span><span class="n">get_vector</span><span class="p">(</span><span class="n">dictionary</span><span class="p">,</span> <span class="n">content</span><span class="p">))</span>
    <span class="n">target</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">corpus</span><span class="o">.</span><span class="n">get_class_id</span><span class="p">(</span><span class="n">file_name</span><span class="p">))</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span> <span class="c">#入力として与えるデータ</span>
<span class="n">target</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">target</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span> <span class="c">#正解データ</span>
</pre></div></div>

<h1>
<span id="stacked-denoising-autoencoders" class="fragment"></span><a href="#stacked-denoising-autoencoders"><i class="fa fa-link"></i></a>Stacked Denoising Autoencoders</h1>

<p>今回はDenoising Autoencoderを深層化したStacked Denoising Autoencoders (SDA)で学習させます．実装は<a href="http://chainer.org" rel="nofollow noopener" target="_blank">Chainer</a>を利用しています．Autoencoderに関する説明は<a href="http://qiita.com/kenmatsu4">kenmatsu4</a>さんの<a href="http://qiita.com/kenmatsu4/items/99d4a54d5a57405ecaf8" id="reference-9f2a7e2e52d07400b896">【ディープラーニング】ChainerでAutoencoderを試して結果を可視化してみる。</a>が個人的にすごくわかりやすいです．<br>
SDAはAutoencoderを3つ積層，過学習防止にDropout，Masking noise，活性化関数にはReLUを使っています．訓練，評価データの比率は9:1です．<br>
SDAのコードは僕のGitHubの<a href="https://github.com/hogefugabar/deep-learning-chainer" rel="nofollow noopener" target="_blank">deep-learning-chainer</a>リポジトリにSDA.pyという名前であげてます．<br>
実行したコードは下みたいな感じです．</p>

<div class="code-frame" data-lang="python"><div class="highlight"><pre>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">SDA</span> <span class="kn">import</span> <span class="n">SDA</span>
<span class="kn">from</span> <span class="nn">chainer</span> <span class="kn">import</span> <span class="n">cuda</span>

<span class="n">cuda</span><span class="o">.</span><span class="n">init</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

<span class="n">rng</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">RandomState</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="n">sda</span> <span class="o">=</span> <span class="n">SDA</span><span class="p">(</span><span class="n">rng</span><span class="o">=</span><span class="n">rng</span><span class="p">,</span>
          <span class="n">data</span><span class="o">=</span><span class="n">data</span><span class="p">,</span>
          <span class="n">target</span><span class="o">=</span><span class="n">target</span><span class="p">,</span>
          <span class="n">n_inputs</span><span class="o">=</span><span class="mi">6974</span><span class="p">,</span>
          <span class="n">n_hidden</span><span class="o">=</span><span class="p">[</span><span class="mi">500</span><span class="p">,</span><span class="mi">500</span><span class="p">,</span><span class="mi">500</span><span class="p">],</span>
          <span class="n">n_outputs</span><span class="o">=</span><span class="mi">9</span><span class="p">,</span>
          <span class="n">gpu</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">sda</span><span class="o">.</span><span class="n">pre_train</span><span class="p">(</span><span class="n">n_epoch</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="n">sda</span><span class="o">.</span><span class="n">fine_tune</span><span class="p">(</span><span class="n">n_epoch</span><span class="o">=</span><span class="mi">30</span><span class="p">)</span>
</pre></div></div>

<h1>
<span id="実行結果" class="fragment"></span><a href="#%E5%AE%9F%E8%A1%8C%E7%B5%90%E6%9E%9C"><i class="fa fa-link"></i></a>実行結果</h1>

<h3>
<span id="sda" class="fragment"></span><a href="#sda"><i class="fa fa-link"></i></a>SDA</h3>

<div class="code-frame" data-lang="text"><div class="highlight"><pre>
C:\Python27\lib\site-packages\skcuda\cublas.py:273: UserWarning: creating CUBLAS
 context to get version number
  warnings.warn('creating CUBLAS context to get version number')
--------First DA training has started!--------
epoch 1
train mean loss=0.106402929114
test mean loss=0.088471424426
epoch 2
train mean loss=0.0816160233447
test mean loss=0.0739360584434
--
中略
--
epoch 9
train mean loss=0.0519113916775
test mean loss=0.0670968969548
epoch 10
train mean loss=0.0511762971061
test mean loss=0.0661109716832
--------Second DA training has started!--------
epoch 1
train mean loss=1.28116437635
test mean loss=0.924632857176
epoch 2
train mean loss=0.908878781048
test mean loss=0.763214301707
--
中略
--
epoch 9
train mean loss=0.500251602623
test mean loss=0.55466137691
epoch 10
train mean loss=0.485327716237
test mean loss=0.517578341663
--------Third DA training has started!--------
epoch 1
train mean loss=1.0635086948
test mean loss=0.778134044507
epoch 2
train mean loss=0.656580147385
test mean loss=0.612065581324
--
中略
--
epoch 9
train mean loss=0.433458953354
test mean loss=0.486904190264
epoch 10
train mean loss=0.400864538789
test mean loss=0.46137621372
fine tuning epoch  1
fine tuning train mean loss=1.33540507985, accuracy=0.614027133827
fine tuning test mean loss=0.363009182577, accuracy=0.902306635635
fine tuning epoch  2
fine tuning train mean loss=0.451324046692, accuracy=0.869683239884
fine tuning test mean loss=0.235001576683, accuracy=0.945725910052
fine tuning epoch  3
fine tuning train mean loss=0.233203321021, accuracy=0.937104056863
fine tuning test mean loss=0.172718693961, accuracy=0.952510164098
fine tuning epoch  4
fine tuning train mean loss=0.156541177815, accuracy=0.957164381244
fine tuning test mean loss=0.167446922435, accuracy=0.962008120247
--
中略
--
fine tuning epoch  27
fine tuning train mean loss=0.0105007310127, accuracy=0.997586716714
fine tuning test mean loss=0.217954038866, accuracy=0.960651269438
fine tuning epoch  28
fine tuning train mean loss=0.00783754364192, accuracy=0.998340867404
fine tuning test mean loss=0.206009919964, accuracy=0.957937559732
fine tuning epoch  29
fine tuning train mean loss=0.00473990425367, accuracy=0.998491696822
fine tuning test mean loss=0.245603679721, accuracy=0.95793756782
fine tuning epoch  30
fine tuning train mean loss=0.00755465408512, accuracy=0.998190036187
fine tuning test mean loss=0.228568312999, accuracy=0.962008120247
</pre></div></div>

<p>分類精度の推移グラフは以下のようになっています．<br>
<a href="https://dl.dropboxusercontent.com/u/38631959/sda_result.png" target="_blank" rel="nofollow noopener"><img src="https://dl.dropboxusercontent.com/u/38631959/sda_result.png" width="500px"></a></p>

<h3>
<span id="多層パーセプトロン" class="fragment"></span><a href="#%E5%A4%9A%E5%B1%A4%E3%83%91%E3%83%BC%E3%82%BB%E3%83%97%E3%83%88%E3%83%AD%E3%83%B3"><i class="fa fa-link"></i></a>多層パーセプトロン</h3>

<p>事前学習を行わなかった場合どうなるのか調べたくて，同じ構造の多層パーセプトロンでも実験してみました．SDAと同じく過学習防止にDropout，活性化関数としてReLUを利用しています．<br>
<a href="https://dl.dropboxusercontent.com/u/38631959/nn_result.png" target="_blank" rel="nofollow noopener"><img src="https://dl.dropboxusercontent.com/u/38631959/nn_result.png" width="500px"></a></p>

<h1>
<span id="おわりに" class="fragment"></span><a href="#%E3%81%8A%E3%82%8F%E3%82%8A%E3%81%AB"><i class="fa fa-link"></i></a>おわりに</h1>

<p>最終的な分類精度としてはSDAは95%位となり，かなりいい結果となりました．多層パーセプトロンは92%位となり，SDAより汎化性能が悪いことがわかりますが，実験を一回しか回していないので結果の信憑性はあやしいです．</p>

<p>変なところとかありましたらご指摘いただけるとありがたいです．</p>
<div class="hidden"><form class="js-task-list-update" action="/hogefugabar/items/c27ed578717c5e7288c0" accept-charset="UTF-8" method="post"><input name="utf8" type="hidden" value="&#x2713;" /><input type="hidden" name="_method" value="patch" /><input type="hidden" name="authenticity_token" value="jps2pxGHTEQf8Vl2YhOpGxn9P73TBZ1kePhG81W89o2QqnE7v1jAOotXEB3jsiw6Kx3YtGn6sl5+fyV09tOgow==" /><input type="hidden" name="updated_at_confirmation_in_unixtime" id="updated_at_confirmation_in_unixtime" value="1440058134" class="js-task-list-updated-at" /><textarea name="raw_body" id="raw_body" class="js-task-list-field">

#はじめに
ニュース記事のBag-of-Words(BoW)から，カテゴリを予測するみたいなことをStacked Denoising Autoencodersでやってみました．

#データセット
データセットは[livedoor ニュースコーパス](http://www.rondhuit.com/download.html#ldcc)を使います．
&gt;本コーパスは、NHN Japan株式会社が運営する「livedoor ニュース」のうち、下記のクリエイティブ・コモンズライセンスが適用されるニュース記事を収集し、可能な限りHTMLタグを取り除いて作成したものです。

らしいです．

- トピックニュース
- Sports Watch
- ITライフハック
- 家電チャンネル
- MOVIE ENTER
- 独女通信
- エスマックス
- livedoor HOMME
- Peachy

の計9つのカテゴリがあるので，9クラス分類問題になります．

#データ前処理
まず記事をBoWにする必要がありますが，これには[yasunori](https://github.com/yasunori/)さんの[Random-Forest-Example](https://github.com/yasunori/Random-Forest-Example)のcorpus.pyを利用させていただきました．

```
python corpus.py
```
を実行すると辞書(livedoordic.txt)を作ってくれます．初回だけ実行します．
次に入力として与えるデータを作成します．corpus.pyについてget_class_idというメソッドについてのみ↓のように書き換えたんだけどかなり昔にやったからどうしてそうなったのか思い出せない．．．

```python:corpus.py
def get_class_id(file_name):
    &#39;&#39;&#39;
    ファイル名から、クラスIDを決定する。
    学習データを作るときに使っています。
    &#39;&#39;&#39;
    dir_list = get_dir_list()
    dir_name = filter(lambda x: x in file_name, dir_list)
    return dir_list.index(dir_name[0])
```


```python
import corpus
import numpy as np

dictionary = corpus.get_dictionary(create_flg=False)
contents = corpus.get_contents()

data = []
target = []
for file_name, content in contents.items():
	data.append(corpus.get_vector(dictionary, content))
	target.append(corpus.get_class_id(file_name))
data = np.array(data, np.float32) #入力として与えるデータ
target = np.array(target, np.int32) #正解データ
```

#Stacked Denoising Autoencoders
今回はDenoising Autoencoderを深層化したStacked Denoising Autoencoders (SDA)で学習させます．実装は[Chainer](http://chainer.org)を利用しています．Autoencoderに関する説明は[kenmatsu4](http://qiita.com/kenmatsu4)さんの[【ディープラーニング】ChainerでAutoencoderを試して結果を可視化してみる。](http://qiita.com/kenmatsu4/items/99d4a54d5a57405ecaf8)が個人的にすごくわかりやすいです．
SDAはAutoencoderを3つ積層，過学習防止にDropout，Masking noise，活性化関数にはReLUを使っています．訓練，評価データの比率は9:1です．
SDAのコードは僕のGitHubの[deep-learning-chainer](https://github.com/hogefugabar/deep-learning-chainer)リポジトリにSDA.pyという名前であげてます．
実行したコードは下みたいな感じです．

```python
import numpy as np
from SDA import SDA
from chainer import cuda

cuda.init(0)

rng = np.random.RandomState(1)
sda = SDA(rng=rng,
		  data=data,
		  target=target,
		  n_inputs=6974,
		  n_hidden=[500,500,500],
		  n_outputs=9,
		  gpu=0)
sda.pre_train(n_epoch=10)
sda.fine_tune(n_epoch=30)
```

#実行結果
###SDA
```
C:\Python27\lib\site-packages\skcuda\cublas.py:273: UserWarning: creating CUBLAS
 context to get version number
  warnings.warn(&#39;creating CUBLAS context to get version number&#39;)
--------First DA training has started!--------
epoch 1
train mean loss=0.106402929114
test mean loss=0.088471424426
epoch 2
train mean loss=0.0816160233447
test mean loss=0.0739360584434
--
中略
--
epoch 9
train mean loss=0.0519113916775
test mean loss=0.0670968969548
epoch 10
train mean loss=0.0511762971061
test mean loss=0.0661109716832
--------Second DA training has started!--------
epoch 1
train mean loss=1.28116437635
test mean loss=0.924632857176
epoch 2
train mean loss=0.908878781048
test mean loss=0.763214301707
--
中略
--
epoch 9
train mean loss=0.500251602623
test mean loss=0.55466137691
epoch 10
train mean loss=0.485327716237
test mean loss=0.517578341663
--------Third DA training has started!--------
epoch 1
train mean loss=1.0635086948
test mean loss=0.778134044507
epoch 2
train mean loss=0.656580147385
test mean loss=0.612065581324
--
中略
--
epoch 9
train mean loss=0.433458953354
test mean loss=0.486904190264
epoch 10
train mean loss=0.400864538789
test mean loss=0.46137621372
fine tuning epoch  1
fine tuning train mean loss=1.33540507985, accuracy=0.614027133827
fine tuning test mean loss=0.363009182577, accuracy=0.902306635635
fine tuning epoch  2
fine tuning train mean loss=0.451324046692, accuracy=0.869683239884
fine tuning test mean loss=0.235001576683, accuracy=0.945725910052
fine tuning epoch  3
fine tuning train mean loss=0.233203321021, accuracy=0.937104056863
fine tuning test mean loss=0.172718693961, accuracy=0.952510164098
fine tuning epoch  4
fine tuning train mean loss=0.156541177815, accuracy=0.957164381244
fine tuning test mean loss=0.167446922435, accuracy=0.962008120247
--
中略
--
fine tuning epoch  27
fine tuning train mean loss=0.0105007310127, accuracy=0.997586716714
fine tuning test mean loss=0.217954038866, accuracy=0.960651269438
fine tuning epoch  28
fine tuning train mean loss=0.00783754364192, accuracy=0.998340867404
fine tuning test mean loss=0.206009919964, accuracy=0.957937559732
fine tuning epoch  29
fine tuning train mean loss=0.00473990425367, accuracy=0.998491696822
fine tuning test mean loss=0.245603679721, accuracy=0.95793756782
fine tuning epoch  30
fine tuning train mean loss=0.00755465408512, accuracy=0.998190036187
fine tuning test mean loss=0.228568312999, accuracy=0.962008120247
```

分類精度の推移グラフは以下のようになっています．
&lt;img src=&quot;https://dl.dropboxusercontent.com/u/38631959/sda_result.png&quot; width=500px&gt;

###多層パーセプトロン
事前学習を行わなかった場合どうなるのか調べたくて，同じ構造の多層パーセプトロンでも実験してみました．SDAと同じく過学習防止にDropout，活性化関数としてReLUを利用しています．
&lt;img src=&quot;https://dl.dropboxusercontent.com/u/38631959/nn_result.png&quot; width=500px&gt;



#おわりに
最終的な分類精度としてはSDAは95%位となり，かなりいい結果となりました．多層パーセプトロンは92%位となり，SDAより汎化性能が悪いことがわかりますが，実験を一回しか回していないので結果の信憑性はあやしいです．

変なところとかありましたらご指摘いただけるとありがたいです．










</textarea><input type="submit" name="commit" value="Save changes" data-disable-with="Save changes" /></form></div></section></div><div class="col-sm-3"><div class="socialButtons"><div class="socialButtons_twitter"><a class="twitter-share-button" data-text="深層学習でニュース記事を分類する by @hogefugabar on @Qiita" data-url="http://qiita.com/hogefugabar/items/c27ed578717c5e7288c0" href="https://twitter.com/share">Tweet</a></div><div class="socialButtons_hatebu"><a class="hatena-bookmark-button" data-hatena-bookmark-layout="simple-balloon" data-hatena-bookmark-title="深層学習でニュース記事を分類する" href="http://b.hatena.ne.jp/entry/http://qiita.com/hogefugabar/items/c27ed578717c5e7288c0" title="Add to Hatena Bookmark"><img alt="Add to Hatena Bookmark" height="20" src="https://b.st-hatena.com/images/entry-button/button-only@2x.png" style="border: none;" width="20" /></a><script async="async" charset="utf-8" src="https://b.st-hatena.com/js/bookmark_button.js" type="text/javascript"></script></div><div class="socialButtons_googlePlus"><div class="g-plusone" data-href="http://qiita.com/hogefugabar/items/c27ed578717c5e7288c0" data-size="medium"></div></div><div class="socialButtons_facebook"><div class="fb-like" data-action="like" data-href="http://qiita.com/hogefugabar/items/c27ed578717c5e7288c0" data-layout="button_count" data-share="false" data-show-faces="false"></div></div><div class="socialButtons_pocket"><a class="pocket-btn" data-lang="en" data-pocket-count="horizontal" data-pocket-label="pocket"></a></div></div><section class="itemsShowAuthorInfo" itemprop="author" itemscope="" itemtype="http://schema.org/Person"><a href="/hogefugabar"><img alt="" class="itemsShowAuthorInfo_userIcon" itemprop="image" src="https://qiita-image-store.s3.amazonaws.com/0/31899/profile-images/1473685791" /></a><div class="itemsShowAuthorInfo_profileStats"><strong class="itemsShowAuthorInfo_userName" itemprop="name"><a itemprop="url" href="/hogefugabar">hogefugabar</a></strong><div class="itemsShowAuthorInfo_contribution"><span class="itemsShowAuthorInfo_count">911</span><span class="itemsShowAuthorInfo_unit">Contribution</span></div><div id="js-react-on-rails-context" data-rails-context="{}"></div>
<div class="js-react-on-rails-component" data-component-name="UserFollowButton" data-props="{&quot;initial_followed_by&quot;:false,&quot;position&quot;:&quot;author-info&quot;,&quot;size&quot;:&quot;btn-xs&quot;,&quot;url_name&quot;:&quot;hogefugabar&quot;}" data-trace="false" data-dom-id="UserFollowButton-react-component-51cb4a5f-08e2-4afd-a8f6-235034692e6e"></div>
    <div id="UserFollowButton-react-component-51cb4a5f-08e2-4afd-a8f6-235034692e6e"></div>
    
</div><section class="itemsShowAuthorPopularItems"><h5 class="itemsShowAuthorPopularItems_sectionTitle">Popular Posts</h5><ul class="itemsShowAuthorPopularItems_posts list-unstyled"><li itemscope="" itemtype="http://schema.org/Article"> <a itemprop="url" track="click" data-label="AuthorPopularItemsAtSidebar" href="/hogefugabar/items/c27ed578717c5e7288c0">深層学習でニュース記事を分類する</a></li><li itemscope="" itemtype="http://schema.org/Article"> <a itemprop="url" track="click" data-label="AuthorPopularItemsAtSidebar" href="/hogefugabar/items/93fcb2bc27d7b268cbe6">深層学習でツイートの感情分析</a></li><li itemscope="" itemtype="http://schema.org/Article"> <a itemprop="url" track="click" data-label="AuthorPopularItemsAtSidebar" href="/hogefugabar/items/312707a09d29632e7288">深層学習でアニメ顔を分類する with Chainer</a></li><li itemscope="" itemtype="http://schema.org/Article"> <a itemprop="url" track="click" data-label="AuthorPopularItemsAtSidebar" href="/hogefugabar/items/c0d71feeb1111a3c6f47">重回帰モデルの理論と実装 -なぜ正則化が必要か-</a></li><li itemscope="" itemtype="http://schema.org/Article"> <a itemprop="url" track="click" data-label="AuthorPopularItemsAtSidebar" href="/hogefugabar/items/1d4f6c905d0edbc71af2">ニューラルネットで最適化アルゴリズムを色々試してみる</a></li></ul></section></section><div class="scroll-chaser"><div class="google-adsense"><style>.test-text-responsible { width: 200px; height: 200px; }@media(min-width: 1200px) {  .test-text-responsible { width: 250px; height: 250px; }}@media(max-width: 979px) and (min-width: 768px) {  .test-text-responsible { width: 120px; height: 240px; }}@media(max-width: 767px) {  .test-text-responsible { width: 320px; height: 50px; }}</style><script async="" src="http://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script><ins class="adsbygoogle test-text-responsible" data-ad-client="ca-pub-8127218772604357" data-ad-slot="3880091879" style="display:inline-block"></ins><script>(adsbygoogle = window.adsbygoogle || []).push({});</script></div></div><div class="js-react-on-rails-component" data-component-name="Toc" data-props="{&quot;body&quot;:&quot;\u003cul\u003e\n\u003cli\u003e\n\u003ca href=\&quot;#%E3%81%AF%E3%81%98%E3%82%81%E3%81%AB\&quot;\u003eはじめに\u003c/a\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\&quot;#%E3%83%87%E3%83%BC%E3%82%BF%E3%82%BB%E3%83%83%E3%83%88\&quot;\u003eデータセット\u003c/a\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\&quot;#%E3%83%87%E3%83%BC%E3%82%BF%E5%89%8D%E5%87%A6%E7%90%86\&quot;\u003eデータ前処理\u003c/a\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\&quot;#stacked-denoising-autoencoders\&quot;\u003eStacked Denoising Autoencoders\u003c/a\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\&quot;#%E5%AE%9F%E8%A1%8C%E7%B5%90%E6%9E%9C\&quot;\u003e実行結果\u003c/a\u003e\n\u003cul\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003ca href=\&quot;#sda\&quot;\u003eSDA\u003c/a\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003ca href=\&quot;#%E5%A4%9A%E5%B1%A4%E3%83%91%E3%83%BC%E3%82%BB%E3%83%97%E3%83%88%E3%83%AD%E3%83%B3\&quot;\u003e多層パーセプトロン\u003c/a\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\n\n\u003ca href=\&quot;#%E3%81%8A%E3%82%8F%E3%82%8A%E3%81%AB\&quot;\u003eおわりに\u003c/a\u003e\n\n\n&quot;,&quot;wrapper&quot;:&quot;#article-body-wrapper&quot;}" data-trace="false" data-dom-id="Toc-react-component-794b5b8d-6099-4fdf-b6a7-f0b0b63625a3"></div>
    <div id="Toc-react-component-794b5b8d-6099-4fdf-b6a7-f0b0b63625a3"></div>
    
</div></div><div class="row"><div class="col-sm-9"><div class="ArticleFooter__menu"><div class="s-flex-align-center"><div class="js-likebutton" data-props="{&quot;like_status&quot;:false,&quot;like_count&quot;:175,&quot;show_count&quot;:true,&quot;uuid&quot;:&quot;c27ed578717c5e7288c0&quot;,&quot;likable_type&quot;:&quot;Article&quot;,&quot;position&quot;:&quot;article-footer&quot;}"></div><div class="ArticleFooter__userList"><div class="ArticleFooter__user"><div class="js-hovercard" data-hovercard-target-name="okappy"><a itemprop="url" href="/okappy"><img alt="okappy" class="thumb thumb--xs" src="https://qiita-image-store.s3.amazonaws.com/0/1418/profile-images/1480224071" /></a></div></div><div class="ArticleFooter__user"><div class="js-hovercard" data-hovercard-target-name="HirofumiYashima"><a itemprop="url" href="/HirofumiYashima"><img alt="HirofumiYashima" class="thumb thumb--xs" src="https://qiita-image-store.s3.amazonaws.com/0/43487/profile-images/1473689546" /></a></div></div><div class="ArticleFooter__user"><div class="js-hovercard" data-hovercard-target-name="t-hanya"><a itemprop="url" href="/t-hanya"><img alt="t-hanya" class="thumb thumb--xs" src="https://qiita-image-store.s3.amazonaws.com/0/38729/profile-images/1473687868" /></a></div></div><div class="ArticleFooter__user"><div class="js-hovercard" data-hovercard-target-name="zaoriku0"><a itemprop="url" href="/zaoriku0"><img alt="zaoriku0" class="thumb thumb--xs" src="https://qiita-image-store.s3.amazonaws.com/0/7438/profile-images/1473684178" /></a></div></div><div class="ArticleFooter__user"><div class="js-hovercard" data-hovercard-target-name="kumazo"><a itemprop="url" href="/kumazo"><img alt="kumazo" class="thumb thumb--xs" src="https://secure.gravatar.com/avatar/f1028eac1359f4c5b6d87584d0b99d2e?d=https://a248.e.akamai.net/assets.github.com%2Fimages%2Fgravatars%2Fgravatar-user-420.png" /></a></div></div><div class="ArticleFooter__user"><div class="js-hovercard" data-hovercard-target-name="mitrad"><a itemprop="url" href="/mitrad"><img alt="mitrad" class="thumb thumb--xs" src="https://qiita-image-store.s3.amazonaws.com/0/86562/profile-images/1473703788" /></a></div></div><div class="ArticleFooter__user"><div class="js-hovercard" data-hovercard-target-name="Reds"><a itemprop="url" href="/Reds"><img alt="Reds" class="thumb thumb--xs" src="https://0.gravatar.com/avatar/e751888e30cdc35253c1a3b241977adf?d=https%3A%2F%2Fidenticons.github.com%2F0e2f15414d97b8b642022be91ff105e0.png" /></a></div></div><div class="ArticleFooter__user"><div class="js-hovercard" data-hovercard-target-name="snoopython"><a itemprop="url" href="/snoopython"><img alt="snoopython" class="thumb thumb--xs" src="https://qiita-image-store.s3.amazonaws.com/0/44000/profile-images/1473898779" /></a></div></div><div class="ArticleFooter__user"><div class="js-hovercard" data-hovercard-target-name="minewebstaff"><a itemprop="url" href="/minewebstaff"><img alt="minewebstaff" class="thumb thumb--xs" src="https://qiita-image-store.s3.amazonaws.com/0/46049/profile-images/1473690517" /></a></div></div><div class="ArticleFooter__user"><div class="js-hovercard" data-hovercard-target-name="mero"><a itemprop="url" href="/mero"><img alt="mero" class="thumb thumb--xs" src="https://qiita-image-store.s3.amazonaws.com/0/63104/profile-images/1473696161" /></a></div></div><div class="ArticleFooter__user"><a href="/hogefugabar/items/c27ed578717c5e7288c0/likers"><span class="fa fa-ellipsis-h"></span></a></div></div></div><div class="u-flex u-align-center"><div class="ArticleFooter__stock"><div class="js-stockbutton" data-position="footer_menu" data-props="{&quot;stock_status&quot;:false}"></div></div><div class="ArticleFooter__editRequest"><a class="u-link-no-underline" data-toggle="tooltip" title="You can propose improvements about the article to the author 💪" href="/drafts/c27ed578717c5e7288c0/edit"><span class="fa fa-send-o fa-lg"></span> <span>Edit request</span></a></div><div class="dropdown ArticleFooter__dropdown"><a class="dropdown-toggle" data-toggle="dropdown" href="#"><span class="fa fa-ellipsis-h"></span></a><ul class="dropdown-menu dropdown-menu-right"><li><a href="/hogefugabar/items/c27ed578717c5e7288c0.md"><span class="fa fa-fw fa-file-text-o"></span> Show article as Markdown</a></li><li><a data-target=".js-report-form" data-toggle="modal" href="#"><i class="fa fa-fw fa-flag"></i> Report article</a></li></ul></div></div></div><div class="itemsShowBody_articleColumnFooter"><div class="socialButtons"><div class="socialButtons_twitter"><a class="twitter-share-button" data-text="深層学習でニュース記事を分類する by @hogefugabar on @Qiita" data-url="http://qiita.com/hogefugabar/items/c27ed578717c5e7288c0" href="https://twitter.com/share">Tweet</a></div><div class="socialButtons_hatebu"><a class="hatena-bookmark-button" data-hatena-bookmark-layout="simple-balloon" data-hatena-bookmark-title="深層学習でニュース記事を分類する" href="http://b.hatena.ne.jp/entry/http://qiita.com/hogefugabar/items/c27ed578717c5e7288c0" title="Add to Hatena Bookmark"><img alt="Add to Hatena Bookmark" height="20" src="https://b.st-hatena.com/images/entry-button/button-only@2x.png" style="border: none;" width="20" /></a><script async="async" charset="utf-8" src="https://b.st-hatena.com/js/bookmark_button.js" type="text/javascript"></script></div><div class="socialButtons_googlePlus"><div class="g-plusone" data-href="http://qiita.com/hogefugabar/items/c27ed578717c5e7288c0" data-size="medium"></div></div><div class="socialButtons_facebook"><div class="fb-like" data-action="like" data-href="http://qiita.com/hogefugabar/items/c27ed578717c5e7288c0" data-layout="button_count" data-share="false" data-show-faces="false"></div></div><div class="socialButtons_pocket"><a class="pocket-btn" data-lang="en" data-pocket-count="horizontal" data-pocket-label="pocket"></a></div></div></div><div class="itemsShowComment_wrapper" id="comments"><div class="js-react-on-rails-component" data-component-name="CommentListContainer" data-props="{&quot;currentUser&quot;:null,&quot;initialComments&quot;:[],&quot;monthly_public_image_uploadable_size_limit&quot;:null,&quot;total_uploaded_public_image_size_in_current_month&quot;:null,&quot;item&quot;:{&quot;id&quot;:317691,&quot;uuid&quot;:&quot;c27ed578717c5e7288c0&quot;,&quot;suspended&quot;:false,&quot;secret&quot;:false},&quot;owner&quot;:{&quot;url_name&quot;:&quot;hogefugabar&quot;},&quot;is_team&quot;:false,&quot;is_project&quot;:false,&quot;logged_in&quot;:false,&quot;polling&quot;:false,&quot;mention_candidates&quot;:[{&quot;id&quot;:31899,&quot;url_name&quot;:&quot;hogefugabar&quot;,&quot;profile_image_url&quot;:&quot;https://qiita-image-store.s3.amazonaws.com/0/31899/profile-images/1473685791&quot;}]}" data-trace="false" data-dom-id="CommentListContainer-react-component-fb00e73f-c287-425a-aab2-501b92426826"></div>
    <div id="CommentListContainer-react-component-fb00e73f-c287-425a-aab2-501b92426826"></div>
    
</div></div></div></div></article><div class="js-report-form modal fade reportForm"><div class="modal-dialog"><div class="modal-content"><div class="modal-header"><button name="button" type="submit" class="close" data-dismiss="modal">&times;</button><h4 class="modal-title">Report article</h4></div><div class="modal-body"><form action="/reports" accept-charset="UTF-8" method="post"><input name="utf8" type="hidden" value="&#x2713;" /><input type="hidden" name="authenticity_token" value="ncMZdlAQ01Zv1zCcTeSiV62b06beIio+Ym0feNowhWiD8l7q/s9fKPtxeffMRSd2n3s0r2TdBQRk6nz/eV/TRg==" /><input type="hidden" name="redirect_path" id="redirect_path" value="/hogefugabar/items/c27ed578717c5e7288c0" /><input type="hidden" name="item_uuid" id="item_uuid" value="c27ed578717c5e7288c0" /><p>Help us understand the problem. What is going on with this item?</p><br /><div class="form-group"><ul class="list-unstyled"><li><label><input type="radio" name="report_type" id="report_type_spam" value="spam" required="required" /> It&#39;s spam </label></li><li><label><input type="radio" name="report_type" id="report_type_harassment" value="harassment" required="required" /> It&#39;s abusive or harmful </label></li><li><label><input type="radio" name="report_type" id="report_type_inappropriate_content" value="inappropriate_content" required="required" /> It contains inappropriate content </label></li></ul></div><div class="reportForm_submitButtonContainer"><button name="button" type="submit" class="btn btn-primary reportForm_submitButton"><i class="fa fa-send"></i> Submit</button></div></form></div></div></div></div><script id="js-item" type="application/json">{ "url": "http://qiita.com/hogefugabar/items/c27ed578717c5e7288c0", "id": 317691, "uuid": "c27ed578717c5e7288c0" }</script><script class="js-user" type="application/json">{&quot;id&quot;:31899,&quot;url_name&quot;:&quot;hogefugabar&quot;,&quot;profile_image_url&quot;:&quot;https://qiita-image-store.s3.amazonaws.com/0/31899/profile-images/1473685791&quot;}</script><script language="JavaScript" src="//cdn.bigmining.com/private/js/qiita_bigmining.js" type="text/javascript"></script></div><footer class="footer"><div class="footer_inner"><div class="footer_container"><ul class="footer_links-left"><li class="footer_link"><a class="footer_copyright" href="http://increments.co.jp">© 2011-2017 Increments Inc.</a></li><li class="footer_link"><a href="http://qiita.com/terms">Terms</a></li><li class="footer_link"><a href="http://qiita.com/privacy">Privacy</a></li><li class="footer_link"><a href="http://help.qiita.com">Help</a></li><li class="footer_link"><a href="https://increments.zendesk.com/anonymous_requests/new">Contact</a></li></ul><ul class="footer_links-right"><li class="footer_link"><a href="http://qiita.com/about">About</a></li><li class="footer_link"><a href="/users">Users</a></li><li class="footer_link"><a href="/tags">Tags</a></li><li class="footer_link"><a href="http://blog.qiita.com">Blog</a></li><li class="footer_link"><a href="http://qiita.com/api/v2/docs">API</a></li><li class="footer_link"><a href="https://teams.qiita.com/">Team</a></li><li class="footer_link"><a href="http://kobito.qiita.com">Kobito</a></li><li class="footer_link"><a class="js-public-form-feedback-link" data-target=".js-feedback-form" data-toggle="modal" href=""><i class="fa fa-heart"></i> Feedback <i class="fa fa-caret-down"></i></a></li></ul></div></div></footer><div class="js-feedback-form modal fade feedbackForm"><div class="modal-dialog"><div class="modal-content"><div class="modal-header"><button name="button" type="submit" class="close" data-dismiss="modal">&times;</button><h4 class="modal-title">Feedback</h4></div><div class="modal-body"><form class="js-feedback-form-form" action="/feedbacks" accept-charset="UTF-8" method="post"><input name="utf8" type="hidden" value="&#x2713;" /><input type="hidden" name="authenticity_token" value="mHwTq32c02ag/zUZ75FJssHys1wLxo/gWFhPcxg9GI6GTVQ300NfGDRZfHJuMMyT8xJUVbE5oNpe3yz0u1JOoA==" /><input type="hidden" name="redirect_path" id="redirect_path" value="/hogefugabar/items/c27ed578717c5e7288c0" /><div class="form-group"><textarea name="feedback[message]" id="feedback_message" class="form-control js-feedback-form-text-area" placeholder="Please give us any feedback about Qiita." required="required" rows="5">
</textarea></div><div class="feedbackForm_submitButtonContainer"><button name="button" type="submit" class="btn btn-primary feedbackForm_submitButton"><i class="fa fa-send"></i> Submit</button><p class="feedbackForm_note">We don&#39;t reply to any feedback.<br />If you need help with Qiita, please send a support request from <a href="https://increments.zendesk.com/anonymous_requests/new">here</a>.</p></div><div style="position:fixed;top:-99999px;opacity:0.0001;"><input name="feedback[name]" type="text" /></div></form></div></div></div></div><script>// if (window.mixpanel instanceof Element) {
//   window.mixpanel = [];
// }
// (function(f,b){if(!b.__SV){var a,e,i,g;window.mixpanel=b;b._i=[];b.init=function(a,e,d){function f(b,h){var a=h.split(".");2==a.length&&(b=b[a[0]],h=a[1]);b[h]=function(){b.push([h].concat(Array.prototype.slice.call(arguments,0)))}}var c=b;"undefined"!==typeof d?c=b[d]=[]:d="mixpanel";c.people=c.people||[];c.toString=function(b){var a="mixpanel";"mixpanel"!==d&&(a+="."+d);b||(a+=" (stub)");return a};c.people.toString=function(){return c.toString(1)+".people (stub)"};i="disable track track_pageview track_links track_forms register register_once alias unregister identify name_tag set_config people.set people.set_once people.increment people.append people.track_charge people.clear_charges people.delete_user".split(" ");
// for(g=0;g<i.length;g++)f(c,i[g]);b._i.push([a,e,d])};b.__SV=1.2;a=f.createElement("script");a.type="text/javascript";a.async=!0;a.src="//cdn.mxpnl.com/libs/mixpanel-2.2.min.js";e=f.getElementsByTagName("script")[0];e.parentNode.insertBefore(a,e)}})(document,window.mixpanel||[]);</script><script src="http://cdn.qiita.com/assets/public-3af9c1d29a49f3320bb796fb5e75304b.min.js"></script><script>
  (function () {
    var script = document.getElementsByTagName('script')[0];
    var load = function (src, id) {
      var el = document.createElement('script');
      el.async = true;
      el.src = src;
      el.id = id;
      script.parentNode.insertBefore(el, script);
    };
      // Optimizely
      load('//cdn.optimizely.com/js/52738645.js', 'optimizely-jssdk');
      // Google Analytics
      window._gaq = window._gaq || [];
      var isCareer = location.hostname.split('.')[0] == 'career';
      if (isCareer) {
        window._gaq.push(['_setAccount', 'UA-24675221-11']);
        window._gaq.push(['_setDomainName', 'qiita.com']);
      } else {
        window._gaq.push(['_setAccount', 'UA-24675221-1']);
      }
      window._gaq.push(['_setCustomVar', 1, 'logged_in', 'false', 2]);
      window._gaq.push(['_trackPageview']);
      var src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
      load(src, 'google-analytics-jssdk');
    // Google Analytics - Universal Analytics
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
    (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
    m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','//www.google-analytics.com/analytics.js','ga');
        ga('create', 'UA-24675221-12', {
          
        });
          ga('create', 'UA-50450234-2', { name: 'user' });
          ga('user.send', 'pageview');
        ga('set', 'dimension1', 'false');
        ga('set', 'dimension3', 'false');
      ga('require', 'displayfeatures');
      ga('set', 'forceSSL', true);
      ga('send', 'pageview');
    // Google Tag Manager
      (function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
      new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
      j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
      '//www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
      })(window,document,'script','dataLayer','GTM-TBQWPN');
  })();
</script>
</body></html>